[2026-01-26T14:38:59.803+0000] {processor.py:161} INFO - Started process (PID=73) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:38:59.807+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:38:59.813+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:38:59.812+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:38:59.875+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:38:59.874+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:38:59.876+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:38:59.876+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:38:59.877+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:38:59.877+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:38:59.883+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:38:59.882+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:38:59.887+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:38:59.886+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:38:59.890+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:38:59.890+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:38:59.891+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:38:59.891+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:38:59.900+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:38:59.892+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:38:59.901+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:38:59.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.176 seconds
[2026-01-26T14:39:30.624+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:39:30.630+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:39:30.639+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:39:30.638+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:39:30.704+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:39:30.704+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:39:30.706+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:39:30.705+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:39:30.708+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:39:30.708+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:39:30.716+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:39:30.715+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:39:30.719+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:39:30.719+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:39:30.723+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:39:30.723+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:39:30.725+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:39:30.724+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:39:30.733+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:39:30.726+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:39:30.734+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:39:30.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.175 seconds
[2026-01-26T14:39:59.581+0000] {processor.py:161} INFO - Started process (PID=64) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:39:59.584+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:39:59.589+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:39:59.588+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:39:59.673+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:39:59.672+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:39:59.676+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:39:59.675+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:39:59.677+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:39:59.677+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:39:59.685+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:39:59.684+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:39:59.689+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:39:59.688+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:39:59.693+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:39:59.693+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:39:59.694+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:39:59.694+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:39:59.704+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:39:59.695+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:39:59.705+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:39:59.768+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.201 seconds
[2026-01-26T14:40:30.729+0000] {processor.py:161} INFO - Started process (PID=74) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:40:30.730+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:40:30.733+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:40:30.733+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:40:30.790+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:40:30.790+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:40:30.792+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:40:30.791+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:40:30.793+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:40:30.793+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:40:30.800+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:40:30.800+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:40:30.804+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:40:30.804+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:40:30.809+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:40:30.808+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:40:30.810+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:40:30.809+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:40:30.818+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:40:30.810+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:40:30.818+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:40:30.869+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.147 seconds
[2026-01-26T14:41:01.676+0000] {processor.py:161} INFO - Started process (PID=84) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:41:01.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:41:01.681+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:41:01.681+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:41:01.723+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:41:01.723+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:41:01.724+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:41:01.724+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:41:01.725+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:41:01.724+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:41:01.728+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:41:01.728+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:41:01.731+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:41:01.730+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:41:01.733+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:41:01.733+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:41:01.734+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:41:01.733+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:41:01.740+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:41:01.734+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:41:01.740+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:41:01.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.112 seconds
[2026-01-26T14:41:32.723+0000] {processor.py:161} INFO - Started process (PID=94) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:41:32.724+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:41:32.727+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:41:32.726+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:41:32.774+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:41:32.774+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:41:32.775+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:41:32.775+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:41:32.776+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:41:32.776+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:41:32.781+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:41:32.781+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:41:32.785+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:41:32.785+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:41:32.788+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:41:32.787+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:41:32.788+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:41:32.788+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:41:32.800+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:41:32.789+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:41:32.801+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:41:32.840+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.123 seconds
[2026-01-26T14:42:03.510+0000] {processor.py:161} INFO - Started process (PID=104) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:42:03.511+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:42:03.513+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:42:03.513+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:42:03.541+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:42:03.541+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:42:03.542+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:42:03.541+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:42:03.542+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:42:03.542+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:42:03.545+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:42:03.545+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:42:03.548+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:42:03.548+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:42:03.551+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:42:03.550+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:42:03.551+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:42:03.551+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:42:03.556+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:42:03.551+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:42:03.556+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:42:03.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.087 seconds
[2026-01-26T14:42:34.535+0000] {processor.py:161} INFO - Started process (PID=114) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:42:34.536+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:42:34.539+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:42:34.538+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:42:34.571+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:42:34.570+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:42:34.572+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:42:34.571+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:42:34.572+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:42:34.572+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:42:34.576+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:42:34.576+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:42:34.579+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:42:34.578+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:42:34.582+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:42:34.581+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:42:34.582+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:42:34.582+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:42:34.589+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:42:34.583+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:42:34.589+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:42:34.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.103 seconds
[2026-01-26T14:43:05.641+0000] {processor.py:161} INFO - Started process (PID=124) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:43:05.642+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:43:05.645+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:43:05.644+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:43:05.683+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:43:05.683+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:43:05.684+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:43:05.684+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:43:05.685+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:43:05.685+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:43:05.690+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:43:05.689+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:43:05.693+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:43:05.693+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:43:05.696+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:43:05.696+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:43:05.697+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:43:05.696+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:43:05.702+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:43:05.697+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:43:05.703+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:43:05.751+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.117 seconds
[2026-01-26T14:43:36.460+0000] {processor.py:161} INFO - Started process (PID=134) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:43:36.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:43:36.464+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:43:36.464+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:43:36.509+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:43:36.509+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:43:36.510+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:43:36.510+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:43:36.511+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:43:36.511+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:43:36.515+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:43:36.515+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:43:36.517+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:43:36.517+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:43:36.520+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:43:36.520+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:43:36.521+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:43:36.521+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:43:36.526+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:43:36.521+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:43:36.527+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:43:36.565+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.112 seconds
[2026-01-26T14:44:06.951+0000] {processor.py:161} INFO - Started process (PID=144) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:44:06.953+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:44:06.956+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:44:06.955+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:44:07.003+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:44:07.003+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:44:07.004+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:44:07.004+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:44:07.005+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:44:07.005+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:44:07.009+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:44:07.008+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:44:07.014+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:44:07.013+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:44:07.017+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:44:07.017+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:44:07.018+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:44:07.018+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:44:07.026+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:44:07.019+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:44:07.027+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:44:07.062+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.118 seconds
[2026-01-26T14:44:37.630+0000] {processor.py:161} INFO - Started process (PID=154) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:44:37.631+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:44:37.634+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:44:37.633+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:44:37.663+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:44:37.663+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:44:37.664+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:44:37.664+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:44:37.665+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:44:37.664+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:44:37.668+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:44:37.667+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:44:37.671+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:44:37.671+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:44:37.673+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:44:37.673+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:44:37.674+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:44:37.674+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:44:37.678+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:44:37.674+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:44:37.679+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:44:37.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.092 seconds
[2026-01-26T14:45:08.286+0000] {processor.py:161} INFO - Started process (PID=164) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:45:08.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:45:08.290+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:45:08.289+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:45:08.332+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:45:08.332+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:45:08.333+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:45:08.333+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:45:08.334+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:45:08.334+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:45:08.338+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:45:08.338+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:45:08.341+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:45:08.341+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:45:08.344+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:45:08.344+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:45:08.346+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:45:08.345+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:45:08.352+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:45:08.346+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:45:08.353+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:45:08.394+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.116 seconds
[2026-01-26T14:45:38.583+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:45:38.585+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:45:38.587+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:45:38.587+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:45:38.635+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:45:38.635+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:45:38.636+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:45:38.636+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:45:38.637+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:45:38.637+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:45:38.642+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:45:38.642+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:45:38.646+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:45:38.645+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:45:38.649+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:45:38.648+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:45:38.650+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:45:38.649+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:45:38.657+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:45:38.650+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:45:38.658+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:45:38.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.151 seconds
[2026-01-26T14:46:09.220+0000] {processor.py:161} INFO - Started process (PID=184) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:46:09.222+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:46:09.225+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:46:09.224+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:46:09.271+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:46:09.270+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:46:09.272+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:46:09.272+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:46:09.274+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:46:09.273+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:46:09.278+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:46:09.278+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:46:09.282+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:46:09.281+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:46:09.286+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:46:09.285+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:46:09.287+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:46:09.287+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:46:09.295+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:46:09.288+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:46:09.296+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:46:09.344+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.130 seconds
[2026-01-26T14:46:39.944+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:46:39.945+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:46:39.947+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:46:39.946+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:46:39.980+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:46:39.980+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:46:39.981+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:46:39.981+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:46:39.982+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:46:39.982+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:46:39.985+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:46:39.985+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:46:39.988+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:46:39.988+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:46:39.990+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:46:39.990+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:46:39.991+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:46:39.991+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:46:39.996+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:46:39.991+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:46:39.997+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:46:40.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.101 seconds
[2026-01-26T14:47:10.695+0000] {processor.py:161} INFO - Started process (PID=204) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:47:10.698+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:47:10.704+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:47:10.703+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:47:10.747+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:47:10.747+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:47:10.748+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:47:10.748+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:47:10.750+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:47:10.749+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:47:10.755+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:47:10.754+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:47:10.759+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:47:10.758+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:47:10.763+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:47:10.763+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:47:10.764+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:47:10.764+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:47:10.772+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:47:10.765+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:47:10.773+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:47:10.825+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.140 seconds
[2026-01-26T14:47:41.532+0000] {processor.py:161} INFO - Started process (PID=214) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:47:41.534+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:47:41.536+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:47:41.536+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:47:41.574+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:47:41.573+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:47:41.576+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:47:41.576+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:47:41.577+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:47:41.577+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:47:41.581+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:47:41.581+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:47:41.586+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:47:41.586+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:47:41.589+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:47:41.589+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:47:41.590+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:47:41.590+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:47:41.597+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:47:41.591+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:47:41.598+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:47:41.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.124 seconds
[2026-01-26T14:48:13.452+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:48:13.454+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:48:13.459+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:48:13.458+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:48:13.513+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:48:13.513+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:48:13.515+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:48:13.514+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:48:13.516+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:48:13.516+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:48:13.520+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:48:13.520+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:48:13.524+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:48:13.524+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:48:13.528+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:48:13.527+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:48:13.529+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:48:13.529+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:48:13.539+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:48:13.530+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:48:13.540+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:48:13.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.157 seconds
[2026-01-26T14:48:44.768+0000] {processor.py:161} INFO - Started process (PID=234) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:48:44.770+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:48:44.773+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:48:44.772+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:48:44.825+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:48:44.825+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:48:44.826+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:48:44.826+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:48:44.827+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:48:44.827+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:48:44.832+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:48:44.832+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:48:44.835+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:48:44.834+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:48:44.837+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:48:44.837+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:48:44.838+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:48:44.838+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:48:44.846+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:48:44.839+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:48:44.847+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:48:44.899+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.138 seconds
[2026-01-26T14:49:15.314+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:49:15.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:49:15.317+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:49:15.317+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:49:15.353+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:49:15.353+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:49:15.354+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:49:15.354+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:49:15.355+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:49:15.354+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:49:15.358+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:49:15.357+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:49:15.361+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:49:15.361+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:49:15.364+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:49:15.363+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:49:15.364+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:49:15.364+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:49:15.369+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:49:15.365+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:49:15.370+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:49:15.402+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.095 seconds
[2026-01-26T14:49:45.935+0000] {processor.py:161} INFO - Started process (PID=254) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:49:45.937+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:49:45.940+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:49:45.939+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:49:45.975+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:49:45.975+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:49:45.976+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:49:45.976+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:49:45.977+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:49:45.976+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:49:45.980+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:49:45.980+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:49:45.983+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:49:45.982+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:49:45.986+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:49:45.986+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:49:45.987+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:49:45.987+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:49:45.993+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:49:45.987+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:49:45.994+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:49:46.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.107 seconds
[2026-01-26T14:50:16.833+0000] {processor.py:161} INFO - Started process (PID=264) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:50:16.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:50:16.837+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:50:16.836+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:50:16.872+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:50:16.871+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:50:16.873+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:50:16.873+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:50:16.874+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:50:16.874+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:50:16.880+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:50:16.880+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:50:16.884+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:50:16.883+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:50:16.887+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:50:16.886+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:50:16.887+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:50:16.887+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:50:16.893+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:50:16.888+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:50:16.894+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:50:16.938+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.111 seconds
[2026-01-26T14:50:48.050+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:50:48.052+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:50:48.055+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:50:48.054+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:50:48.110+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:50:48.109+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:50:48.112+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:50:48.111+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:50:48.113+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:50:48.113+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:50:48.118+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:50:48.117+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:50:48.120+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:50:48.120+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:50:48.123+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:50:48.123+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:50:48.124+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:50:48.124+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:50:48.131+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:50:48.124+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:50:48.132+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:50:48.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.134 seconds
[2026-01-26T14:51:19.368+0000] {processor.py:161} INFO - Started process (PID=284) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:51:19.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:51:19.374+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:51:19.373+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:51:19.462+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:51:19.461+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:51:19.463+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:51:19.463+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:51:19.465+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:51:19.465+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:51:19.470+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:51:19.470+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:51:19.475+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:51:19.474+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:51:19.479+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:51:19.478+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:51:19.480+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:51:19.480+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:51:19.501+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:51:19.481+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:51:19.503+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:51:19.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.212 seconds
[2026-01-26T14:51:50.570+0000] {processor.py:161} INFO - Started process (PID=294) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:51:50.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:51:50.584+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:51:50.583+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:51:50.704+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:51:50.704+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:51:50.705+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:51:50.705+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:51:50.710+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:51:50.709+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:51:50.719+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:51:50.718+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:51:50.723+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:51:50.722+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:51:50.731+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:51:50.731+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:51:50.732+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:51:50.732+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:51:50.748+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:51:50.733+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:51:50.749+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:51:50.911+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.361 seconds
[2026-01-26T14:52:21.247+0000] {processor.py:161} INFO - Started process (PID=304) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:52:21.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:52:21.251+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:52:21.251+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:52:21.289+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:52:21.289+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:52:21.290+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:52:21.290+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:52:21.291+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:52:21.291+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:52:21.296+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:52:21.295+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:52:21.299+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:52:21.298+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:52:21.302+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:52:21.302+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:52:21.303+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:52:21.302+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:52:21.310+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:52:21.303+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:52:21.311+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:52:21.359+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.120 seconds
[2026-01-26T14:52:51.897+0000] {processor.py:161} INFO - Started process (PID=314) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:52:51.899+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:52:51.903+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:52:51.902+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:52:51.947+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:52:51.946+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:52:51.947+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:52:51.947+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:52:51.948+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:52:51.948+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:52:51.953+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:52:51.952+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:52:51.956+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:52:51.956+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:52:51.959+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:52:51.958+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:52:51.960+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:52:51.959+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:52:51.966+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:52:51.960+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:52:51.966+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:52:52.010+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.123 seconds
[2026-01-26T14:53:22.413+0000] {processor.py:161} INFO - Started process (PID=324) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:53:22.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:53:22.418+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:53:22.418+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:53:22.465+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:53:22.464+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:53:22.466+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:53:22.465+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:53:22.467+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:53:22.466+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:53:22.471+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:53:22.471+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:53:22.475+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:53:22.475+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:53:22.478+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:53:22.478+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:53:22.479+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:53:22.479+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:53:22.490+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:53:22.483+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:53:22.491+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:53:22.536+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.133 seconds
[2026-01-26T14:53:52.905+0000] {processor.py:161} INFO - Started process (PID=334) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:53:52.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:53:52.909+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:53:52.909+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:53:52.943+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:53:52.942+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:53:52.943+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:53:52.943+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:53:52.944+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:53:52.944+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:53:52.948+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:53:52.948+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:53:52.951+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:53:52.950+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:53:52.953+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:53:52.953+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:53:52.954+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:53:52.954+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:53:52.959+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:53:52.954+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:53:52.960+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:53:52.992+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.094 seconds
[2026-01-26T14:54:24.611+0000] {processor.py:161} INFO - Started process (PID=344) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:54:24.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:54:24.618+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:54:24.617+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:54:24.674+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:54:24.673+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:54:24.675+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:54:24.675+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:54:24.677+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:54:24.677+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:54:24.684+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:54:24.683+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:54:24.688+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:54:24.687+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:54:24.691+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:54:24.691+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:54:24.692+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:54:24.691+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:54:24.700+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:54:24.692+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:54:24.701+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:54:24.751+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.149 seconds
[2026-01-26T14:54:55.146+0000] {processor.py:161} INFO - Started process (PID=354) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:54:55.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:54:55.151+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:54:55.150+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:54:55.190+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:54:55.190+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:54:55.191+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:54:55.191+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:54:55.192+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:54:55.192+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:54:55.196+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:54:55.195+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:54:55.198+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:54:55.198+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:54:55.203+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:54:55.203+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:54:55.204+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:54:55.204+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:54:55.211+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:54:55.205+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:54:55.212+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:54:55.261+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.122 seconds
[2026-01-26T14:55:26.086+0000] {processor.py:161} INFO - Started process (PID=364) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:55:26.087+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:55:26.089+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:55:26.088+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:55:26.122+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:55:26.122+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:55:26.123+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:55:26.123+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:55:26.125+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:55:26.125+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:55:26.129+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:55:26.129+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:55:26.132+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:55:26.132+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:55:26.135+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:55:26.135+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:55:26.136+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:55:26.136+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:55:26.141+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:55:26.136+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:55:26.142+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:55:26.180+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.102 seconds
[2026-01-26T14:55:56.663+0000] {processor.py:161} INFO - Started process (PID=374) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:55:56.665+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:55:56.669+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:55:56.668+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:55:56.716+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:55:56.716+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:55:56.717+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:55:56.717+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:55:56.718+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:55:56.718+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:55:56.723+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:55:56.722+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:55:56.725+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:55:56.725+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:55:56.728+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:55:56.728+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:55:56.729+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:55:56.729+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:55:56.736+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:55:56.729+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:55:56.737+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:55:56.779+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.125 seconds
[2026-01-26T14:56:27.977+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:56:27.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:56:27.981+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:56:27.981+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:56:28.029+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:56:28.029+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:56:28.030+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:56:28.030+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:56:28.031+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:56:28.031+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:56:28.035+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:56:28.035+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:56:28.039+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:56:28.039+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:56:28.042+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:56:28.041+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:56:28.042+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:56:28.042+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:56:28.047+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:56:28.043+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:56:28.048+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:56:28.083+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.111 seconds
[2026-01-26T14:56:58.998+0000] {processor.py:161} INFO - Started process (PID=394) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:56:58.999+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:56:59.003+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:56:59.002+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:56:59.055+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:56:59.054+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:56:59.055+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:56:59.055+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:56:59.056+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:56:59.056+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:56:59.060+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:56:59.060+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:56:59.063+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:56:59.062+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:56:59.067+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:56:59.067+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:56:59.068+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:56:59.068+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:56:59.075+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:56:59.069+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:56:59.075+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:56:59.127+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.137 seconds
[2026-01-26T14:57:38.031+0000] {processor.py:161} INFO - Started process (PID=64) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:57:38.035+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:57:38.040+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:57:38.039+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:57:38.114+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:57:38.113+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:57:38.115+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:57:38.115+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:57:38.117+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:57:38.117+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:57:38.124+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:57:38.123+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:57:38.128+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:57:38.127+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:57:38.132+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:57:38.131+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:57:38.133+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:57:38.133+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:57:38.141+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:57:38.133+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:57:38.142+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:57:38.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.179 seconds
[2026-01-26T14:58:09.749+0000] {processor.py:161} INFO - Started process (PID=74) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:58:09.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:58:09.754+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:58:09.754+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:58:09.830+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:58:09.830+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:58:09.832+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:58:09.831+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:58:09.834+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:58:09.833+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:58:09.842+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:58:09.841+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:58:09.847+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:58:09.846+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:58:09.851+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:58:09.851+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:58:09.853+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:58:09.852+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:58:09.862+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:58:09.853+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:58:09.863+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:58:09.949+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.217 seconds
[2026-01-26T14:58:40.092+0000] {processor.py:161} INFO - Started process (PID=84) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:58:40.093+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:58:40.095+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:58:40.095+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:58:40.128+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:58:40.128+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:58:40.129+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:58:40.129+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:58:40.130+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:58:40.130+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:58:40.133+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:58:40.133+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:58:40.137+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:58:40.136+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:58:40.139+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:58:40.139+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:58:40.140+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:58:40.140+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:58:40.145+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:58:40.140+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:58:40.146+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:58:40.186+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.101 seconds
[2026-01-26T14:59:11.476+0000] {processor.py:161} INFO - Started process (PID=94) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:59:11.484+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:59:11.489+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:59:11.488+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:59:11.554+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:59:11.554+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:59:11.555+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:59:11.555+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:59:11.556+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:59:11.556+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:59:11.561+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:59:11.560+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:59:11.565+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:59:11.565+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:59:11.569+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:59:11.568+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:59:11.570+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:59:11.569+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:59:11.579+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:59:11.570+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:59:11.581+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:59:11.634+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.177 seconds
[2026-01-26T14:59:41.848+0000] {processor.py:161} INFO - Started process (PID=104) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:59:41.851+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T14:59:41.856+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:59:41.855+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:59:41.907+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:59:41.906+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T14:59:41.907+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:59:41.907+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T14:59:41.909+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:59:41.908+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T14:59:41.914+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:59:41.913+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:59:41.917+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:59:41.917+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:59:41.921+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:59:41.921+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T14:59:41.922+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:59:41.922+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T14:59:41.931+0000] {logging_mixin.py:188} INFO - [2026-01-26T14:59:41.923+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T14:59:41.936+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T14:59:42.111+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.274 seconds
[2026-01-26T15:00:13.196+0000] {processor.py:161} INFO - Started process (PID=114) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:00:13.197+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:00:13.201+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:00:13.201+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:00:13.292+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:00:13.292+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:00:13.294+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:00:13.293+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:00:13.295+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:00:13.295+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:00:13.304+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:00:13.303+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:00:13.308+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:00:13.307+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:00:13.312+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:00:13.311+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:00:13.313+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:00:13.313+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:00:13.322+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:00:13.314+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:00:13.323+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:00:13.369+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.183 seconds
[2026-01-26T15:00:44.179+0000] {processor.py:161} INFO - Started process (PID=124) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:00:44.180+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:00:44.182+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:00:44.182+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:00:44.218+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:00:44.218+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:00:44.219+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:00:44.219+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:00:44.219+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:00:44.219+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:00:44.223+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:00:44.223+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:00:44.226+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:00:44.226+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:00:44.229+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:00:44.228+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:00:44.229+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:00:44.229+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:00:44.235+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:00:44.230+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:00:44.236+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:00:44.270+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.097 seconds
[2026-01-26T15:01:15.120+0000] {processor.py:161} INFO - Started process (PID=134) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:01:15.121+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:01:15.124+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:01:15.124+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:01:15.156+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:01:15.156+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:01:15.157+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:01:15.157+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:01:15.157+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:01:15.157+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:01:15.161+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:01:15.161+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:01:15.164+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:01:15.164+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:01:15.167+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:01:15.167+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:01:15.168+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:01:15.167+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:01:15.173+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:01:15.168+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:01:15.174+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:01:15.211+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.098 seconds
[2026-01-26T15:01:46.349+0000] {processor.py:161} INFO - Started process (PID=144) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:01:46.350+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:01:46.352+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:01:46.352+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:01:46.387+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:01:46.387+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:01:46.388+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:01:46.387+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:01:46.388+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:01:46.388+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:01:46.392+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:01:46.392+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:01:46.396+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:01:46.396+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:01:46.400+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:01:46.399+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:01:46.401+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:01:46.400+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:01:46.411+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:01:46.402+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:01:46.412+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:01:46.449+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.106 seconds
[2026-01-26T15:02:16.819+0000] {processor.py:161} INFO - Started process (PID=154) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:02:16.820+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:02:16.822+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:02:16.822+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:02:16.864+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:02:16.864+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:02:16.865+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:02:16.865+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:02:16.866+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:02:16.866+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:02:16.871+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:02:16.870+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:02:16.874+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:02:16.874+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:02:16.879+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:02:16.879+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:02:16.880+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:02:16.880+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:02:16.887+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:02:16.881+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:02:16.888+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:02:16.938+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.126 seconds
[2026-01-26T15:02:47.381+0000] {processor.py:161} INFO - Started process (PID=164) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:02:47.382+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:02:47.386+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:02:47.386+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:02:47.444+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:02:47.443+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:02:47.445+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:02:47.445+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:02:47.446+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:02:47.445+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:02:50.451+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:02:50.451+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: timed out
[2026-01-26T15:02:53.456+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:02:53.456+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: timed out
[2026-01-26T15:06:44.899+0000] {processor.py:161} INFO - Started process (PID=58) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:06:44.904+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:06:44.909+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:06:44.908+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:06:44.975+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:06:44.975+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:06:44.977+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:06:44.976+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:06:44.978+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:06:44.978+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:06:44.984+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:06:44.984+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:06:44.989+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:06:44.988+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:06:44.993+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:06:44.993+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:06:44.994+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:06:44.994+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:06:45.003+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:06:44.995+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:06:45.004+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:06:45.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.184 seconds
[2026-01-26T15:07:16.238+0000] {processor.py:161} INFO - Started process (PID=86) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:07:16.239+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:07:16.243+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:07:16.242+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:07:16.294+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:07:16.294+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:07:16.296+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:07:16.295+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:07:16.297+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:07:16.296+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:07:16.301+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:07:16.301+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:07:16.304+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:07:16.304+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:07:16.307+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:07:16.307+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:07:16.308+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:07:16.308+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:07:16.316+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:07:16.309+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:07:16.317+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:07:16.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.137 seconds
[2026-01-26T15:09:22.808+0000] {processor.py:161} INFO - Started process (PID=64) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:09:22.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:09:22.814+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:09:22.814+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:09:22.864+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:09:22.863+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:09:22.865+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:09:22.865+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:09:22.866+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:09:22.866+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:09:22.871+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:09:22.871+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:09:22.874+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:09:22.874+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:09:22.877+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:09:22.877+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:09:22.878+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:09:22.878+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:09:22.886+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:09:22.879+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:09:22.886+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:09:22.928+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.130 seconds
[2026-01-26T15:09:53.929+0000] {processor.py:161} INFO - Started process (PID=74) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:09:53.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:09:53.933+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:09:53.933+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:09:53.971+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:09:53.971+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:09:53.972+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:09:53.972+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:09:53.973+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:09:53.973+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:09:53.977+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:09:53.977+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:09:53.981+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:09:53.980+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:09:53.984+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:09:53.983+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:09:53.984+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:09:53.984+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:09:53.991+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:09:53.985+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:09:53.992+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:09:54.038+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.117 seconds
[2026-01-26T15:10:24.226+0000] {processor.py:161} INFO - Started process (PID=84) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:10:24.227+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:10:24.229+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:10:24.229+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:10:24.272+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:10:24.272+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:10:24.273+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:10:24.273+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:10:24.274+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:10:24.274+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:10:24.279+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:10:24.278+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:10:24.282+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:10:24.282+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:10:24.285+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:10:24.285+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:10:24.286+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:10:24.286+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:10:24.292+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:10:24.286+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:10:24.293+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:10:24.338+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.119 seconds
[2026-01-26T15:12:43.802+0000] {processor.py:161} INFO - Started process (PID=64) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:12:43.806+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:12:43.812+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:12:43.811+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:12:43.882+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:12:43.881+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:12:43.883+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:12:43.883+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:12:43.884+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:12:43.884+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:12:43.892+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:12:43.891+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:12:43.896+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:12:43.895+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:12:43.899+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:12:43.899+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:12:43.900+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:12:43.900+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:12:43.908+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:12:43.901+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:12:43.909+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:12:43.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.179 seconds
[2026-01-26T15:13:31.250+0000] {processor.py:161} INFO - Started process (PID=64) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:13:31.253+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:13:31.258+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:13:31.257+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:13:31.335+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:13:31.334+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:13:31.337+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:13:31.336+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:13:31.339+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:13:31.338+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:13:31.347+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:13:31.346+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:13:31.352+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:13:31.351+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:13:31.356+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:13:31.355+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:13:31.358+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:13:31.357+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:13:31.367+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:13:31.358+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:13:31.369+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:13:31.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.204 seconds
[2026-01-26T15:14:02.299+0000] {processor.py:161} INFO - Started process (PID=85) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:14:02.301+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:14:02.304+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:14:02.304+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:14:02.354+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:14:02.354+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:14:02.355+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:14:02.355+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:14:02.356+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:14:02.356+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:14:02.362+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:14:02.362+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:14:02.365+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:14:02.365+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:14:02.368+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:14:02.368+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:14:02.369+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:14:02.369+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:14:02.377+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:14:02.370+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:14:02.379+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:14:02.434+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.144 seconds
[2026-01-26T15:14:33.415+0000] {processor.py:161} INFO - Started process (PID=95) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:14:33.417+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:14:33.422+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:14:33.421+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:14:33.471+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:14:33.471+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:14:33.472+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:14:33.472+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:14:33.473+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:14:33.473+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:14:33.477+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:14:33.477+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:14:33.480+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:14:33.480+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:14:33.483+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:14:33.482+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:14:33.483+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:14:33.483+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:14:33.490+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:14:33.484+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:14:33.491+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:14:33.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.451 seconds
[2026-01-26T15:15:05.010+0000] {processor.py:161} INFO - Started process (PID=105) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:15:05.016+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:15:05.023+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:15:05.022+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:15:05.110+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:15:05.110+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:15:05.113+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:15:05.112+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:15:05.115+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:15:05.114+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:15:05.125+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:15:05.125+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:15:05.131+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:15:05.130+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:15:05.137+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:15:05.136+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:15:05.138+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:15:05.138+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:15:05.154+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:15:05.139+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:15:05.156+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:15:05.228+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.250 seconds
[2026-01-26T15:15:36.162+0000] {processor.py:161} INFO - Started process (PID=115) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:15:36.163+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:15:36.165+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:15:36.165+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:15:36.205+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:15:36.205+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:15:36.206+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:15:36.206+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:15:36.207+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:15:36.207+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:15:36.211+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:15:36.210+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:15:36.213+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:15:36.213+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:15:36.216+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:15:36.216+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:15:36.217+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:15:36.217+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:15:36.223+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:15:36.217+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:15:36.224+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:15:36.290+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.135 seconds
[2026-01-26T15:16:07.337+0000] {processor.py:161} INFO - Started process (PID=125) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:16:07.339+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:16:07.343+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:16:07.342+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:16:07.386+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:16:07.385+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:16:07.387+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:16:07.386+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:16:07.388+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:16:07.387+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:16:07.393+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:16:07.392+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:16:07.395+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:16:07.395+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:16:07.399+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:16:07.398+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:16:07.400+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:16:07.399+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:16:07.406+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:16:07.400+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:16:07.407+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:16:07.448+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.119 seconds
[2026-01-26T15:16:38.669+0000] {processor.py:161} INFO - Started process (PID=135) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:16:38.671+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:16:38.674+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:16:38.674+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:16:38.728+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:16:38.728+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:16:38.730+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:16:38.729+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:16:38.731+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:16:38.731+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:16:38.737+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:16:38.736+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:16:38.740+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:16:38.740+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:16:38.744+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:16:38.743+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:16:38.744+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:16:38.744+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:16:38.753+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:16:38.745+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:16:38.754+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:16:38.802+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.141 seconds
[2026-01-26T15:17:09.278+0000] {processor.py:161} INFO - Started process (PID=145) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:17:09.289+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:17:09.304+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:17:09.303+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:17:09.517+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:17:09.517+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:17:09.520+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:17:09.519+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:17:09.522+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:17:09.522+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:17:09.531+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:17:09.530+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:17:09.537+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:17:09.536+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:17:09.546+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:17:09.545+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:17:09.548+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:17:09.548+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:17:09.693+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:17:09.549+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:17:09.696+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:17:09.816+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.574 seconds
[2026-01-26T15:17:41.166+0000] {processor.py:161} INFO - Started process (PID=155) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:17:41.179+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:17:41.209+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:17:41.197+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:17:41.548+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:17:41.547+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:17:41.549+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:17:41.549+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:17:41.553+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:17:41.553+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:17:41.585+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:17:41.585+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:17:41.601+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:17:41.600+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:17:41.611+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:17:41.610+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:17:41.615+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:17:41.615+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:17:41.708+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:17:41.619+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:17:41.712+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:17:42.017+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.920 seconds
[2026-01-26T15:18:31.471+0000] {processor.py:161} INFO - Started process (PID=165) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:18:31.495+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:18:31.527+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:18:31.527+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:18:32.386+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:18:32.386+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:18:32.388+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:18:32.388+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:18:32.416+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:18:32.415+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:18:32.486+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:18:32.485+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:18:32.544+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:18:32.544+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:18:32.590+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:18:32.590+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:18:32.596+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:18:32.595+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:18:32.801+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:18:32.618+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:18:32.821+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:18:33.627+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 2.189 seconds
[2026-01-26T15:19:31.956+0000] {processor.py:161} INFO - Started process (PID=176) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:19:31.968+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:19:32.001+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:19:31.984+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:19:32.300+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:19:32.299+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:19:32.302+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:19:32.302+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:19:32.307+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:19:32.306+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:19:32.340+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:19:32.339+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:19:32.346+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:19:32.345+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:19:32.367+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:19:32.366+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:19:32.368+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:19:32.368+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:19:32.441+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:19:32.385+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:19:32.443+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:19:32.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.716 seconds
[2026-01-26T15:20:59.840+0000] {processor.py:161} INFO - Started process (PID=184) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:20:59.865+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:20:59.874+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:20:59.873+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:21:00.428+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:21:00.427+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:21:00.430+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:21:00.430+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:21:00.723+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:21:00.722+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:21:02.049+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:21:02.048+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:21:02.088+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:21:02.088+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:21:02.107+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:21:02.107+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:21:02.109+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:21:02.109+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:21:02.171+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:21:02.111+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:21:02.176+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:21:02.475+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 2.663 seconds
[2026-01-26T15:21:33.149+0000] {processor.py:161} INFO - Started process (PID=212) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:21:33.152+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:21:33.155+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:21:33.154+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:21:33.205+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:21:33.205+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:21:33.207+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:21:33.206+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:21:33.208+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:21:33.208+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:21:33.214+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:21:33.214+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:21:33.217+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:21:33.217+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:21:33.220+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:21:33.220+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:21:33.221+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:21:33.221+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:21:33.228+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:21:33.222+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:21:33.229+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:21:33.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.142 seconds
[2026-01-26T15:22:05.796+0000] {processor.py:161} INFO - Started process (PID=222) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:22:05.798+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:22:05.801+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:22:05.800+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:22:05.851+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:22:05.850+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:22:05.852+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:22:05.852+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:22:05.853+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:22:05.853+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:22:05.860+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:22:05.860+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:22:05.864+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:22:05.863+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:22:05.868+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:22:05.867+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:22:05.869+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:22:05.868+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:22:05.875+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:22:05.869+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:22:05.876+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:22:06.067+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.280 seconds
[2026-01-26T15:22:36.965+0000] {processor.py:161} INFO - Started process (PID=232) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:22:36.966+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:22:36.969+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:22:36.968+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:22:37.020+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:22:37.020+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:22:37.022+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:22:37.022+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:22:37.023+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:22:37.023+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:22:37.029+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:22:37.029+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:22:37.033+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:22:37.033+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:22:37.037+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:22:37.037+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:22:37.038+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:22:37.038+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:22:37.047+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:22:37.039+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:22:37.048+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:22:37.104+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.147 seconds
[2026-01-26T15:23:10.077+0000] {processor.py:161} INFO - Started process (PID=242) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:23:10.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:23:10.082+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:23:10.082+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:23:10.139+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:23:10.138+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:23:10.143+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:23:10.143+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:23:10.145+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:23:10.144+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:23:10.156+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:23:10.155+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:23:10.160+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:23:10.160+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:23:10.163+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:23:10.163+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:23:10.164+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:23:10.164+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:23:10.172+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:23:10.165+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:23:10.173+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:23:10.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.177 seconds
[2026-01-26T15:23:44.313+0000] {processor.py:161} INFO - Started process (PID=252) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:23:44.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-26T15:23:44.326+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:23:44.322+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:23:44.419+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:23:44.418+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-26T15:23:44.421+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:23:44.420+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-26T15:23:44.423+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:23:44.423+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-26T15:23:44.433+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:23:44.432+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:23:44.438+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:23:44.438+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:23:44.445+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:23:44.445+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-26T15:23:44.447+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:23:44.447+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-26T15:23:44.476+0000] {logging_mixin.py:188} INFO - [2026-01-26T15:23:44.449+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-26T15:23:44.478+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-26T15:23:44.563+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.269 seconds
