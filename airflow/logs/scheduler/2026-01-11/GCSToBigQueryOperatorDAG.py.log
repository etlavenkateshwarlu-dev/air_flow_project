[2026-01-11T09:23:51.199+0000] {processor.py:161} INFO - Started process (PID=56) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:23:51.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:23:51.207+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:23:51.207+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:23:51.239+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:23:51.232+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:23:51.254+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:23:51.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.168 seconds
[2026-01-11T09:24:22.270+0000] {processor.py:161} INFO - Started process (PID=70) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:24:22.271+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:24:22.274+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:24:22.273+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:24:22.289+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:24:22.286+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:24:22.290+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:24:22.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.068 seconds
[2026-01-11T09:24:53.269+0000] {processor.py:161} INFO - Started process (PID=77) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:24:53.270+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:24:53.272+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:24:53.272+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:24:53.298+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:24:53.293+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:24:53.300+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:24:53.357+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.093 seconds
[2026-01-11T09:25:24.198+0000] {processor.py:161} INFO - Started process (PID=84) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:25:24.200+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:25:24.204+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:25:24.203+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:25:24.227+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:25:24.221+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:25:24.229+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:25:24.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.099 seconds
[2026-01-11T09:25:55.108+0000] {processor.py:161} INFO - Started process (PID=91) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:25:55.109+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:25:55.112+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:25:55.112+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:25:55.146+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:25:55.139+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:25:55.148+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:25:55.213+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.111 seconds
[2026-01-11T09:26:26.494+0000] {processor.py:161} INFO - Started process (PID=98) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:26:26.498+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:26:26.501+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:26:26.500+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:26:26.516+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:26:26.513+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:26:26.518+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:26:26.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.072 seconds
[2026-01-11T09:26:57.513+0000] {processor.py:161} INFO - Started process (PID=105) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:26:57.514+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:26:57.516+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:26:57.516+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:26:57.534+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:26:57.530+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:26:57.536+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:26:57.586+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.078 seconds
[2026-01-11T09:27:28.368+0000] {processor.py:161} INFO - Started process (PID=112) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:27:28.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:27:28.372+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:27:28.372+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:27:28.391+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:27:28.386+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:27:28.392+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:27:28.448+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.086 seconds
[2026-01-11T09:27:59.225+0000] {processor.py:161} INFO - Started process (PID=119) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:27:59.240+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:27:59.245+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:27:59.244+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:27:59.394+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:27:59.387+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:27:59.397+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:27:59.467+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.250 seconds
[2026-01-11T09:28:29.894+0000] {processor.py:161} INFO - Started process (PID=126) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:28:29.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:28:29.898+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:28:29.897+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:28:29.914+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:28:29.911+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:28:29.915+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:28:29.955+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.067 seconds
[2026-01-11T09:29:00.378+0000] {processor.py:161} INFO - Started process (PID=133) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:29:00.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:29:00.381+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:29:00.381+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:29:00.398+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:29:00.394+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:29:00.400+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:29:00.438+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.065 seconds
[2026-01-11T09:29:30.785+0000] {processor.py:161} INFO - Started process (PID=140) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:29:30.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:29:30.790+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:29:30.789+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:29:30.817+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:29:30.811+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:29:30.820+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:29:30.883+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.104 seconds
[2026-01-11T09:30:01.497+0000] {processor.py:161} INFO - Started process (PID=147) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:30:01.500+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:30:01.504+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:30:01.503+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:30:01.527+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:30:01.523+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:30:01.528+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:30:01.588+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.097 seconds
[2026-01-11T09:30:32.543+0000] {processor.py:161} INFO - Started process (PID=154) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:30:32.544+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:30:32.547+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:30:32.546+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:30:32.563+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:30:32.558+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:30:32.565+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:30:32.603+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.066 seconds
[2026-01-11T09:31:03.330+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:31:03.331+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:31:03.333+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:31:03.333+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:31:03.348+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:31:03.344+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:31:03.349+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:31:03.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.076 seconds
[2026-01-11T09:31:33.766+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:31:33.767+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:31:33.769+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:31:33.769+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:31:33.785+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:31:33.781+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:31:33.786+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:31:33.824+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.066 seconds
[2026-01-11T09:32:04.157+0000] {processor.py:161} INFO - Started process (PID=175) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:32:04.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:32:04.162+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:32:04.161+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:32:04.178+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:32:04.174+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:32:04.179+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:32:04.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.070 seconds
[2026-01-11T09:32:34.531+0000] {processor.py:161} INFO - Started process (PID=182) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:32:34.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:32:34.535+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:32:34.534+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:32:34.568+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:32:34.561+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:32:34.571+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:32:34.638+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.114 seconds
[2026-01-11T09:33:06.236+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:33:06.238+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:33:06.239+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:33:06.239+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:33:06.257+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:33:06.254+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:33:06.259+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:33:06.301+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.070 seconds
[2026-01-11T09:33:36.648+0000] {processor.py:161} INFO - Started process (PID=196) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:33:36.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:33:36.652+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:33:36.651+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:33:36.671+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:33:36.667+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:33:36.673+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:33:36.726+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.086 seconds
[2026-01-11T09:34:07.092+0000] {processor.py:161} INFO - Started process (PID=203) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:34:07.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:34:07.096+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:34:07.095+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:34:07.113+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:34:07.107+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:34:07.114+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:34:07.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.072 seconds
[2026-01-11T09:34:37.723+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:34:37.726+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:34:37.729+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:34:37.728+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:34:37.760+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:34:37.753+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:34:37.763+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:34:37.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.283 seconds
[2026-01-11T09:35:08.453+0000] {processor.py:161} INFO - Started process (PID=217) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:35:08.454+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:35:08.459+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:35:08.458+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:35:08.494+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:35:08.487+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:35:08.497+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:35:08.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.231 seconds
[2026-01-11T09:35:39.340+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:35:39.341+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:35:39.343+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:35:39.343+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:35:39.358+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:35:39.354+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:35:39.360+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:35:39.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.065 seconds
[2026-01-11T09:36:10.508+0000] {processor.py:161} INFO - Started process (PID=231) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:36:10.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:36:10.513+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:36:10.512+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:36:10.540+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:36:10.534+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:36:10.543+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:36:10.610+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.108 seconds
[2026-01-11T09:36:41.365+0000] {processor.py:161} INFO - Started process (PID=238) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:36:41.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:36:41.369+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:36:41.368+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:36:41.386+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:36:41.383+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:36:41.389+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:36:41.430+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.071 seconds
[2026-01-11T09:37:12.255+0000] {processor.py:161} INFO - Started process (PID=245) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:37:12.256+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:37:12.259+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:37:12.259+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:37:12.280+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:37:12.276+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:37:12.282+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:37:12.342+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.093 seconds
[2026-01-11T09:37:43.346+0000] {processor.py:161} INFO - Started process (PID=252) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:37:43.347+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:37:43.350+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:37:43.349+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:37:43.392+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:37:43.386+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:37:43.394+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:37:43.469+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.134 seconds
[2026-01-11T09:38:13.786+0000] {processor.py:161} INFO - Started process (PID=259) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:38:13.788+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:38:13.791+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:38:13.790+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:38:13.820+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:38:13.814+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:38:13.822+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:38:13.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.104 seconds
[2026-01-11T09:38:44.180+0000] {processor.py:161} INFO - Started process (PID=266) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:38:44.181+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:38:44.183+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:38:44.183+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:38:44.198+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:38:44.195+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:38:44.200+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:38:44.243+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.069 seconds
[2026-01-11T09:39:14.536+0000] {processor.py:161} INFO - Started process (PID=273) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:39:14.537+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:39:14.540+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:39:14.539+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:39:14.563+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:39:14.556+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:39:14.565+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:39:14.624+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.095 seconds
[2026-01-11T09:39:45.149+0000] {processor.py:161} INFO - Started process (PID=280) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:39:45.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:39:45.154+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:39:45.154+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:39:45.174+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:39:45.170+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:39:45.175+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:39:45.218+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.075 seconds
[2026-01-11T09:40:16.391+0000] {processor.py:161} INFO - Started process (PID=287) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:40:16.393+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:40:16.395+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:40:16.394+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:40:16.413+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:40:16.409+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:40:16.414+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:40:16.468+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.084 seconds
[2026-01-11T09:40:46.679+0000] {processor.py:161} INFO - Started process (PID=294) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:40:46.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:40:46.682+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:40:46.681+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:40:46.696+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:40:46.693+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:40:46.698+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:40:46.740+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.066 seconds
[2026-01-11T09:41:16.948+0000] {processor.py:161} INFO - Started process (PID=301) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:41:16.949+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:41:16.951+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:41:16.951+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:41:16.965+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:41:16.961+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:41:16.967+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:41:17.016+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.074 seconds
[2026-01-11T09:41:47.388+0000] {processor.py:161} INFO - Started process (PID=308) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:41:47.389+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:41:47.392+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:41:47.392+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:41:47.413+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:41:47.408+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 4, in <module>
    from airflow.providers.standard.operators.empty import EmptyOperator
ModuleNotFoundError: No module named 'airflow.providers.standard'
[2026-01-11T09:41:47.415+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:41:47.465+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.084 seconds
[2026-01-11T09:42:12.767+0000] {processor.py:161} INFO - Started process (PID=313) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:42:12.768+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:42:12.770+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:42:12.769+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:42:12.835+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:42:12.834+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:42:12.836+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:42:12.836+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:42:12.844+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:42:12.843+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:42:12.863+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:42:12.863+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:42:12.867+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:42:12.866+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:42:12.870+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:42:12.870+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:42:12.872+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:42:12.872+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:42:12.886+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:42:12.873+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:42:12.887+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:42:12.936+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.175 seconds
[2026-01-11T09:42:44.082+0000] {processor.py:161} INFO - Started process (PID=320) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:42:44.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:42:44.086+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:42:44.086+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:42:44.117+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:42:44.117+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:42:44.118+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:42:44.118+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:42:44.118+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:42:44.118+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:42:44.122+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:42:44.122+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:42:44.124+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:42:44.124+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:42:44.126+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:42:44.126+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:42:44.127+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:42:44.126+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:42:44.131+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:42:44.127+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:42:44.132+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:42:44.172+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.096 seconds
[2026-01-11T09:43:00.687+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:43:00.690+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:43:00.699+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:43:00.697+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:43:00.883+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:43:00.882+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:43:00.885+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:43:00.884+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:43:00.886+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:43:00.886+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:43:00.893+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:43:00.892+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:43:00.901+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:43:00.900+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:43:00.906+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:43:00.905+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:43:00.907+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:43:00.907+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:43:00.924+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:43:00.908+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:43:00.928+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:43:01.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.345 seconds
[2026-01-11T09:43:31.969+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:43:31.971+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:43:31.974+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:43:31.973+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:43:32.018+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:43:32.017+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:43:32.018+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:43:32.018+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:43:32.019+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:43:32.019+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:43:32.024+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:43:32.024+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:43:32.027+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:43:32.027+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:43:32.030+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:43:32.030+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:43:32.030+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:43:32.030+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:43:32.035+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:43:32.031+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:43:32.036+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:43:32.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.108 seconds
[2026-01-11T09:44:02.747+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:44:02.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:44:02.751+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:44:02.750+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:44:02.792+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:44:02.792+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:44:02.793+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:44:02.793+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:44:02.794+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:44:02.794+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:44:02.798+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:44:02.798+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:44:02.800+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:44:02.800+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:44:02.803+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:44:02.802+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:44:02.803+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:44:02.803+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:44:02.809+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:44:02.803+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:44:02.810+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:44:02.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.115 seconds
[2026-01-11T09:44:33.784+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:44:33.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:44:33.789+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:44:33.789+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:44:33.818+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:44:33.818+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:44:33.819+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:44:33.819+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:44:33.820+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:44:33.820+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:44:33.824+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:44:33.824+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:44:33.826+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:44:33.826+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:44:33.828+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:44:33.828+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:44:33.829+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:44:33.829+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:44:33.835+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:44:33.829+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:44:33.836+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:44:33.877+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.099 seconds
[2026-01-11T09:45:04.616+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:45:04.618+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:45:04.620+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:45:04.620+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:45:04.676+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:45:04.675+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:45:04.677+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:45:04.677+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:45:04.678+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:45:04.678+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:45:04.683+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:45:04.682+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:45:04.685+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:45:04.685+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:45:04.688+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:45:04.687+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:45:04.688+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:45:04.688+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:45:04.695+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:45:04.689+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:45:04.696+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:45:04.755+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.146 seconds
[2026-01-11T09:45:35.417+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:45:35.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:45:35.422+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:45:35.421+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:45:35.467+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:45:35.467+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:45:35.468+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:45:35.468+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:45:35.469+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:45:35.469+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:45:35.473+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:45:35.472+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:45:35.477+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:45:35.477+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:45:35.481+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:45:35.480+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:45:35.482+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:45:35.481+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:45:35.491+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:45:35.482+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:45:35.493+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:45:35.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.135 seconds
[2026-01-11T09:46:06.161+0000] {processor.py:161} INFO - Started process (PID=104) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:46:06.162+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:46:06.165+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:46:06.165+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:46:06.194+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:46:06.194+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:46:06.195+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:46:06.195+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:46:06.196+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:46:06.195+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:46:06.198+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:46:06.198+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:46:06.201+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:46:06.200+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:46:06.202+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:46:06.202+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:46:06.203+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:46:06.203+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:46:06.209+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:46:06.203+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:46:06.209+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:46:06.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.093 seconds
[2026-01-11T09:46:37.205+0000] {processor.py:161} INFO - Started process (PID=111) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:46:37.206+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:46:37.208+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:46:37.208+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:46:37.242+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:46:37.241+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:46:37.242+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:46:37.242+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:46:37.243+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:46:37.243+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:46:37.247+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:46:37.246+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:46:37.249+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:46:37.249+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:46:37.252+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:46:37.251+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:46:37.252+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:46:37.252+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:46:37.258+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:46:37.253+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:46:37.259+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:46:37.337+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.138 seconds
[2026-01-11T09:47:08.052+0000] {processor.py:161} INFO - Started process (PID=119) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:47:08.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:47:08.055+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:47:08.055+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:47:08.081+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:47:08.081+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:47:08.082+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:47:08.082+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:47:08.082+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:47:08.082+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:47:08.085+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:47:08.085+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:47:08.087+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:47:08.087+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:47:08.089+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:47:08.089+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:47:08.090+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:47:08.090+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:47:08.094+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:47:08.090+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:47:08.094+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:47:08.127+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.080 seconds
[2026-01-11T09:47:38.918+0000] {processor.py:161} INFO - Started process (PID=127) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:47:38.919+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:47:38.922+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:47:38.921+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:47:38.946+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:47:38.945+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:47:38.947+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:47:38.946+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:47:38.947+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:47:38.947+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:47:38.950+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:47:38.950+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:47:38.952+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:47:38.952+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:47:38.954+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:47:38.954+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:47:38.954+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:47:38.954+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:47:38.958+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:47:38.955+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:47:38.959+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:47:38.993+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.080 seconds
[2026-01-11T09:48:09.687+0000] {processor.py:161} INFO - Started process (PID=135) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:48:09.689+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:48:09.691+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:48:09.690+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:48:09.723+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:48:09.723+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:48:09.724+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:48:09.724+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:48:09.725+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:48:09.725+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:48:09.728+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:48:09.728+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:48:09.730+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:48:09.730+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:48:09.732+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:48:09.732+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:48:09.732+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:48:09.732+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:48:09.737+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:48:09.733+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:48:09.737+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:48:09.772+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.092 seconds
[2026-01-11T09:48:40.552+0000] {processor.py:161} INFO - Started process (PID=143) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:48:40.554+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:48:40.556+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:48:40.555+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:48:40.595+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:48:40.595+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:48:40.596+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:48:40.596+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:48:40.597+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:48:40.597+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:48:40.602+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:48:40.601+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:48:40.604+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:48:40.604+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:48:40.607+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:48:40.607+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:48:40.608+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:48:40.608+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:48:40.615+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:48:40.609+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:48:40.616+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:48:40.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.124 seconds
[2026-01-11T09:49:11.206+0000] {processor.py:161} INFO - Started process (PID=151) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:49:11.208+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:49:11.210+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:49:11.210+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:49:11.243+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:49:11.243+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:49:11.244+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:49:11.244+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:49:11.245+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:49:11.245+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:49:11.249+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:49:11.248+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:49:11.251+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:49:11.251+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:49:11.254+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:49:11.254+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:49:11.254+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:49:11.254+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:49:11.261+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:49:11.255+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:49:11.261+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:49:11.303+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.102 seconds
[2026-01-11T09:49:42.036+0000] {processor.py:161} INFO - Started process (PID=159) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:49:42.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:49:42.039+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:49:42.039+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:49:42.070+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:49:42.070+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:49:42.071+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:49:42.071+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:49:42.072+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:49:42.071+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:49:42.076+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:49:42.076+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:49:42.079+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:49:42.079+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:49:42.081+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:49:42.081+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:49:42.081+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:49:42.081+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:49:42.086+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:49:42.082+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:49:42.087+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:49:42.129+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.098 seconds
[2026-01-11T09:50:12.888+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:50:12.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:50:12.891+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:50:12.891+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:50:12.917+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:50:12.917+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:50:12.918+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:50:12.918+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:50:12.919+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:50:12.919+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:50:12.922+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:50:12.922+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:50:12.924+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:50:12.924+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:50:12.926+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:50:12.926+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:50:12.927+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:50:12.926+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:50:12.931+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:50:12.927+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:50:12.931+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:50:12.964+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.082 seconds
[2026-01-11T09:50:43.574+0000] {processor.py:161} INFO - Started process (PID=175) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:50:43.575+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:50:43.577+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:50:43.577+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:50:43.609+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:50:43.609+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:50:43.610+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:50:43.610+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:50:43.611+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:50:43.611+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:50:43.614+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:50:43.614+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:50:43.616+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:50:43.616+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:50:43.618+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:50:43.618+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:50:43.619+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:50:43.618+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:50:43.623+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:50:43.619+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:50:43.623+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:50:43.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.090 seconds
[2026-01-11T09:51:14.296+0000] {processor.py:161} INFO - Started process (PID=183) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:51:14.297+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:51:14.299+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:51:14.299+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:51:14.326+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:51:14.326+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:51:14.327+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:51:14.326+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:51:14.328+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:51:14.328+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:51:14.331+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:51:14.331+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:51:14.335+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:51:14.335+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:51:14.337+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:51:14.336+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:51:14.337+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:51:14.337+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:51:14.341+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:51:14.337+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:51:14.342+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:51:14.376+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.085 seconds
[2026-01-11T09:51:45.080+0000] {processor.py:161} INFO - Started process (PID=191) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:51:45.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:51:45.084+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:51:45.083+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:51:45.121+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:51:45.121+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:51:45.122+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:51:45.122+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:51:45.123+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:51:45.123+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:51:45.126+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:51:45.126+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:51:45.130+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:51:45.130+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:51:45.133+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:51:45.133+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:51:45.134+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:51:45.133+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:51:45.140+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:51:45.134+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:51:45.141+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:51:45.193+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.118 seconds
[2026-01-11T09:52:15.914+0000] {processor.py:161} INFO - Started process (PID=199) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:52:15.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:52:15.919+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:52:15.919+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:52:15.964+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:52:15.963+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:52:15.966+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:52:15.965+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:52:15.968+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:52:15.967+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:52:15.974+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:52:15.974+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:52:15.978+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:52:15.977+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:52:15.980+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:52:15.980+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:52:15.982+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:52:15.981+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:52:15.989+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:52:15.983+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:52:15.989+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:52:16.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.125 seconds
[2026-01-11T09:52:46.770+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:52:46.772+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:52:46.775+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:52:46.774+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:52:46.806+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:52:46.806+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:52:46.807+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:52:46.807+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:52:46.807+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:52:46.807+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:52:46.813+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:52:46.813+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:52:46.817+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:52:46.817+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:52:46.820+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:52:46.820+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:52:46.820+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:52:46.820+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:52:46.825+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:52:46.821+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:52:46.825+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:52:46.869+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.106 seconds
[2026-01-11T09:53:17.685+0000] {processor.py:161} INFO - Started process (PID=215) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:53:17.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:53:17.689+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:53:17.688+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:53:17.722+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:53:17.721+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:53:17.723+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:53:17.723+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:53:17.724+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:53:17.724+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:53:17.728+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:53:17.727+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:53:17.730+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:53:17.730+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:53:17.732+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:53:17.732+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:53:17.733+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:53:17.733+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:53:17.738+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:53:17.733+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:53:17.739+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:53:17.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.097 seconds
[2026-01-11T09:53:48.021+0000] {processor.py:161} INFO - Started process (PID=225) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:53:48.023+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:53:48.025+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:53:48.025+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:53:48.060+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:53:48.060+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:53:48.060+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:53:48.060+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:53:48.061+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:53:48.061+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:53:48.065+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:53:48.064+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:53:48.068+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:53:48.068+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:53:48.070+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:53:48.070+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:53:48.070+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:53:48.070+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:53:48.075+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:53:48.071+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:53:48.075+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:53:48.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.092 seconds
[2026-01-11T09:54:18.353+0000] {processor.py:161} INFO - Started process (PID=233) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:54:18.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:54:18.357+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:54:18.356+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:54:18.386+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:54:18.386+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:54:18.387+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:54:18.387+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:54:18.388+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:54:18.388+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:54:18.392+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:54:18.392+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:54:18.394+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:54:18.394+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:54:18.397+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:54:18.397+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:54:18.398+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:54:18.398+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:54:18.404+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:54:18.398+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:54:18.405+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:54:18.452+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.105 seconds
[2026-01-11T09:54:49.020+0000] {processor.py:161} INFO - Started process (PID=241) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:54:49.022+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:54:49.025+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:54:49.024+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:54:49.071+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:54:49.071+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:54:49.072+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:54:49.072+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:54:49.073+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:54:49.073+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:54:49.078+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:54:49.078+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:54:49.082+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:54:49.081+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:54:49.085+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:54:49.085+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:54:49.086+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:54:49.086+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:54:49.093+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:54:49.087+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:54:49.094+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:54:49.159+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.148 seconds
[2026-01-11T09:55:19.773+0000] {processor.py:161} INFO - Started process (PID=249) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:55:19.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:55:19.776+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:55:19.775+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:55:19.813+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:55:19.813+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:55:19.814+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:55:19.814+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:55:19.815+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:55:19.815+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:55:19.819+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:55:19.818+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:55:19.821+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:55:19.821+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:55:19.823+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:55:19.823+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:55:19.825+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:55:19.824+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:55:19.831+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:55:19.825+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:55:19.832+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:55:19.874+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.107 seconds
[2026-01-11T09:55:50.577+0000] {processor.py:161} INFO - Started process (PID=257) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:55:50.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:55:50.581+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:55:50.581+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:55:50.613+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:55:50.613+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:55:50.614+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:55:50.613+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:55:50.614+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:55:50.614+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:55:50.618+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:55:50.618+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:55:50.620+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:55:50.620+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:55:50.622+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:55:50.622+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:55:50.623+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:55:50.623+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:55:50.627+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:55:50.623+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:55:50.628+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:55:50.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.090 seconds
[2026-01-11T09:56:21.435+0000] {processor.py:161} INFO - Started process (PID=267) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:56:21.436+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:56:21.438+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:56:21.438+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:56:21.467+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:56:21.467+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:56:21.468+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:56:21.467+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:56:21.468+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:56:21.468+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:56:21.473+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:56:21.472+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:56:21.475+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:56:21.475+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:56:21.477+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:56:21.477+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:56:21.478+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:56:21.477+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:56:21.481+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:56:21.478+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:56:21.482+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:56:21.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.086 seconds
[2026-01-11T09:56:51.839+0000] {processor.py:161} INFO - Started process (PID=277) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:56:51.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:56:51.842+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:56:51.842+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:56:51.869+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:56:51.868+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:56:51.869+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:56:51.869+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:56:51.870+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:56:51.870+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:56:51.873+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:56:51.873+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:56:51.875+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:56:51.875+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:56:51.878+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:56:51.878+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:56:51.879+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:56:51.879+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:56:51.882+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:56:51.879+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:56:51.883+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:56:51.915+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.081 seconds
[2026-01-11T09:57:22.662+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:57:22.663+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:57:22.665+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:57:22.665+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:57:22.704+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:57:22.703+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:57:22.705+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:57:22.704+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:57:22.706+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:57:22.705+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:57:22.710+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:57:22.710+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:57:22.713+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:57:22.713+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:57:22.716+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:57:22.715+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:57:22.716+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:57:22.716+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:57:22.723+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:57:22.717+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:57:22.724+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:57:22.780+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.125 seconds
[2026-01-11T09:57:53.553+0000] {processor.py:161} INFO - Started process (PID=294) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:57:53.554+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:57:53.556+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:57:53.556+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:57:53.586+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:57:53.586+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:57:53.587+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:57:53.587+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:57:53.587+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:57:53.587+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:57:53.590+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:57:53.590+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:57:53.592+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:57:53.592+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:57:53.595+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:57:53.595+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:57:53.596+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:57:53.596+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:57:53.601+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:57:53.596+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:57:53.601+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:57:53.636+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.089 seconds
[2026-01-11T09:58:24.412+0000] {processor.py:161} INFO - Started process (PID=303) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:58:24.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:58:24.415+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:58:24.414+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:58:24.441+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:58:24.440+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:58:24.442+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:58:24.441+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:58:24.442+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:58:24.442+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:58:24.447+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:58:24.447+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:58:24.449+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:58:24.449+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:58:24.451+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:58:24.451+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:58:24.451+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:58:24.451+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:58:24.456+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:58:24.452+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:58:24.457+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:58:24.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.090 seconds
[2026-01-11T09:58:55.378+0000] {processor.py:161} INFO - Started process (PID=312) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:58:55.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:58:55.382+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:58:55.381+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:58:55.428+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:58:55.428+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:58:55.429+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:58:55.429+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:58:55.430+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:58:55.430+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:58:55.435+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:58:55.434+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:58:55.444+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:58:55.444+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:58:55.447+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:58:55.446+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:58:55.447+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:58:55.447+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:58:55.454+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:58:55.448+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:58:55.456+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:58:55.517+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.145 seconds
[2026-01-11T09:59:26.312+0000] {processor.py:161} INFO - Started process (PID=322) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:59:26.313+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:59:26.315+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:59:26.315+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:59:26.344+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:59:26.344+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:59:26.345+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:59:26.344+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:59:26.345+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:59:26.345+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:59:26.348+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:59:26.348+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:59:26.351+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:59:26.350+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:59:26.352+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:59:26.352+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:59:26.353+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:59:26.353+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:59:26.357+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:59:26.353+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:59:26.358+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:59:26.391+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.084 seconds
[2026-01-11T09:59:58.717+0000] {processor.py:161} INFO - Started process (PID=332) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:59:58.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T09:59:58.720+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:59:58.720+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:59:58.749+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:59:58.748+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T09:59:58.749+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:59:58.749+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T09:59:58.750+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:59:58.750+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T09:59:58.753+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:59:58.753+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:59:58.755+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:59:58.755+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:59:58.757+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:59:58.757+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T09:59:58.757+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:59:58.757+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T09:59:58.762+0000] {logging_mixin.py:188} INFO - [2026-01-11T09:59:58.758+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T09:59:58.763+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T09:59:58.816+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.104 seconds
[2026-01-11T10:00:29.473+0000] {processor.py:161} INFO - Started process (PID=341) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:00:29.474+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:00:29.476+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:00:29.476+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:00:29.505+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:00:29.505+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:00:29.506+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:00:29.506+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:00:29.507+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:00:29.507+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:00:29.510+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:00:29.510+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:00:29.512+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:00:29.512+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:00:29.514+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:00:29.514+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:00:29.514+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:00:29.514+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:00:29.519+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:00:29.515+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:00:29.519+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:00:29.561+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.093 seconds
[2026-01-11T10:00:59.942+0000] {processor.py:161} INFO - Started process (PID=351) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:00:59.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:00:59.946+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:00:59.946+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:00:59.991+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:00:59.991+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:00:59.993+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:00:59.993+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:00:59.994+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:00:59.994+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:00:59.998+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:00:59.998+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:01:00.002+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:01:00.002+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:01:00.006+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:01:00.006+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:01:00.007+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:01:00.007+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:01:00.017+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:01:00.008+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:01:00.018+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:01:00.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.139 seconds
[2026-01-11T10:01:30.808+0000] {processor.py:161} INFO - Started process (PID=360) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:01:30.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:01:30.811+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:01:30.811+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:01:30.847+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:01:30.847+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:01:30.848+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:01:30.847+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:01:30.848+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:01:30.848+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:01:30.852+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:01:30.851+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:01:30.854+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:01:30.853+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:01:30.855+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:01:30.855+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:01:30.856+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:01:30.856+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:01:30.860+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:01:30.856+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:01:30.861+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:01:30.893+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.091 seconds
[2026-01-11T10:02:01.497+0000] {processor.py:161} INFO - Started process (PID=369) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:02:01.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:02:01.501+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:02:01.501+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:02:01.532+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:02:01.531+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:02:01.532+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:02:01.532+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:02:01.533+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:02:01.533+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:02:01.537+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:02:01.536+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:02:01.539+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:02:01.539+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:02:01.541+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:02:01.541+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:02:01.541+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:02:01.541+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:02:01.546+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:02:01.542+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:02:01.546+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:02:01.586+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.096 seconds
[2026-01-11T10:02:32.267+0000] {processor.py:161} INFO - Started process (PID=378) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:02:32.270+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:02:32.276+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:02:32.275+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:02:32.374+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:02:32.374+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:02:32.376+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:02:32.376+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:02:32.378+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:02:32.378+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:02:32.385+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:02:32.385+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:02:32.391+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:02:32.390+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:02:32.397+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:02:32.396+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:02:32.399+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:02:32.398+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:02:32.416+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:02:32.400+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:02:32.418+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:02:32.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.275 seconds
[2026-01-11T10:03:03.026+0000] {processor.py:161} INFO - Started process (PID=388) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:03:03.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:03:03.030+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:03:03.030+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:03:03.118+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:03:03.118+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:03:03.121+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:03:03.120+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:03:03.123+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:03:03.123+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:03:03.132+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:03:03.131+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:03:03.138+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:03:03.138+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:03:03.144+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:03:03.144+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:03:03.146+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:03:03.145+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:03:03.159+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:03:03.147+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:03:03.160+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:03:03.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.234 seconds
[2026-01-11T10:03:33.784+0000] {processor.py:161} INFO - Started process (PID=398) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:03:33.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:03:33.790+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:03:33.789+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:03:33.858+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:03:33.857+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:03:33.860+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:03:33.860+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:03:33.861+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:03:33.861+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:03:33.870+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:03:33.869+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:03:33.875+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:03:33.874+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:03:33.882+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:03:33.882+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:03:33.884+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:03:33.883+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:03:33.897+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:03:33.884+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:03:33.899+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:03:33.985+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.209 seconds
[2026-01-11T10:04:04.766+0000] {processor.py:161} INFO - Started process (PID=407) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:04:04.770+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:04:04.774+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:04:04.774+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:04:04.846+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:04:04.846+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:04:04.847+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:04:04.847+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:04:04.849+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:04:04.848+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:04:04.861+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:04:04.860+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:04:04.866+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:04:04.866+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:04:04.874+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:04:04.873+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:04:04.876+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:04:04.875+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:04:04.888+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:04:04.876+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:04:04.889+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:04:04.979+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.222 seconds
[2026-01-11T10:04:35.591+0000] {processor.py:161} INFO - Started process (PID=418) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:04:35.593+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:04:35.597+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:04:35.596+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:04:35.682+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:04:35.681+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:04:35.684+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:04:35.683+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:04:35.685+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:04:35.685+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:04:35.693+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:04:35.692+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:04:35.698+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:04:35.697+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:04:35.703+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:04:35.702+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:04:35.704+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:04:35.704+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:04:35.719+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:04:35.706+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:04:35.721+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:04:35.814+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.233 seconds
[2026-01-11T10:05:06.379+0000] {processor.py:161} INFO - Started process (PID=429) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:05:06.382+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:05:06.386+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:05:06.385+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:05:06.466+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:05:06.466+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:05:06.468+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:05:06.467+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:05:06.469+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:05:06.469+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:05:06.476+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:05:06.476+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:05:06.481+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:05:06.481+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:05:06.486+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:05:06.486+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:05:06.489+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:05:06.488+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:05:06.503+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:05:06.490+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:05:06.505+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:05:06.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.228 seconds
[2026-01-11T10:05:37.569+0000] {processor.py:161} INFO - Started process (PID=439) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:05:37.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:05:37.574+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:05:37.574+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:05:37.641+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:05:37.640+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:05:37.642+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:05:37.642+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:05:37.643+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:05:37.643+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:05:37.652+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:05:37.651+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:05:37.656+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:05:37.656+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:05:37.664+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:05:37.664+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:05:37.666+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:05:37.666+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:05:37.681+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:05:37.667+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:05:37.682+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:05:37.784+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.230 seconds
[2026-01-11T10:06:08.342+0000] {processor.py:161} INFO - Started process (PID=448) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:06:08.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:06:08.348+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:06:08.347+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:06:08.421+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:06:08.421+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:06:08.424+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:06:08.423+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:06:08.426+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:06:08.425+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:06:08.435+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:06:08.435+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:06:08.443+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:06:08.443+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:06:08.450+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:06:08.449+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:06:08.451+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:06:08.451+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:06:08.475+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:06:08.452+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:06:08.477+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:06:08.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.283 seconds
[2026-01-11T10:06:38.911+0000] {processor.py:161} INFO - Started process (PID=457) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:06:38.914+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:06:38.918+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:06:38.917+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:06:39.001+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:06:39.000+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:06:39.003+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:06:39.002+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:06:39.005+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:06:39.004+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:06:39.012+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:06:39.011+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:06:39.017+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:06:39.017+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:06:39.024+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:06:39.024+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:06:39.026+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:06:39.025+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:06:39.039+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:06:39.026+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:06:39.040+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:06:39.139+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.241 seconds
[2026-01-11T10:07:09.946+0000] {processor.py:161} INFO - Started process (PID=466) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:07:09.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:07:09.954+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:07:09.952+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:07:10.051+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:07:10.051+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:07:10.053+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:07:10.052+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:07:10.055+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:07:10.054+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:07:10.063+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:07:10.062+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:07:10.069+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:07:10.068+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:07:10.077+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:07:10.076+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:07:10.079+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:07:10.078+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:07:10.099+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:07:10.080+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:07:10.101+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:07:10.205+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.267 seconds
[2026-01-11T10:07:41.560+0000] {processor.py:161} INFO - Started process (PID=475) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:07:41.562+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:07:41.568+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:07:41.567+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:07:41.656+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:07:41.655+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:07:41.657+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:07:41.657+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:07:41.659+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:07:41.659+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:07:41.666+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:07:41.666+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:07:41.672+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:07:41.672+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:07:41.677+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:07:41.677+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:07:41.678+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:07:41.678+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:07:41.691+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:07:41.679+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:07:41.693+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:07:41.815+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.270 seconds
[2026-01-11T10:08:12.055+0000] {processor.py:161} INFO - Started process (PID=484) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:08:12.058+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:08:12.061+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:08:12.061+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:08:12.131+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:08:12.131+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:08:12.132+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:08:12.132+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:08:12.134+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:08:12.134+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:08:12.140+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:08:12.140+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:08:12.145+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:08:12.145+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:08:12.151+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:08:12.150+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:08:12.152+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:08:12.152+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:08:12.164+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:08:12.152+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:08:12.165+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:08:12.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.205 seconds
[2026-01-11T10:08:43.878+0000] {processor.py:161} INFO - Started process (PID=494) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:08:43.881+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:08:43.885+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:08:43.884+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:08:43.962+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:08:43.961+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:08:43.964+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:08:43.963+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:08:43.965+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:08:43.965+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:08:43.974+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:08:43.974+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:08:43.979+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:08:43.979+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:08:43.985+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:08:43.984+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:08:43.986+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:08:43.986+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:08:43.999+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:08:43.987+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:08:44.000+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:08:44.084+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.218 seconds
[2026-01-11T10:09:14.957+0000] {processor.py:161} INFO - Started process (PID=505) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:09:14.959+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:09:14.962+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:09:14.962+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:09:15.040+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:09:15.039+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:09:15.041+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:09:15.041+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:09:15.042+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:09:15.042+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:09:15.049+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:09:15.048+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:09:15.055+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:09:15.054+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:09:15.060+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:09:15.059+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:09:15.061+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:09:15.061+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:09:15.076+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:09:15.062+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:09:15.077+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:09:15.173+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.230 seconds
[2026-01-11T10:09:46.090+0000] {processor.py:161} INFO - Started process (PID=514) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:09:46.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:09:46.101+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:09:46.101+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:09:46.182+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:09:46.182+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:09:46.184+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:09:46.184+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:09:46.185+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:09:46.185+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:09:46.191+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:09:46.191+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:09:46.196+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:09:46.196+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:09:46.201+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:09:46.201+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:09:46.202+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:09:46.202+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:09:46.215+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:09:46.203+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:09:46.216+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:09:46.304+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.228 seconds
[2026-01-11T10:10:16.965+0000] {processor.py:161} INFO - Started process (PID=523) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:10:16.967+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:10:16.972+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:10:16.971+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:10:17.047+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:10:17.046+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:10:17.048+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:10:17.048+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:10:17.049+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:10:17.049+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:10:17.056+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:10:17.056+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:10:17.061+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:10:17.061+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:10:17.068+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:10:17.067+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:10:17.069+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:10:17.069+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:10:17.082+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:10:17.070+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:10:17.083+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:10:17.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.220 seconds
[2026-01-11T10:10:47.979+0000] {processor.py:161} INFO - Started process (PID=532) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:10:47.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:10:47.988+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:10:47.987+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:10:48.196+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:10:48.194+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:10:48.198+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:10:48.198+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:10:48.200+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:10:48.200+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:10:48.219+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:10:48.218+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:10:48.235+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:10:48.234+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:10:48.252+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:10:48.251+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:10:48.259+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:10:48.258+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:10:48.279+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:10:48.260+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:10:48.281+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:10:48.425+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.466 seconds
[2026-01-11T10:11:18.929+0000] {processor.py:161} INFO - Started process (PID=541) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:11:18.931+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:11:18.935+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:11:18.935+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:11:19.037+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:11:19.037+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:11:19.039+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:11:19.038+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:11:19.041+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:11:19.040+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:11:19.050+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:11:19.049+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:11:19.059+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:11:19.059+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:11:19.067+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:11:19.066+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:11:19.069+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:11:19.068+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:11:19.084+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:11:19.070+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:11:19.086+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:11:19.205+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.284 seconds
[2026-01-11T10:11:50.288+0000] {processor.py:161} INFO - Started process (PID=550) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:11:50.291+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:11:50.296+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:11:50.295+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:11:50.401+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:11:50.400+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:11:50.405+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:11:50.402+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:11:50.407+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:11:50.407+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:11:50.417+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:11:50.416+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:11:50.425+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:11:50.424+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:11:50.441+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:11:50.440+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:11:50.442+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:11:50.442+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:11:50.457+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:11:50.443+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:11:50.459+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:11:50.564+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.298 seconds
[2026-01-11T10:12:21.043+0000] {processor.py:161} INFO - Started process (PID=559) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:12:21.045+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:12:21.050+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:12:21.049+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:12:21.143+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:12:21.143+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:12:21.144+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:12:21.144+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:12:21.145+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:12:21.145+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:12:21.153+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:12:21.153+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:12:21.160+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:12:21.159+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:12:21.165+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:12:21.165+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:12:21.167+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:12:21.166+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:12:21.181+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:12:21.168+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:12:21.182+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:12:21.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.237 seconds
[2026-01-11T10:12:52.177+0000] {processor.py:161} INFO - Started process (PID=568) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:12:52.179+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:12:52.183+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:12:52.182+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:12:52.269+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:12:52.269+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:12:52.271+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:12:52.271+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:12:52.274+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:12:52.274+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:12:52.281+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:12:52.281+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:12:52.288+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:12:52.288+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:12:52.295+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:12:52.294+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:12:52.295+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:12:52.295+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:12:52.308+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:12:52.296+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:12:52.310+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:12:52.395+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.229 seconds
[2026-01-11T10:13:23.168+0000] {processor.py:161} INFO - Started process (PID=577) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:13:23.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:13:23.177+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:13:23.176+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:13:23.246+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:13:23.246+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:13:23.248+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:13:23.247+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:13:23.249+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:13:23.249+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:13:23.257+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:13:23.256+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:13:23.263+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:13:23.262+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:13:23.268+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:13:23.267+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:13:23.269+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:13:23.269+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:13:23.282+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:13:23.270+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:13:23.283+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:13:23.377+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.216 seconds
[2026-01-11T10:13:53.961+0000] {processor.py:161} INFO - Started process (PID=586) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:13:53.963+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:13:53.967+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:13:53.967+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:13:54.067+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:13:54.066+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:13:54.069+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:13:54.068+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:13:54.076+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:13:54.076+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:13:54.084+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:13:54.083+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:13:54.091+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:13:54.090+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:13:54.097+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:13:54.096+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:13:54.098+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:13:54.098+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:13:54.113+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:13:54.099+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:13:54.114+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:13:54.205+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.260 seconds
[2026-01-11T10:14:24.662+0000] {processor.py:161} INFO - Started process (PID=595) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:14:24.663+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:14:24.667+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:14:24.666+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:14:24.742+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:14:24.741+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:14:24.743+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:14:24.743+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:14:24.744+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:14:24.744+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:14:24.752+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:14:24.752+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:14:24.758+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:14:24.757+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:14:24.763+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:14:24.762+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:14:24.764+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:14:24.763+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:14:24.777+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:14:24.765+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:14:24.778+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:14:24.870+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.220 seconds
[2026-01-11T10:14:55.617+0000] {processor.py:161} INFO - Started process (PID=604) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:14:55.623+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:14:55.628+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:14:55.627+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:14:55.707+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:14:55.706+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:14:55.709+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:14:55.708+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:14:55.710+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:14:55.710+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:14:55.717+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:14:55.716+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:14:55.724+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:14:55.723+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:14:55.729+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:14:55.729+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:14:55.731+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:14:55.730+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:14:55.745+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:14:55.732+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:14:55.746+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:14:55.843+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.236 seconds
[2026-01-11T10:15:26.355+0000] {processor.py:161} INFO - Started process (PID=613) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:15:26.417+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:15:26.423+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:15:26.422+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:15:26.520+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:15:26.519+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:15:26.521+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:15:26.521+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:15:26.522+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:15:26.522+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:15:26.528+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:15:26.528+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:15:26.533+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:15:26.533+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:15:26.540+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:15:26.540+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:15:26.542+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:15:26.542+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:15:26.554+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:15:26.543+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:15:26.556+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:15:26.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.327 seconds
[2026-01-11T10:15:57.175+0000] {processor.py:161} INFO - Started process (PID=622) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:15:57.179+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:15:57.184+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:15:57.184+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:15:57.291+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:15:57.290+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:15:57.293+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:15:57.292+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:15:57.295+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:15:57.294+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:15:57.303+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:15:57.302+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:15:57.312+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:15:57.311+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:15:57.319+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:15:57.319+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:15:57.323+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:15:57.322+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:15:57.342+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:15:57.325+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:15:57.343+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:15:57.460+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.297 seconds
[2026-01-11T10:16:28.159+0000] {processor.py:161} INFO - Started process (PID=631) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:16:28.161+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:16:28.164+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:16:28.163+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:16:28.241+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:16:28.240+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:16:28.243+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:16:28.242+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:16:28.244+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:16:28.244+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:16:28.252+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:16:28.252+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:16:28.259+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:16:28.258+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:16:28.263+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:16:28.263+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:16:28.264+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:16:28.264+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:16:28.278+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:16:28.265+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:16:28.279+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:16:28.374+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.226 seconds
[2026-01-11T10:16:59.166+0000] {processor.py:161} INFO - Started process (PID=640) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:16:59.168+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:16:59.173+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:16:59.172+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:16:59.239+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:16:59.238+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:16:59.241+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:16:59.240+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:16:59.243+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:16:59.242+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:16:59.250+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:16:59.249+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:16:59.255+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:16:59.255+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:16:59.261+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:16:59.260+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:16:59.262+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:16:59.262+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:16:59.274+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:16:59.263+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:16:59.276+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:16:59.370+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.211 seconds
[2026-01-11T10:17:30.065+0000] {processor.py:161} INFO - Started process (PID=649) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:17:30.069+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:17:30.073+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:17:30.072+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:17:30.135+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:17:30.134+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:17:30.136+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:17:30.136+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:17:30.138+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:17:30.138+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:17:30.145+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:17:30.145+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:17:30.151+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:17:30.151+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:17:30.157+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:17:30.156+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:17:30.158+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:17:30.158+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:17:30.172+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:17:30.159+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:17:30.174+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:17:30.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.221 seconds
[2026-01-11T10:18:00.981+0000] {processor.py:161} INFO - Started process (PID=658) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:18:00.984+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:18:00.990+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:18:00.989+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:18:01.061+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:18:01.060+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:18:01.062+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:18:01.062+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:18:01.063+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:18:01.063+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:18:01.070+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:18:01.069+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:18:01.076+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:18:01.075+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:18:01.081+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:18:01.081+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:18:01.082+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:18:01.082+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:18:01.097+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:18:01.085+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:18:01.098+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:18:01.185+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.214 seconds
[2026-01-11T10:18:31.741+0000] {processor.py:161} INFO - Started process (PID=667) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:18:31.744+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:18:31.749+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:18:31.748+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:18:31.858+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:18:31.858+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:18:31.859+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:18:31.859+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:18:31.861+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:18:31.861+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:18:31.869+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:18:31.869+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:18:31.873+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:18:31.873+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:18:31.878+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:18:31.877+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:18:31.879+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:18:31.878+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:18:31.890+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:18:31.879+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:18:31.892+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:18:31.976+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.248 seconds
[2026-01-11T10:19:02.135+0000] {processor.py:161} INFO - Started process (PID=676) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:19:02.138+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:19:02.144+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:19:02.143+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:19:02.256+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:19:02.255+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:19:02.259+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:19:02.258+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:19:02.261+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:19:02.261+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:19:02.269+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:19:02.269+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:19:02.276+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:19:02.275+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:19:02.282+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:19:02.282+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:19:02.284+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:19:02.284+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:19:02.303+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:19:02.285+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:19:02.305+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:19:02.433+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.313 seconds
[2026-01-11T10:19:32.949+0000] {processor.py:161} INFO - Started process (PID=685) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:19:32.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:19:32.955+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:19:32.954+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:19:33.075+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:19:33.074+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:19:33.077+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:19:33.076+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:19:33.079+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:19:33.079+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:19:33.087+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:19:33.086+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:19:33.093+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:19:33.093+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:19:33.100+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:19:33.100+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:19:33.101+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:19:33.101+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:19:33.118+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:19:33.103+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:19:33.120+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:19:33.230+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.293 seconds
[2026-01-11T10:20:04.210+0000] {processor.py:161} INFO - Started process (PID=694) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:20:04.213+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:20:04.218+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:20:04.217+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:20:04.321+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:20:04.320+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:20:04.323+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:20:04.323+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:20:04.325+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:20:04.325+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:20:04.335+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:20:04.334+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:20:04.341+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:20:04.341+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:20:04.347+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:20:04.347+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:20:04.348+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:20:04.348+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:20:04.363+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:20:04.349+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:20:04.364+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:20:04.451+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.257 seconds
[2026-01-11T10:20:34.889+0000] {processor.py:161} INFO - Started process (PID=703) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:20:34.891+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:20:34.895+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:20:34.894+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:20:34.980+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:20:34.979+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:20:34.981+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:20:34.981+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:20:34.983+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:20:34.983+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:20:34.990+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:20:34.990+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:20:34.996+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:20:34.995+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:20:35.002+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:20:35.002+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:20:35.004+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:20:35.004+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:20:35.019+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:20:35.005+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:20:35.021+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:20:35.116+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.238 seconds
[2026-01-11T10:21:05.672+0000] {processor.py:161} INFO - Started process (PID=712) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:21:05.676+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:21:05.686+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:21:05.684+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:21:05.820+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:21:05.819+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:21:05.823+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:21:05.822+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:21:05.825+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:21:05.825+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:21:05.836+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:21:05.836+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:21:05.843+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:21:05.842+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:21:05.852+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:21:05.851+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:21:05.854+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:21:05.853+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:21:05.875+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:21:05.855+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:21:05.877+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:21:05.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.347 seconds
[2026-01-11T10:21:36.871+0000] {processor.py:161} INFO - Started process (PID=721) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:21:36.874+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:21:36.879+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:21:36.878+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:21:36.966+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:21:36.966+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:21:36.967+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:21:36.967+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:21:36.969+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:21:36.969+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:21:36.976+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:21:36.975+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:21:36.981+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:21:36.980+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:21:36.986+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:21:36.986+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:21:36.987+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:21:36.987+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:21:37.001+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:21:36.988+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:21:37.002+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:21:37.097+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.238 seconds
[2026-01-11T10:22:08.079+0000] {processor.py:161} INFO - Started process (PID=730) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:22:08.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:22:08.085+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:22:08.085+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:22:08.179+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:22:08.179+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:22:08.181+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:22:08.181+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:22:08.183+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:22:08.182+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:22:08.191+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:22:08.191+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:22:08.197+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:22:08.197+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:22:08.204+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:22:08.203+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:22:08.205+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:22:08.205+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:22:08.222+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:22:08.207+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:22:08.223+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:22:08.330+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.258 seconds
[2026-01-11T10:22:38.725+0000] {processor.py:161} INFO - Started process (PID=739) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:22:38.728+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:22:38.731+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:22:38.730+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:22:38.819+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:22:38.819+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:22:38.821+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:22:38.820+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:22:38.822+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:22:38.822+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:22:38.828+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:22:38.828+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:22:38.833+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:22:38.833+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:22:38.838+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:22:38.838+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:22:38.839+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:22:38.839+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:22:38.853+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:22:38.840+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:22:38.854+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:22:38.951+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.233 seconds
[2026-01-11T10:23:09.135+0000] {processor.py:161} INFO - Started process (PID=748) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:23:09.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:23:09.142+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:23:09.141+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:23:09.207+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:23:09.206+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:23:09.209+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:23:09.208+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:23:09.210+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:23:09.210+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:23:09.218+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:23:09.218+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:23:09.225+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:23:09.224+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:23:09.232+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:23:09.232+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:23:09.234+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:23:09.234+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:23:09.248+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:23:09.235+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:23:09.250+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:23:09.345+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.217 seconds
[2026-01-11T10:23:40.362+0000] {processor.py:161} INFO - Started process (PID=757) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:23:40.364+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:23:40.367+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:23:40.367+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:23:40.429+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:23:40.429+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:23:40.431+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:23:40.430+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:23:40.432+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:23:40.432+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:23:40.439+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:23:40.438+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:23:40.444+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:23:40.443+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:23:40.449+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:23:40.449+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:23:40.451+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:23:40.450+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:23:40.463+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:23:40.451+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:23:40.464+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:23:40.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.192 seconds
[2026-01-11T10:24:11.606+0000] {processor.py:161} INFO - Started process (PID=766) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:24:11.610+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:24:11.616+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:24:11.615+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:24:11.724+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:24:11.723+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:24:11.726+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:24:11.725+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:24:11.728+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:24:11.727+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:24:11.737+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:24:11.736+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:24:11.743+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:24:11.743+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:24:11.749+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:24:11.749+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:24:11.751+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:24:11.750+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:24:11.770+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:24:11.752+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:24:11.772+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:24:11.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.285 seconds
[2026-01-11T10:24:42.891+0000] {processor.py:161} INFO - Started process (PID=775) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:24:42.893+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:24:42.897+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:24:42.896+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:24:42.994+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:24:42.994+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:24:42.996+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:24:42.996+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:24:42.998+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:24:42.998+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:24:43.009+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:24:43.008+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:24:43.013+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:24:43.013+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:24:43.019+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:24:43.019+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:24:43.021+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:24:43.020+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:24:43.036+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:24:43.022+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:24:43.038+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:24:43.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.257 seconds
[2026-01-11T10:25:13.833+0000] {processor.py:161} INFO - Started process (PID=784) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:25:13.836+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:25:13.842+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:25:13.841+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:25:13.927+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:25:13.926+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:25:13.929+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:25:13.929+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:25:13.931+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:25:13.930+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:25:13.939+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:25:13.938+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:25:13.944+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:25:13.944+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:25:13.950+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:25:13.949+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:25:13.952+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:25:13.951+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:25:13.964+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:25:13.953+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:25:13.966+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:25:14.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.244 seconds
[2026-01-11T10:25:44.657+0000] {processor.py:161} INFO - Started process (PID=793) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:25:44.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:25:44.662+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:25:44.662+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:25:44.744+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:25:44.744+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:25:44.746+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:25:44.745+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:25:44.747+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:25:44.747+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:25:44.755+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:25:44.754+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:25:44.761+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:25:44.760+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:25:44.766+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:25:44.765+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:25:44.768+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:25:44.767+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:25:44.784+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:25:44.769+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:25:44.786+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:25:44.918+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.274 seconds
[2026-01-11T10:26:15.313+0000] {processor.py:161} INFO - Started process (PID=802) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:26:15.316+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:26:15.321+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:26:15.320+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:26:15.430+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:26:15.429+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:26:15.432+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:26:15.432+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:26:15.436+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:26:15.435+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:26:15.444+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:26:15.443+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:26:15.451+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:26:15.450+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:26:15.458+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:26:15.457+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:26:15.459+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:26:15.459+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:26:15.478+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:26:15.460+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:26:15.480+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:26:15.580+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.278 seconds
[2026-01-11T10:26:46.623+0000] {processor.py:161} INFO - Started process (PID=811) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:26:46.625+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:26:46.630+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:26:46.629+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:26:46.737+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:26:46.737+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:26:46.740+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:26:46.739+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:26:46.742+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:26:46.742+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:26:46.753+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:26:46.752+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:26:46.759+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:26:46.759+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:26:46.765+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:26:46.765+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:26:46.768+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:26:46.767+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:26:46.788+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:26:46.769+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:26:46.790+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:26:46.910+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.301 seconds
[2026-01-11T10:27:17.457+0000] {processor.py:161} INFO - Started process (PID=820) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:27:17.459+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:27:17.466+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:27:17.465+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:27:17.529+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:27:17.528+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:27:17.531+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:27:17.530+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:27:17.533+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:27:17.532+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:27:17.541+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:27:17.541+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:27:17.548+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:27:17.548+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:27:17.553+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:27:17.553+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:27:17.554+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:27:17.554+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:27:17.567+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:27:17.555+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:27:17.568+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:27:17.662+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.211 seconds
[2026-01-11T10:27:48.350+0000] {processor.py:161} INFO - Started process (PID=829) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:27:48.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:27:48.358+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:27:48.357+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:27:48.428+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:27:48.428+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:27:48.430+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:27:48.429+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:27:48.432+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:27:48.431+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:27:48.438+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:27:48.438+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:27:48.443+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:27:48.443+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:27:48.448+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:27:48.448+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:27:48.450+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:27:48.450+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:27:48.462+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:27:48.451+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:27:48.463+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:27:48.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.213 seconds
[2026-01-11T10:28:18.748+0000] {processor.py:161} INFO - Started process (PID=838) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:28:18.750+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:28:18.754+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:28:18.754+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:28:18.817+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:28:18.816+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:28:18.818+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:28:18.818+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:28:18.819+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:28:18.819+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:28:18.825+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:28:18.824+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:28:18.831+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:28:18.830+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:28:18.835+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:28:18.834+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:28:18.836+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:28:18.836+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:28:18.847+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:28:18.836+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:28:18.848+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:28:18.936+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.198 seconds
[2026-01-11T10:28:49.476+0000] {processor.py:161} INFO - Started process (PID=847) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:28:49.478+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:28:49.487+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:28:49.484+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:28:49.566+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:28:49.565+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:28:49.568+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:28:49.567+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:28:49.571+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:28:49.571+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:28:49.578+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:28:49.577+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:28:49.585+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:28:49.584+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:28:49.590+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:28:49.590+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:28:49.591+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:28:49.591+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:28:49.606+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:28:49.592+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:28:49.607+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:28:49.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.247 seconds
[2026-01-11T10:29:20.691+0000] {processor.py:161} INFO - Started process (PID=856) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:29:20.693+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:29:20.699+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:29:20.697+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:29:20.785+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:29:20.784+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:29:20.787+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:29:20.787+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:29:20.789+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:29:20.789+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:29:20.799+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:29:20.798+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:29:20.806+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:29:20.805+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:29:20.812+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:29:20.811+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:29:20.814+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:29:20.813+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:29:20.831+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:29:20.815+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:29:20.833+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:29:20.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.263 seconds
[2026-01-11T10:29:52.054+0000] {processor.py:161} INFO - Started process (PID=865) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:29:52.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:29:52.064+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:29:52.062+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:29:52.159+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:29:52.158+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:29:52.160+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:29:52.160+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:29:52.162+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:29:52.162+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:29:52.172+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:29:52.171+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:29:52.178+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:29:52.177+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:29:52.185+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:29:52.184+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:29:52.187+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:29:52.186+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:29:52.207+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:29:52.188+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:29:52.209+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:29:52.325+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.286 seconds
[2026-01-11T10:30:22.854+0000] {processor.py:161} INFO - Started process (PID=874) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:30:22.857+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:30:22.864+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:30:22.862+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:30:22.968+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:30:22.968+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:30:22.971+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:30:22.970+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:30:22.973+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:30:22.973+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:30:22.985+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:30:22.985+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:30:22.992+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:30:22.992+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:30:22.999+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:30:22.999+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:30:23.001+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:30:23.001+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:30:23.021+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:30:23.002+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:30:23.023+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:30:23.131+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.291 seconds
[2026-01-11T10:30:53.966+0000] {processor.py:161} INFO - Started process (PID=883) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:30:53.969+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:30:53.972+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:30:53.972+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:30:54.038+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:30:54.037+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:30:54.040+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:30:54.039+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:30:54.041+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:30:54.041+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:30:54.048+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:30:54.047+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:30:54.053+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:30:54.052+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:30:54.057+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:30:54.057+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:30:54.059+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:30:54.058+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:30:54.072+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:30:54.060+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:30:54.074+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:30:54.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.224 seconds
[2026-01-11T10:31:24.729+0000] {processor.py:161} INFO - Started process (PID=892) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:31:24.730+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:31:24.734+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:31:24.734+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:31:24.803+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:31:24.803+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:31:24.804+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:31:24.804+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:31:24.806+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:31:24.805+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:31:24.812+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:31:24.812+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:31:24.817+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:31:24.817+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:31:24.825+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:31:24.824+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:31:24.826+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:31:24.826+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:31:24.838+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:31:24.827+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:31:24.840+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:31:24.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.207 seconds
[2026-01-11T10:31:55.495+0000] {processor.py:161} INFO - Started process (PID=901) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:31:55.500+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:31:55.504+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:31:55.504+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:31:55.601+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:31:55.600+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:31:55.603+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:31:55.602+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:31:55.604+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:31:55.604+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:31:55.613+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:31:55.612+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:31:55.621+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:31:55.620+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:31:55.628+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:31:55.628+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:31:55.629+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:31:55.629+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:31:55.641+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:31:55.630+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:31:55.643+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:31:55.728+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.245 seconds
[2026-01-11T10:32:26.097+0000] {processor.py:161} INFO - Started process (PID=910) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:32:26.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:32:26.104+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:32:26.103+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:32:26.199+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:32:26.198+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:32:26.201+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:32:26.201+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:32:26.204+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:32:26.204+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:32:26.218+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:32:26.217+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:32:26.224+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:32:26.223+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:32:26.231+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:32:26.230+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:32:26.233+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:32:26.232+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:32:26.248+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:32:26.234+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:32:26.250+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:32:26.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.265 seconds
[2026-01-11T10:32:56.540+0000] {processor.py:161} INFO - Started process (PID=919) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:32:56.542+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:32:56.547+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:32:56.546+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:32:56.632+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:32:56.632+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:32:56.634+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:32:56.633+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:32:56.635+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:32:56.635+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:32:56.641+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:32:56.640+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:32:56.647+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:32:56.647+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:32:56.653+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:32:56.652+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:32:56.654+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:32:56.654+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:32:56.669+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:32:56.655+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:32:56.671+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:32:56.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.246 seconds
[2026-01-11T10:33:27.078+0000] {processor.py:161} INFO - Started process (PID=928) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:33:27.080+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:33:27.086+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:33:27.086+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:33:27.154+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:33:27.154+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:33:27.155+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:33:27.155+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:33:27.157+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:33:27.157+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:33:27.162+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:33:27.162+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:33:27.168+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:33:27.168+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:33:27.173+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:33:27.173+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:33:27.175+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:33:27.174+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:33:27.184+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:33:27.176+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:33:27.186+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:33:27.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.196 seconds
[2026-01-11T10:33:57.970+0000] {processor.py:161} INFO - Started process (PID=937) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:33:57.972+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:33:57.982+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:33:57.978+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:33:58.137+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:33:58.136+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:33:58.138+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:33:58.138+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:33:58.140+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:33:58.139+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:33:58.145+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:33:58.145+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:33:58.154+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:33:58.153+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:33:58.164+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:33:58.164+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:33:58.166+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:33:58.165+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:33:58.176+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:33:58.167+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:33:58.178+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:33:58.257+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.295 seconds
[2026-01-11T10:34:29.659+0000] {processor.py:161} INFO - Started process (PID=946) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:34:29.661+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:34:29.665+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:34:29.664+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:34:29.735+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:34:29.734+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:34:29.737+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:34:29.736+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:34:29.738+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:34:29.738+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:34:29.744+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:34:29.744+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:34:29.751+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:34:29.751+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:34:29.757+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:34:29.756+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:34:29.758+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:34:29.758+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:34:29.771+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:34:29.759+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:34:29.772+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:34:29.854+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.202 seconds
[2026-01-11T10:35:00.217+0000] {processor.py:161} INFO - Started process (PID=955) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:35:00.219+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:35:00.222+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:35:00.222+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:35:00.287+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:35:00.287+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:35:00.289+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:35:00.289+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:35:00.270+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:35:00.270+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:35:00.277+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:35:00.276+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:35:00.281+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:35:00.281+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:35:00.286+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:35:00.285+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:35:00.287+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:35:00.286+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:35:00.298+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:35:00.287+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:35:00.299+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:35:00.385+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.198 seconds
[2026-01-11T10:35:30.567+0000] {processor.py:161} INFO - Started process (PID=964) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:35:30.569+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:35:30.571+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:35:30.571+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:35:30.652+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:35:30.651+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:35:30.654+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:35:30.654+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:35:30.657+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:35:30.656+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:35:30.667+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:35:30.666+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:35:30.673+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:35:30.672+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:35:30.680+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:35:30.679+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:35:30.681+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:35:30.681+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:35:30.697+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:35:30.683+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:35:30.698+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:35:30.784+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.224 seconds
[2026-01-11T10:36:01.346+0000] {processor.py:161} INFO - Started process (PID=973) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:36:01.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:36:01.353+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:36:01.352+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:36:01.471+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:36:01.471+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:36:01.473+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:36:01.473+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:36:01.475+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:36:01.474+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:36:01.482+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:36:01.481+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:36:01.486+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:36:01.486+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:36:01.492+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:36:01.492+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:36:01.494+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:36:01.494+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:36:01.511+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:36:01.495+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:36:01.512+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:36:01.618+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.288 seconds
[2026-01-11T10:36:31.908+0000] {processor.py:161} INFO - Started process (PID=982) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:36:31.911+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:36:31.915+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:36:31.914+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:36:32.007+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:36:32.007+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:36:32.010+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:36:32.009+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:36:32.011+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:36:32.011+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:36:32.020+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:36:32.020+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:36:32.026+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:36:32.025+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:36:32.031+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:36:32.031+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:36:32.032+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:36:32.032+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:36:32.048+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:36:32.033+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:36:32.049+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:36:32.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.263 seconds
[2026-01-11T10:37:02.622+0000] {processor.py:161} INFO - Started process (PID=991) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:37:02.624+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:37:02.630+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:37:02.630+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:37:02.698+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:37:02.698+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:37:02.700+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:37:02.699+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:37:02.701+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:37:02.700+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:37:02.706+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:37:02.706+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:37:02.712+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:37:02.711+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:37:02.718+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:37:02.718+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:37:02.720+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:37:02.719+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:37:02.734+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:37:02.721+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:37:02.735+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:37:02.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.207 seconds
[2026-01-11T10:37:33.151+0000] {processor.py:161} INFO - Started process (PID=1000) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:37:33.155+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:37:33.161+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:37:33.160+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:37:33.276+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:37:33.276+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:37:33.278+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:37:33.278+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:37:33.280+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:37:33.280+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:37:33.289+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:37:33.288+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:37:33.295+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:37:33.294+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:37:33.301+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:37:33.301+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:37:33.303+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:37:33.303+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:37:33.320+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:37:33.304+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:37:33.322+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:37:33.423+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.289 seconds
[2026-01-11T10:38:05.422+0000] {processor.py:161} INFO - Started process (PID=1009) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:38:05.426+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:38:05.431+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:38:05.430+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:38:05.500+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:38:05.499+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:38:05.501+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:38:05.501+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:38:05.502+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:38:05.502+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:38:05.508+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:38:05.508+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:38:05.515+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:38:05.514+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:38:05.519+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:38:05.519+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:38:05.520+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:38:05.520+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:38:05.532+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:38:05.521+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:38:05.534+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:38:05.637+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.225 seconds
[2026-01-11T10:38:36.118+0000] {processor.py:161} INFO - Started process (PID=1018) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:38:36.120+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:38:36.124+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:38:36.123+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:38:36.183+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:38:36.183+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:38:36.185+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:38:36.184+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:38:36.186+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:38:36.186+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:38:36.194+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:38:36.193+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:38:36.199+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:38:36.199+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:38:36.204+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:38:36.203+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:38:36.205+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:38:36.205+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:38:36.221+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:38:36.206+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:38:36.223+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:38:36.334+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.224 seconds
[2026-01-11T10:39:06.873+0000] {processor.py:161} INFO - Started process (PID=1027) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:39:06.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:39:06.881+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:39:06.880+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:39:06.979+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:39:06.979+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:39:06.981+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:39:06.981+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:39:06.983+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:39:06.983+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:39:06.993+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:39:06.992+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:39:07.000+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:39:06.999+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:39:07.005+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:39:07.005+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:39:07.007+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:39:07.006+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:39:07.021+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:39:07.011+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:39:07.022+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:39:07.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.260 seconds
[2026-01-11T10:39:37.583+0000] {processor.py:161} INFO - Started process (PID=1036) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:39:37.585+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:39:37.589+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:39:37.588+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:39:37.657+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:39:37.656+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:39:37.660+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:39:37.659+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:39:37.662+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:39:37.661+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:39:37.667+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:39:37.667+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:39:37.673+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:39:37.672+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:39:37.678+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:39:37.678+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:39:37.680+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:39:37.679+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:39:37.692+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:39:37.681+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:39:37.694+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:39:37.783+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.207 seconds
[2026-01-11T10:40:09.125+0000] {processor.py:161} INFO - Started process (PID=1045) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:40:09.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:40:09.131+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:40:09.130+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:40:09.214+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:40:09.214+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:40:09.215+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:40:09.215+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:40:09.217+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:40:09.217+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:40:09.224+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:40:09.223+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:40:09.230+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:40:09.229+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:40:09.237+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:40:09.237+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:40:09.239+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:40:09.238+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:40:09.259+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:40:09.240+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:40:09.261+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:40:09.374+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.257 seconds
[2026-01-11T10:40:40.552+0000] {processor.py:161} INFO - Started process (PID=1054) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:40:40.554+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:40:40.558+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:40:40.557+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:40:40.635+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:40:40.635+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:40:40.637+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:40:40.636+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:40:40.638+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:40:40.638+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:40:40.647+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:40:40.646+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:40:40.651+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:40:40.651+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:40:40.656+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:40:40.656+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:40:40.658+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:40:40.657+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:40:40.669+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:40:40.659+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:40:40.670+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:40:40.755+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.211 seconds
[2026-01-11T10:41:12.231+0000] {processor.py:161} INFO - Started process (PID=1063) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:41:12.233+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:41:12.236+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:41:12.236+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:41:12.341+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:41:12.340+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:41:12.347+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:41:12.346+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:41:12.348+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:41:12.348+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:41:12.362+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:41:12.362+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:41:12.369+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:41:12.368+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:41:12.376+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:41:12.375+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:41:12.382+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:41:12.382+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:41:12.428+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:41:12.384+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:41:12.431+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:41:12.666+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.445 seconds
[2026-01-11T10:41:43.444+0000] {processor.py:161} INFO - Started process (PID=1072) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:41:43.446+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:41:43.452+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:41:43.450+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:41:43.531+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:41:43.531+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:41:43.533+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:41:43.532+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:41:43.534+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:41:43.534+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:41:43.543+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:41:43.542+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:41:43.547+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:41:43.547+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:41:43.552+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:41:43.552+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:41:43.553+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:41:43.553+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:41:43.569+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:41:43.554+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:41:43.570+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:41:43.653+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.222 seconds
[2026-01-11T10:42:14.303+0000] {processor.py:161} INFO - Started process (PID=1081) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:42:14.307+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:42:14.315+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:42:14.313+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:42:14.463+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:42:14.462+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:42:14.466+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:42:14.465+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:42:14.468+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:42:14.468+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:42:14.481+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:42:14.481+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:42:14.488+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:42:14.487+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:42:14.496+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:42:14.495+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:42:14.498+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:42:14.498+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:42:14.521+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:42:14.500+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:42:14.523+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:42:14.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.365 seconds
[2026-01-11T10:42:45.146+0000] {processor.py:161} INFO - Started process (PID=1090) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:42:45.149+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:42:45.156+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:42:45.154+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:42:45.245+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:42:45.245+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:42:45.247+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:42:45.247+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:42:45.249+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:42:45.249+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:42:45.258+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:42:45.258+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:42:45.265+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:42:45.265+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:42:45.271+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:42:45.271+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:42:45.273+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:42:45.273+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:42:45.293+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:42:45.275+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:42:45.295+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:42:45.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.281 seconds
[2026-01-11T10:43:16.138+0000] {processor.py:161} INFO - Started process (PID=1099) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:43:16.141+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:43:16.146+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:43:16.145+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:43:16.221+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:43:16.221+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:43:16.223+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:43:16.222+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:43:16.224+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:43:16.224+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:43:16.231+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:43:16.231+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:43:16.237+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:43:16.236+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:43:16.243+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:43:16.242+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:43:16.244+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:43:16.243+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:43:16.255+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:43:16.245+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:43:16.256+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:43:16.342+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.213 seconds
[2026-01-11T10:43:47.517+0000] {processor.py:161} INFO - Started process (PID=1108) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:43:47.520+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:43:47.527+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:43:47.526+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:43:47.628+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:43:47.627+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:43:47.630+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:43:47.630+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:43:47.632+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:43:47.632+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:43:47.643+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:43:47.643+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:43:47.648+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:43:47.648+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:43:47.656+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:43:47.655+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:43:47.657+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:43:47.657+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:43:47.676+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:43:47.659+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:43:47.678+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:43:47.783+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.283 seconds
[2026-01-11T10:44:18.495+0000] {processor.py:161} INFO - Started process (PID=1117) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:44:18.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:44:18.500+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:44:18.500+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:44:18.563+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:44:18.563+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:44:18.565+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:44:18.565+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:44:18.567+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:44:18.567+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:44:18.573+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:44:18.573+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:44:18.579+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:44:18.579+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:44:18.586+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:44:18.585+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:44:18.587+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:44:18.587+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:44:18.598+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:44:18.588+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:44:18.600+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:44:18.689+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.202 seconds
[2026-01-11T10:44:49.645+0000] {processor.py:161} INFO - Started process (PID=1126) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:44:49.647+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:44:49.652+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:44:49.651+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:44:49.745+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:44:49.745+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:44:49.747+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:44:49.747+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:44:49.749+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:44:49.749+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:44:49.756+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:44:49.755+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:44:49.761+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:44:49.760+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:44:49.766+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:44:49.766+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:44:49.767+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:44:49.767+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:44:49.779+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:44:49.768+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:44:49.781+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:44:49.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.234 seconds
[2026-01-11T10:45:20.476+0000] {processor.py:161} INFO - Started process (PID=1135) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:45:20.480+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:45:20.486+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:45:20.485+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:45:20.583+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:45:20.582+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:45:20.584+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:45:20.584+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:45:20.586+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:45:20.585+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:45:20.593+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:45:20.593+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:45:20.599+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:45:20.599+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:45:20.604+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:45:20.604+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:45:20.605+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:45:20.605+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:45:20.616+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:45:20.606+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:45:20.618+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:45:20.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.267 seconds
[2026-01-11T10:45:51.222+0000] {processor.py:161} INFO - Started process (PID=1144) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:45:51.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:45:51.228+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:45:51.228+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:45:51.289+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:45:51.289+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:45:51.291+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:45:51.290+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:45:51.292+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:45:51.291+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:45:51.297+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:45:51.297+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:45:51.302+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:45:51.302+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:45:51.307+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:45:51.307+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:45:51.308+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:45:51.308+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:45:51.320+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:45:51.309+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:45:51.323+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:45:51.404+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.194 seconds
[2026-01-11T10:46:22.692+0000] {processor.py:161} INFO - Started process (PID=1153) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:46:22.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:46:22.701+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:46:22.700+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:46:22.789+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:46:22.788+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:46:22.790+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:46:22.790+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:46:22.792+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:46:22.791+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:46:22.798+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:46:22.797+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:46:22.802+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:46:22.801+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:46:22.807+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:46:22.806+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:46:22.808+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:46:22.808+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:46:22.821+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:46:22.809+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:46:22.822+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:46:22.927+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.246 seconds
[2026-01-11T10:46:54.872+0000] {processor.py:161} INFO - Started process (PID=1162) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:46:54.874+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:46:54.878+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:46:54.877+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:46:54.944+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:46:54.943+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:46:54.946+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:46:54.945+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:46:54.947+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:46:54.947+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:46:54.955+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:46:54.954+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:46:54.960+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:46:54.960+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:46:54.965+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:46:54.964+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:46:54.967+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:46:54.966+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:46:54.978+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:46:54.968+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:46:54.979+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:46:55.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.206 seconds
[2026-01-11T10:47:25.935+0000] {processor.py:161} INFO - Started process (PID=1171) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:47:25.937+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:47:25.940+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:47:25.940+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:47:26.012+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:47:26.010+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:47:26.015+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:47:26.015+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:47:26.018+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:47:26.017+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:47:26.024+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:47:26.024+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:47:26.030+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:47:26.030+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:47:26.036+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:47:26.036+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:47:26.037+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:47:26.037+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:47:26.050+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:47:26.038+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:47:26.051+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:47:26.141+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.215 seconds
[2026-01-11T10:47:56.712+0000] {processor.py:161} INFO - Started process (PID=1180) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:47:56.715+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:47:56.719+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:47:56.718+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:47:56.783+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:47:56.783+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:47:56.785+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:47:56.784+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:47:56.786+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:47:56.786+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:47:56.792+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:47:56.792+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:47:56.797+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:47:56.796+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:47:56.804+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:47:56.803+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:47:56.805+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:47:56.805+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:47:56.816+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:47:56.805+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:47:56.818+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:47:56.902+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.197 seconds
[2026-01-11T10:48:27.900+0000] {processor.py:161} INFO - Started process (PID=1189) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:48:27.902+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:48:27.906+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:48:27.906+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:48:27.973+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:48:27.972+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:48:27.975+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:48:27.975+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:48:27.976+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:48:27.976+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:48:27.983+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:48:27.983+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:48:27.989+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:48:27.989+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:48:27.995+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:48:27.995+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:48:27.997+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:48:27.996+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:48:28.008+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:48:27.998+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:48:28.010+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:48:28.093+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.202 seconds
[2026-01-11T10:48:58.641+0000] {processor.py:161} INFO - Started process (PID=1198) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:48:58.643+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:48:58.645+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:48:58.645+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:48:58.723+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:48:58.722+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:48:58.725+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:48:58.724+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:48:58.727+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:48:58.726+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:48:58.737+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:48:58.736+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:48:58.743+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:48:58.742+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:48:58.750+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:48:58.749+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:48:58.752+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:48:58.751+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:48:58.766+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:48:58.753+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:48:58.768+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:48:58.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.229 seconds
[2026-01-11T10:49:30.449+0000] {processor.py:161} INFO - Started process (PID=1207) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:49:30.450+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:49:30.454+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:49:30.453+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:49:30.529+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:49:30.528+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:49:30.531+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:49:30.530+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:49:30.533+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:49:30.533+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:49:30.541+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:49:30.541+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:49:30.549+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:49:30.549+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:49:30.556+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:49:30.555+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:49:30.557+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:49:30.556+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:49:30.573+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:49:30.558+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:49:30.575+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:49:30.664+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.225 seconds
[2026-01-11T10:50:01.511+0000] {processor.py:161} INFO - Started process (PID=1216) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:50:01.515+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:50:01.521+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:50:01.519+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:50:01.631+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:50:01.631+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:50:01.633+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:50:01.633+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:50:01.635+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:50:01.635+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:50:01.649+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:50:01.648+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:50:01.655+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:50:01.655+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:50:01.661+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:50:01.660+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:50:01.662+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:50:01.662+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:50:01.676+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:50:01.664+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:50:01.677+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:50:01.767+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.277 seconds
[2026-01-11T10:50:32.653+0000] {processor.py:161} INFO - Started process (PID=1225) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:50:32.655+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:50:32.658+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:50:32.658+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:50:32.732+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:50:32.732+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:50:32.734+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:50:32.733+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:50:32.735+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:50:32.735+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:50:32.741+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:50:32.741+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:50:32.748+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:50:32.747+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:50:32.753+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:50:32.752+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:50:32.754+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:50:32.754+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:50:32.767+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:50:32.755+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:50:32.769+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:50:32.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.210 seconds
[2026-01-11T10:51:03.583+0000] {processor.py:161} INFO - Started process (PID=1234) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:51:03.586+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:51:03.590+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:51:03.590+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:51:03.671+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:51:03.671+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:51:03.673+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:51:03.672+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:51:03.674+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:51:03.673+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:51:03.679+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:51:03.679+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:51:03.685+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:51:03.685+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:51:03.692+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:51:03.692+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:51:03.694+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:51:03.693+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:51:03.708+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:51:03.694+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:51:03.710+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:51:03.813+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.241 seconds
[2026-01-11T10:51:34.656+0000] {processor.py:161} INFO - Started process (PID=1243) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:51:34.658+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T10:51:34.661+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:51:34.660+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:51:34.722+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:51:34.722+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T10:51:34.724+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:51:34.723+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T10:51:34.725+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:51:34.725+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T10:51:34.732+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:51:34.732+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:51:34.738+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:51:34.737+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:51:34.742+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:51:34.742+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T10:51:34.744+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:51:34.743+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T10:51:34.757+0000] {logging_mixin.py:188} INFO - [2026-01-11T10:51:34.744+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T10:51:34.759+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T10:51:34.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.201 seconds
[2026-01-11T12:44:22.401+0000] {processor.py:161} INFO - Started process (PID=1249) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T12:44:22.403+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-11T12:44:22.418+0000] {logging_mixin.py:188} INFO - [2026-01-11T12:44:22.417+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T12:44:22.488+0000] {logging_mixin.py:188} INFO - [2026-01-11T12:44:22.487+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-11T12:44:22.497+0000] {logging_mixin.py:188} INFO - [2026-01-11T12:44:22.496+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-11T12:44:22.499+0000] {logging_mixin.py:188} INFO - [2026-01-11T12:44:22.499+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-11T12:44:22.515+0000] {logging_mixin.py:188} INFO - [2026-01-11T12:44:22.514+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T12:44:22.524+0000] {logging_mixin.py:188} INFO - [2026-01-11T12:44:22.523+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T12:44:22.529+0000] {logging_mixin.py:188} INFO - [2026-01-11T12:44:22.528+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-11T12:44:22.530+0000] {logging_mixin.py:188} INFO - [2026-01-11T12:44:22.530+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-11T12:44:22.542+0000] {logging_mixin.py:188} INFO - [2026-01-11T12:44:22.531+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-11T12:44:22.543+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-11T12:44:22.670+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.296 seconds
