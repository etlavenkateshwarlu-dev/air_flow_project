[2026-01-23T02:54:37.830+0000] {processor.py:161} INFO - Started process (PID=63) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:54:37.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T02:54:37.835+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:54:37.835+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:54:37.889+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:54:37.888+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T02:54:37.892+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:54:37.891+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T02:54:37.893+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:54:37.893+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T02:54:37.899+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:54:37.898+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:54:37.902+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:54:37.902+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:54:37.906+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:54:37.906+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:54:37.908+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:54:37.907+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T02:54:37.916+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:54:37.909+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T02:54:37.917+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:54:37.965+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.145 seconds
[2026-01-23T02:55:08.592+0000] {processor.py:161} INFO - Started process (PID=72) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:55:08.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T02:55:08.596+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:55:08.596+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:55:08.628+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:55:08.628+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T02:55:08.628+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:55:08.628+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T02:55:08.629+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:55:08.629+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T02:55:08.633+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:55:08.633+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:55:08.635+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:55:08.635+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:55:08.637+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:55:08.637+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:55:08.638+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:55:08.638+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T02:55:08.642+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:55:08.638+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T02:55:08.643+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:55:08.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.089 seconds
[2026-01-23T02:55:38.829+0000] {processor.py:161} INFO - Started process (PID=81) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:55:38.831+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T02:55:38.833+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:55:38.832+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:55:38.862+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:55:38.861+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T02:55:38.862+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:55:38.862+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T02:55:38.863+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:55:38.863+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T02:55:38.867+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:55:38.866+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:55:38.869+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:55:38.868+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:55:38.870+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:55:38.870+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:55:38.871+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:55:38.871+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T02:55:38.875+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:55:38.871+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T02:55:38.876+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:55:38.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.101 seconds
[2026-01-23T02:56:09.838+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:56:09.839+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T02:56:09.842+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:56:09.842+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:56:09.874+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:56:09.874+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T02:56:09.875+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:56:09.875+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T02:56:09.876+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:56:09.876+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T02:56:09.879+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:56:09.878+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:56:09.881+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:56:09.880+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:56:09.883+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:56:09.882+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:56:09.883+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:56:09.883+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T02:56:09.888+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:56:09.884+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T02:56:09.889+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:56:09.920+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.088 seconds
[2026-01-23T02:56:40.561+0000] {processor.py:161} INFO - Started process (PID=99) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:56:40.562+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T02:56:40.564+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:56:40.564+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:56:40.594+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:56:40.594+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T02:56:40.595+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:56:40.595+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T02:56:40.596+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:56:40.596+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T02:56:40.599+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:56:40.598+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:56:40.601+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:56:40.600+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:56:40.602+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:56:40.602+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:56:40.603+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:56:40.603+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T02:56:40.607+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:56:40.603+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T02:56:40.608+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:56:40.640+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.086 seconds
[2026-01-23T02:57:11.510+0000] {processor.py:161} INFO - Started process (PID=108) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:57:11.512+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T02:57:11.514+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:57:11.513+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:57:11.546+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:57:11.545+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T02:57:11.547+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:57:11.546+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T02:57:11.548+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:57:11.547+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T02:57:11.552+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:57:11.552+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:57:11.555+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:57:11.555+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:57:11.558+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:57:11.558+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:57:11.559+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:57:11.558+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T02:57:11.564+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:57:11.559+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T02:57:11.564+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:57:11.602+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.097 seconds
[2026-01-23T02:57:42.351+0000] {processor.py:161} INFO - Started process (PID=117) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:57:42.352+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T02:57:42.354+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:57:42.354+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:57:42.391+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:57:42.390+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T02:57:42.391+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:57:42.391+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T02:57:42.392+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:57:42.392+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T02:57:42.395+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:57:42.395+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:57:42.398+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:57:42.398+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:57:42.400+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:57:42.400+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:57:42.401+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:57:42.401+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T02:57:42.406+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:57:42.401+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T02:57:42.407+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:57:42.437+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.092 seconds
[2026-01-23T02:58:13.390+0000] {processor.py:161} INFO - Started process (PID=126) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:58:13.391+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T02:58:13.394+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:58:13.393+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:58:13.432+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:58:13.432+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T02:58:13.434+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:58:13.434+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T02:58:13.435+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:58:13.435+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T02:58:13.438+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:58:13.438+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:58:13.441+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:58:13.441+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:58:13.443+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:58:13.443+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:58:13.444+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:58:13.444+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T02:58:13.451+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:58:13.444+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T02:58:13.452+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:58:13.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.108 seconds
[2026-01-23T02:58:44.177+0000] {processor.py:161} INFO - Started process (PID=135) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:58:44.178+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T02:58:44.182+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:58:44.181+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:58:44.226+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:58:44.226+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T02:58:44.227+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:58:44.227+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T02:58:44.227+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:58:44.227+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T02:58:44.231+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:58:44.231+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:58:44.234+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:58:44.234+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:58:44.237+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:58:44.236+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:58:44.237+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:58:44.237+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T02:58:44.242+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:58:44.238+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T02:58:44.243+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:58:44.275+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.104 seconds
[2026-01-23T02:59:14.910+0000] {processor.py:161} INFO - Started process (PID=144) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:59:14.911+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T02:59:14.914+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:59:14.914+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:59:14.954+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:59:14.954+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T02:59:14.955+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:59:14.955+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T02:59:14.956+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:59:14.956+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T02:59:14.959+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:59:14.959+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:59:14.961+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:59:14.961+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:59:14.963+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:59:14.963+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:59:14.964+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:59:14.964+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T02:59:14.969+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:59:14.964+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T02:59:14.969+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:59:14.999+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.097 seconds
[2026-01-23T02:59:45.955+0000] {processor.py:161} INFO - Started process (PID=153) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:59:45.957+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T02:59:45.959+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:59:45.959+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:59:46.001+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:59:46.000+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T02:59:46.002+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:59:46.002+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T02:59:46.003+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:59:46.002+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T02:59:46.006+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:59:46.006+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:59:46.009+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:59:46.008+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:59:46.011+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:59:46.011+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T02:59:46.012+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:59:46.012+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T02:59:46.018+0000] {logging_mixin.py:188} INFO - [2026-01-23T02:59:46.012+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T02:59:46.019+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T02:59:46.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.121 seconds
[2026-01-23T03:00:16.767+0000] {processor.py:161} INFO - Started process (PID=162) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:00:16.769+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:00:16.772+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:00:16.771+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:00:16.807+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:00:16.807+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:00:16.808+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:00:16.808+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:00:16.809+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:00:16.808+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:00:16.813+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:00:16.812+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:00:16.815+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:00:16.815+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:00:16.818+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:00:16.817+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:00:16.818+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:00:16.818+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:00:16.824+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:00:16.819+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:00:16.825+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:00:16.868+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.108 seconds
[2026-01-23T03:00:47.606+0000] {processor.py:161} INFO - Started process (PID=171) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:00:47.608+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:00:47.610+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:00:47.610+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:00:47.641+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:00:47.641+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:00:47.642+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:00:47.642+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:00:47.643+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:00:47.643+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:00:47.646+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:00:47.646+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:00:47.648+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:00:47.648+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:00:47.650+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:00:47.650+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:00:47.651+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:00:47.650+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:00:47.656+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:00:47.651+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:00:47.657+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:00:47.690+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.090 seconds
[2026-01-23T03:01:18.428+0000] {processor.py:161} INFO - Started process (PID=180) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:01:18.430+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:01:18.433+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:01:18.432+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:01:18.467+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:01:18.466+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:01:18.467+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:01:18.467+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:01:18.468+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:01:18.468+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:01:18.472+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:01:18.471+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:01:18.475+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:01:18.474+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:01:18.478+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:01:18.478+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:01:18.479+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:01:18.479+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:01:18.484+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:01:18.479+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:01:18.485+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:01:18.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.113 seconds
[2026-01-23T03:01:49.374+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:01:49.376+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:01:49.379+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:01:49.378+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:01:49.414+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:01:49.413+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:01:49.414+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:01:49.414+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:01:49.415+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:01:49.415+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:01:49.419+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:01:49.418+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:01:49.421+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:01:49.420+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:01:49.422+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:01:49.422+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:01:49.423+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:01:49.423+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:01:49.428+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:01:49.423+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:01:49.428+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:01:49.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.094 seconds
[2026-01-23T03:02:20.359+0000] {processor.py:161} INFO - Started process (PID=198) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:02:20.361+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:02:20.364+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:02:20.363+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:02:20.412+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:02:20.411+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:02:20.413+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:02:20.413+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:02:20.415+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:02:20.414+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:02:20.419+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:02:20.419+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:02:20.423+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:02:20.423+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:02:20.426+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:02:20.426+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:02:20.427+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:02:20.426+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:02:20.432+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:02:20.427+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:02:20.433+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:02:20.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.117 seconds
[2026-01-23T03:02:51.126+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:02:51.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:02:51.130+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:02:51.130+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:02:51.166+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:02:51.166+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:02:51.167+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:02:51.167+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:02:51.168+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:02:51.167+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:02:51.171+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:02:51.171+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:02:51.173+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:02:51.173+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:02:51.175+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:02:51.175+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:02:51.176+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:02:51.176+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:02:51.180+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:02:51.176+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:02:51.181+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:02:51.218+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.098 seconds
[2026-01-23T03:03:21.558+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:03:21.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:03:21.562+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:03:21.561+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:03:21.593+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:03:21.593+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:03:21.594+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:03:21.594+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:03:21.595+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:03:21.595+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:03:21.598+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:03:21.598+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:03:21.600+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:03:21.600+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:03:21.602+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:03:21.602+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:03:21.603+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:03:21.602+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:03:21.607+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:03:21.603+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:03:21.608+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:03:21.644+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.092 seconds
[2026-01-23T03:03:52.067+0000] {processor.py:161} INFO - Started process (PID=225) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:03:52.068+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:03:52.071+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:03:52.070+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:03:52.106+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:03:52.105+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:03:52.106+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:03:52.106+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:03:52.107+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:03:52.107+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:03:52.110+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:03:52.110+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:03:52.112+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:03:52.112+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:03:52.114+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:03:52.114+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:03:52.115+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:03:52.115+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:03:52.120+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:03:52.115+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:03:52.121+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:03:52.153+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.092 seconds
[2026-01-23T03:04:22.348+0000] {processor.py:161} INFO - Started process (PID=234) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:04:22.350+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:04:22.353+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:04:22.352+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:04:22.395+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:04:22.395+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:04:22.396+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:04:22.396+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:04:22.397+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:04:22.397+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:04:22.401+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:04:22.401+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:04:22.403+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:04:22.403+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:04:22.406+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:04:22.405+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:04:22.406+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:04:22.406+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:04:22.411+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:04:22.407+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:04:22.412+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:04:22.446+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.105 seconds
[2026-01-23T03:04:52.806+0000] {processor.py:161} INFO - Started process (PID=243) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:04:52.807+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:04:52.809+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:04:52.809+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:04:52.842+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:04:52.841+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:04:52.842+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:04:52.842+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:04:52.843+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:04:52.843+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:04:52.847+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:04:52.847+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:04:52.850+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:04:52.849+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:04:52.853+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:04:52.852+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:04:52.853+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:04:52.853+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:04:52.861+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:04:52.854+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:04:52.861+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:04:52.903+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.102 seconds
[2026-01-23T03:05:23.056+0000] {processor.py:161} INFO - Started process (PID=252) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:05:23.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:05:23.059+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:05:23.059+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:05:23.091+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:05:23.090+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:05:23.091+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:05:23.091+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:05:23.092+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:05:23.092+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:05:23.095+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:05:23.095+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:05:23.097+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:05:23.097+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:05:23.099+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:05:23.099+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:05:23.100+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:05:23.100+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:05:23.104+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:05:23.100+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:05:23.105+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:05:23.139+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.088 seconds
[2026-01-23T03:05:53.724+0000] {processor.py:161} INFO - Started process (PID=261) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:05:53.726+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:05:53.728+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:05:53.727+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:05:53.761+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:05:53.761+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:05:53.762+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:05:53.762+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:05:53.763+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:05:53.763+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:05:53.766+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:05:53.766+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:05:53.769+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:05:53.768+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:05:53.772+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:05:53.771+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:05:53.772+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:05:53.772+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:05:53.778+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:05:53.773+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:05:53.778+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:05:53.832+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.113 seconds
[2026-01-23T03:06:24.295+0000] {processor.py:161} INFO - Started process (PID=270) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:06:24.297+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:06:24.300+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:06:24.299+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:06:24.343+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:06:24.342+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:06:24.344+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:06:24.343+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:06:24.344+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:06:24.344+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:06:24.348+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:06:24.348+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:06:24.350+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:06:24.350+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:06:24.353+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:06:24.352+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:06:24.354+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:06:24.353+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:06:24.360+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:06:24.354+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:06:24.361+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:06:24.405+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.119 seconds
[2026-01-23T03:06:54.635+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:06:54.637+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:06:54.640+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:06:54.640+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:06:54.680+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:06:54.680+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:06:54.681+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:06:54.681+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:06:54.682+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:06:54.682+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:06:54.687+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:06:54.686+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:06:54.690+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:06:54.689+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:06:54.692+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:06:54.692+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:06:54.693+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:06:54.693+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:06:54.700+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:06:54.693+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:06:54.701+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:06:54.763+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.135 seconds
[2026-01-23T03:07:25.614+0000] {processor.py:161} INFO - Started process (PID=288) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:07:25.616+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:07:25.619+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:07:25.619+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:07:25.668+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:07:25.667+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:07:25.669+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:07:25.668+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:07:25.670+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:07:25.669+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:07:25.673+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:07:25.673+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:07:25.677+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:07:25.677+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:07:25.680+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:07:25.679+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:07:25.680+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:07:25.680+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:07:25.689+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:07:25.681+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:07:25.690+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:07:25.740+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.133 seconds
[2026-01-23T03:07:56.545+0000] {processor.py:161} INFO - Started process (PID=297) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:07:56.547+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:07:56.552+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:07:56.551+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:07:56.605+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:07:56.605+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:07:56.606+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:07:56.606+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:07:56.608+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:07:56.607+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:07:56.614+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:07:56.613+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:07:56.618+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:07:56.617+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:07:56.621+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:07:56.621+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:07:56.623+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:07:56.622+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:07:56.632+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:07:56.623+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:07:56.633+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:07:56.685+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.148 seconds
[2026-01-23T03:08:27.431+0000] {processor.py:161} INFO - Started process (PID=306) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:08:27.433+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:08:27.436+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:08:27.435+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:08:27.497+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:08:27.496+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:08:27.498+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:08:27.498+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:08:27.499+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:08:27.499+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:08:27.503+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:08:27.503+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:08:27.507+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:08:27.507+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:08:27.510+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:08:27.510+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:08:27.511+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:08:27.511+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:08:27.521+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:08:27.512+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:08:27.522+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:08:27.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.152 seconds
[2026-01-23T03:08:58.334+0000] {processor.py:161} INFO - Started process (PID=315) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:08:58.336+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:08:58.338+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:08:58.337+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:08:58.377+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:08:58.376+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:08:58.378+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:08:58.378+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:08:58.379+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:08:58.379+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:08:58.383+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:08:58.382+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:08:58.385+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:08:58.385+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:08:58.388+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:08:58.387+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:08:58.388+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:08:58.388+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:08:58.395+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:08:58.388+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:08:58.396+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:08:58.435+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.107 seconds
[2026-01-23T03:09:29.494+0000] {processor.py:161} INFO - Started process (PID=324) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:09:29.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:09:29.499+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:09:29.498+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:09:29.540+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:09:29.539+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:09:29.541+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:09:29.541+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:09:29.542+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:09:29.541+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:09:29.546+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:09:29.545+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:09:29.549+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:09:29.548+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:09:29.552+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:09:29.551+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:09:29.552+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:09:29.552+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:09:29.564+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:09:29.553+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:09:29.565+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:09:29.619+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.130 seconds
[2026-01-23T03:10:01.060+0000] {processor.py:161} INFO - Started process (PID=333) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:10:01.061+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:10:01.064+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:10:01.063+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:10:01.111+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:10:01.111+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:10:01.112+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:10:01.112+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:10:01.113+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:10:01.113+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:10:01.118+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:10:01.117+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:10:01.121+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:10:01.120+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:10:01.123+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:10:01.123+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:10:01.124+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:10:01.123+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:10:01.130+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:10:01.124+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:10:01.131+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:10:01.173+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.123 seconds
[2026-01-23T03:10:31.768+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:10:31.769+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:10:31.772+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:10:31.771+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:10:31.809+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:10:31.808+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:10:31.809+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:10:31.809+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:10:31.810+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:10:31.810+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:10:31.814+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:10:31.813+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:10:31.816+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:10:31.816+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:10:31.819+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:10:31.819+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:10:31.820+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:10:31.820+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:10:31.826+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:10:31.820+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:10:31.827+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:10:31.869+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.106 seconds
[2026-01-23T03:11:02.405+0000] {processor.py:161} INFO - Started process (PID=351) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:11:02.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:11:02.409+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:11:02.409+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:11:02.444+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:11:02.444+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:11:02.445+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:11:02.445+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:11:02.446+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:11:02.446+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:11:02.450+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:11:02.450+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:11:02.452+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:11:02.452+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:11:02.454+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:11:02.454+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:11:02.455+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:11:02.455+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:11:02.461+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:11:02.455+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:11:02.462+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:11:02.502+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.103 seconds
[2026-01-23T03:11:33.014+0000] {processor.py:161} INFO - Started process (PID=360) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:11:33.016+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:11:33.018+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:11:33.017+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:11:33.050+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:11:33.050+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:11:33.051+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:11:33.051+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:11:33.052+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:11:33.052+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:11:33.055+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:11:33.055+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:11:33.057+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:11:33.057+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:11:33.059+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:11:33.059+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:11:33.060+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:11:33.060+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:11:33.065+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:11:33.060+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:11:33.066+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:11:33.100+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.092 seconds
[2026-01-23T03:12:03.649+0000] {processor.py:161} INFO - Started process (PID=369) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:12:03.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:12:03.652+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:12:03.651+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:12:03.680+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:12:03.680+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:12:03.681+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:12:03.681+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:12:03.682+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:12:03.681+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:12:03.685+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:12:03.684+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:12:03.687+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:12:03.686+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:12:03.689+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:12:03.689+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:12:03.690+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:12:03.689+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:12:03.694+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:12:03.690+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:12:03.695+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:12:03.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.089 seconds
[2026-01-23T03:12:34.771+0000] {processor.py:161} INFO - Started process (PID=378) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:12:34.772+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:12:34.775+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:12:34.775+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:12:34.812+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:12:34.812+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:12:34.813+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:12:34.813+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:12:34.814+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:12:34.814+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:12:34.817+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:12:34.817+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:12:34.820+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:12:34.820+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:12:34.822+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:12:34.822+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:12:34.823+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:12:34.823+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:12:34.828+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:12:34.823+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:12:34.828+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:12:34.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.100 seconds
[2026-01-23T03:13:07.065+0000] {processor.py:161} INFO - Started process (PID=387) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:13:07.067+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:13:07.081+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:13:07.079+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:13:07.257+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:13:07.257+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:13:07.259+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:13:07.259+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:13:07.264+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:13:07.264+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:13:07.285+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:13:07.285+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:13:07.300+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:13:07.299+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:13:07.322+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:13:07.322+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:13:07.323+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:13:07.323+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:13:07.401+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:13:07.324+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:13:07.402+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:13:07.493+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.439 seconds
[2026-01-23T03:13:37.610+0000] {processor.py:161} INFO - Started process (PID=396) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:13:37.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:13:37.617+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:13:37.616+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:13:37.662+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:13:37.662+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:13:37.663+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:13:37.663+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:13:37.664+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:13:37.664+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:13:37.668+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:13:37.668+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:13:37.672+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:13:37.671+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:13:37.675+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:13:37.674+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:13:37.675+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:13:37.675+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:13:37.682+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:13:37.676+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:13:37.683+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:13:37.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.128 seconds
[2026-01-23T03:14:08.101+0000] {processor.py:161} INFO - Started process (PID=405) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:14:08.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:14:08.106+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:14:08.106+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:14:08.155+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:14:08.154+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:14:08.156+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:14:08.156+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:14:08.157+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:14:08.157+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:14:08.162+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:14:08.161+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:14:08.164+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:14:08.164+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:14:08.168+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:14:08.168+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:14:08.169+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:14:08.169+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:14:08.179+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:14:08.170+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:14:08.180+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:14:08.232+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.138 seconds
[2026-01-23T03:14:38.459+0000] {processor.py:161} INFO - Started process (PID=414) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:14:38.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:14:38.462+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:14:38.462+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:14:38.491+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:14:38.491+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:14:38.492+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:14:38.492+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:14:38.493+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:14:38.493+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:14:38.496+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:14:38.496+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:14:38.499+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:14:38.499+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:14:38.501+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:14:38.500+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:14:38.501+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:14:38.501+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:14:38.506+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:14:38.502+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:14:38.506+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:14:38.535+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.082 seconds
[2026-01-23T03:15:08.956+0000] {processor.py:161} INFO - Started process (PID=423) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:15:08.957+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:15:08.961+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:15:08.960+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:15:08.998+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:15:08.998+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:15:08.999+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:15:08.999+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:15:09.000+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:15:09.000+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:15:09.003+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:15:09.003+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:15:09.006+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:15:09.006+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:15:09.009+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:15:09.009+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:15:09.010+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:15:09.010+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:15:09.015+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:15:09.010+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:15:09.015+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:15:09.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.104 seconds
[2026-01-23T03:15:39.534+0000] {processor.py:161} INFO - Started process (PID=432) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:15:39.536+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:15:39.539+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:15:39.538+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:15:39.578+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:15:39.578+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:15:39.579+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:15:39.579+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:15:39.580+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:15:39.580+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:15:39.583+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:15:39.583+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:15:39.587+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:15:39.586+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:15:39.589+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:15:39.589+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:15:39.590+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:15:39.590+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:15:39.597+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:15:39.591+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:15:39.597+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:15:39.637+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.109 seconds
[2026-01-23T03:16:10.115+0000] {processor.py:161} INFO - Started process (PID=441) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:16:10.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:16:10.119+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:16:10.118+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:16:10.155+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:16:10.154+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:16:10.155+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:16:10.155+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:16:10.156+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:16:10.156+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:16:10.160+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:16:10.160+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:16:10.163+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:16:10.162+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:16:10.174+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:16:10.173+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:16:10.175+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:16:10.174+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:16:10.181+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:16:10.175+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:16:10.182+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:16:10.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.112 seconds
[2026-01-23T03:16:40.976+0000] {processor.py:161} INFO - Started process (PID=450) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:16:40.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:16:40.981+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:16:40.980+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:16:41.030+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:16:41.029+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:16:41.031+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:16:41.030+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:16:41.032+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:16:41.032+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:16:41.036+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:16:41.036+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:16:41.039+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:16:41.039+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:16:41.042+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:16:41.042+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:16:41.043+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:16:41.043+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:16:41.050+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:16:41.044+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:16:41.050+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:16:41.089+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.130 seconds
[2026-01-23T03:17:11.838+0000] {processor.py:161} INFO - Started process (PID=459) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:17:11.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:17:11.844+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:17:11.843+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:17:11.884+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:17:11.883+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:17:11.884+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:17:11.884+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:17:11.885+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:17:11.885+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:17:11.889+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:17:11.889+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:17:11.892+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:17:11.892+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:17:11.894+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:17:11.894+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:17:11.895+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:17:11.895+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:17:11.901+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:17:11.895+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:17:11.901+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:17:11.941+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.110 seconds
[2026-01-23T03:17:42.512+0000] {processor.py:161} INFO - Started process (PID=468) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:17:42.513+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:17:42.516+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:17:42.515+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:17:42.551+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:17:42.550+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:17:42.552+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:17:42.552+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:17:42.553+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:17:42.553+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:17:42.557+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:17:42.557+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:17:42.560+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:17:42.560+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:17:42.562+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:17:42.562+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:17:42.563+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:17:42.563+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:17:42.569+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:17:42.564+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:17:42.570+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:17:42.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.101 seconds
[2026-01-23T03:18:12.947+0000] {processor.py:161} INFO - Started process (PID=477) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:18:12.949+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:18:12.951+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:18:12.950+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:18:12.985+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:18:12.985+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:18:12.986+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:18:12.986+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:18:12.987+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:18:12.986+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:18:12.990+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:18:12.990+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:18:12.992+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:18:12.992+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:18:12.995+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:18:12.994+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:18:12.995+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:18:12.995+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:18:13.000+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:18:12.995+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:18:13.001+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:18:13.043+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.102 seconds
[2026-01-23T03:18:43.629+0000] {processor.py:161} INFO - Started process (PID=494) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:18:43.631+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:18:43.634+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:18:43.634+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:18:43.666+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:18:43.665+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:18:43.667+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:18:43.666+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:18:43.667+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:18:43.667+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:18:43.671+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:18:43.671+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:18:43.673+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:18:43.673+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:18:43.675+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:18:43.675+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:18:43.676+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:18:43.676+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:18:43.681+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:18:43.676+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:18:43.681+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:18:43.720+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.098 seconds
[2026-01-23T03:19:14.389+0000] {processor.py:161} INFO - Started process (PID=505) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:19:14.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:19:14.392+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:19:14.391+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:19:14.424+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:19:14.424+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:19:14.425+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:19:14.425+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:19:14.426+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:19:14.426+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:19:14.429+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:19:14.429+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:19:14.432+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:19:14.431+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:19:14.434+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:19:14.433+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:19:14.434+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:19:14.434+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:19:14.439+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:19:14.435+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:19:14.440+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:19:14.481+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.098 seconds
[2026-01-23T03:19:45.093+0000] {processor.py:161} INFO - Started process (PID=514) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:19:45.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:19:45.097+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:19:45.096+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:19:45.124+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:19:45.124+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:19:45.125+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:19:45.125+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:19:45.126+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:19:45.125+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:19:45.130+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:19:45.129+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:19:45.132+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:19:45.132+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:19:45.135+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:19:45.134+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:19:45.135+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:19:45.135+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:19:45.141+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:19:45.136+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:19:45.141+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:19:45.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.089 seconds
[2026-01-23T03:20:15.920+0000] {processor.py:161} INFO - Started process (PID=523) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:20:15.921+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:20:15.924+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:20:15.924+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:20:15.957+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:20:15.957+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:20:15.958+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:20:15.957+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:20:15.958+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:20:15.958+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:20:15.961+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:20:15.961+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:20:15.964+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:20:15.963+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:20:15.966+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:20:15.966+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:20:15.967+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:20:15.967+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:20:15.972+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:20:15.967+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:20:15.973+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:20:16.010+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.096 seconds
[2026-01-23T03:20:46.875+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:20:46.876+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:20:46.879+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:20:46.878+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:20:46.918+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:20:46.917+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:20:46.919+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:20:46.919+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:20:46.920+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:20:46.920+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:20:46.924+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:20:46.924+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:20:46.927+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:20:46.926+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:20:46.930+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:20:46.929+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:20:46.931+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:20:46.931+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:20:46.940+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:20:46.932+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:20:46.941+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:20:46.982+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.116 seconds
[2026-01-23T03:21:17.696+0000] {processor.py:161} INFO - Started process (PID=547) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:21:17.697+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:21:17.700+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:21:17.699+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:21:17.735+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:21:17.735+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:21:17.736+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:21:17.736+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:21:17.737+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:21:17.737+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:21:17.741+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:21:17.740+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:21:17.743+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:21:17.743+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:21:17.745+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:21:17.744+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:21:17.745+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:21:17.745+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:21:17.750+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:21:17.745+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:21:17.751+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:21:17.794+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.105 seconds
[2026-01-23T03:21:40.989+0000] {processor.py:161} INFO - Started process (PID=56) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:21:40.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:21:40.995+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:21:40.994+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:21:41.037+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:21:41.037+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:21:41.038+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:21:41.038+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:21:41.039+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:21:41.039+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:21:41.044+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:21:41.043+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:21:41.047+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:21:41.047+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:21:41.050+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:21:41.050+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:21:41.051+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:21:41.050+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:21:41.058+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:21:41.051+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:21:41.058+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:21:41.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.121 seconds
[2026-01-23T03:22:11.496+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:22:11.498+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:22:11.502+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:22:11.502+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:22:11.593+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:22:11.592+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:22:11.596+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:22:11.596+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:22:11.598+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:22:11.598+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:22:11.603+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:22:11.603+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:22:11.608+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:22:11.607+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:22:11.612+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:22:11.612+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:22:11.613+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:22:11.613+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:22:11.623+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:22:11.614+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:22:11.625+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:22:11.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.333 seconds
[2026-01-23T03:22:42.591+0000] {processor.py:161} INFO - Started process (PID=92) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:22:42.593+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:22:42.596+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:22:42.596+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:22:42.637+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:22:42.636+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:22:42.638+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:22:42.637+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:22:42.639+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:22:42.639+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:22:42.643+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:22:42.643+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:22:42.646+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:22:42.646+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:22:42.649+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:22:42.648+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:22:42.649+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:22:42.649+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:22:42.656+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:22:42.650+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:22:42.657+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:22:42.706+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.121 seconds
[2026-01-23T03:23:13.763+0000] {processor.py:161} INFO - Started process (PID=101) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:23:13.765+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:23:13.768+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:23:13.767+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:23:13.819+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:23:13.819+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:23:13.820+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:23:13.820+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:23:13.821+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:23:13.821+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:23:13.826+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:23:13.825+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:23:13.830+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:23:13.830+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:23:13.833+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:23:13.832+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:23:13.834+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:23:13.833+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:23:13.841+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:23:13.834+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:23:13.842+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:23:13.909+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.162 seconds
[2026-01-23T03:23:44.625+0000] {processor.py:161} INFO - Started process (PID=110) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:23:44.627+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:23:44.628+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:23:44.628+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:23:44.660+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:23:44.659+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:23:44.660+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:23:44.660+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:23:44.661+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:23:44.661+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:23:44.664+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:23:44.664+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:23:44.666+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:23:44.666+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:23:44.668+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:23:44.668+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:23:44.669+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:23:44.669+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:23:44.673+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:23:44.669+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:23:44.673+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:23:44.706+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.087 seconds
[2026-01-23T03:24:15.696+0000] {processor.py:161} INFO - Started process (PID=119) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:24:15.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:24:15.706+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:24:15.705+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:24:15.779+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:24:15.778+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:24:15.780+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:24:15.780+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:24:15.784+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:24:15.784+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:24:15.793+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:24:15.792+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:24:15.799+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:24:15.798+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:24:15.802+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:24:15.802+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:24:15.803+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:24:15.803+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:24:15.811+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:24:15.803+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:24:15.812+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:24:15.869+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.183 seconds
[2026-01-23T03:24:46.890+0000] {processor.py:161} INFO - Started process (PID=128) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:24:46.892+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:24:46.894+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:24:46.894+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:24:46.930+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:24:46.930+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:24:46.931+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:24:46.931+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:24:46.932+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:24:46.932+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:24:46.936+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:24:46.936+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:24:46.939+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:24:46.939+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:24:46.942+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:24:46.942+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:24:46.943+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:24:46.943+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:24:46.949+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:24:46.943+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:24:46.950+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:24:46.994+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.110 seconds
[2026-01-23T03:25:18.024+0000] {processor.py:161} INFO - Started process (PID=137) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:25:18.026+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:25:18.028+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:25:18.028+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:25:18.061+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:25:18.060+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:25:18.061+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:25:18.061+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:25:18.062+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:25:18.062+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:25:18.065+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:25:18.065+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:25:18.068+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:25:18.067+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:25:18.070+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:25:18.070+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:25:18.071+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:25:18.070+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:25:18.076+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:25:18.071+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:25:18.077+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:25:18.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.091 seconds
[2026-01-23T03:25:49.195+0000] {processor.py:161} INFO - Started process (PID=146) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:25:49.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:25:49.200+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:25:49.199+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:25:49.235+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:25:49.234+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:25:49.235+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:25:49.235+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:25:49.236+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:25:49.236+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:25:49.239+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:25:49.239+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:25:49.242+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:25:49.241+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:25:49.244+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:25:49.244+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:25:49.245+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:25:49.245+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:25:49.252+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:25:49.245+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:25:49.252+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:25:49.290+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.101 seconds
[2026-01-23T03:26:20.424+0000] {processor.py:161} INFO - Started process (PID=155) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:26:20.425+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:26:20.427+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:26:20.427+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:26:20.459+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:26:20.459+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:26:20.460+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:26:20.460+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:26:20.461+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:26:20.461+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:26:20.465+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:26:20.464+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:26:20.467+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:26:20.467+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:26:20.469+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:26:20.469+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:26:20.469+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:26:20.469+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:26:20.475+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:26:20.470+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:26:20.476+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:26:20.511+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.094 seconds
[2026-01-23T03:26:51.094+0000] {processor.py:161} INFO - Started process (PID=164) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:26:51.096+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:26:51.097+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:26:51.097+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:26:51.122+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:26:51.122+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:26:51.123+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:26:51.123+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:26:51.124+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:26:51.124+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:26:51.126+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:26:51.126+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:26:51.129+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:26:51.128+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:26:51.131+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:26:51.130+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:26:51.131+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:26:51.131+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:26:51.135+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:26:51.132+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:26:51.136+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:26:51.166+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.077 seconds
[2026-01-23T03:27:21.917+0000] {processor.py:161} INFO - Started process (PID=173) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:27:21.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:27:21.920+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:27:21.920+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:27:21.946+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:27:21.946+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:27:21.947+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:27:21.947+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:27:21.948+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:27:21.947+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:27:21.951+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:27:21.951+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:27:21.953+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:27:21.953+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:27:21.955+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:27:21.954+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:27:21.955+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:27:21.955+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:27:21.960+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:27:21.955+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:27:21.960+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:27:21.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.085 seconds
[2026-01-23T03:27:52.708+0000] {processor.py:161} INFO - Started process (PID=182) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:27:52.709+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:27:52.712+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:27:52.711+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:27:52.739+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:27:52.739+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:27:52.740+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:27:52.740+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:27:52.740+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:27:52.740+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:27:52.743+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:27:52.743+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:27:52.745+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:27:52.745+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:27:52.747+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:27:52.747+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:27:52.747+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:27:52.747+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:27:52.752+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:27:52.748+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:27:52.752+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:27:52.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.080 seconds
[2026-01-23T03:28:23.727+0000] {processor.py:161} INFO - Started process (PID=191) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:28:23.728+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:28:23.733+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:28:23.733+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:28:23.778+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:28:23.778+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:28:23.779+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:28:23.779+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:28:23.779+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:28:23.779+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:28:23.783+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:28:23.783+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:28:23.786+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:28:23.785+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:28:23.788+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:28:23.788+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:28:23.789+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:28:23.789+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:28:23.796+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:28:23.790+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:28:23.797+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:28:23.834+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.114 seconds
[2026-01-23T03:28:54.486+0000] {processor.py:161} INFO - Started process (PID=200) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:28:54.488+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:28:54.490+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:28:54.490+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:28:54.521+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:28:54.521+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:28:54.522+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:28:54.522+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:28:54.522+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:28:54.522+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:28:54.525+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:28:54.525+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:28:54.527+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:28:54.527+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:28:54.530+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:28:54.529+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:28:54.530+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:28:54.530+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:28:54.536+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:28:54.531+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:28:54.536+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:28:54.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.089 seconds
[2026-01-23T03:29:25.312+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:29:25.313+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:29:25.317+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:29:25.316+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:29:25.356+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:29:25.356+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:29:25.357+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:29:25.357+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:29:25.358+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:29:25.358+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:29:25.361+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:29:25.361+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:29:25.364+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:29:25.364+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:29:25.366+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:29:25.366+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:29:25.367+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:29:25.366+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:29:25.373+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:29:25.367+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:29:25.374+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:29:25.417+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.112 seconds
[2026-01-23T03:29:56.048+0000] {processor.py:161} INFO - Started process (PID=218) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:29:56.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:29:56.051+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:29:56.051+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:29:56.077+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:29:56.077+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:29:56.078+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:29:56.078+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:29:56.078+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:29:56.078+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:29:56.081+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:29:56.081+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:29:56.083+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:29:56.083+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:29:56.085+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:29:56.084+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:29:56.085+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:29:56.085+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:29:56.089+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:29:56.086+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:29:56.090+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:29:56.120+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.077 seconds
[2026-01-23T03:30:26.384+0000] {processor.py:161} INFO - Started process (PID=227) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:30:26.386+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:30:26.388+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:30:26.387+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:30:26.421+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:30:26.420+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:30:26.421+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:30:26.421+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:30:26.422+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:30:26.422+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:30:26.425+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:30:26.425+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:30:26.427+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:30:26.427+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:30:26.430+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:30:26.429+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:30:26.430+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:30:26.430+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:30:26.436+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:30:26.430+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:30:26.436+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:30:26.468+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.090 seconds
[2026-01-23T03:30:56.912+0000] {processor.py:161} INFO - Started process (PID=236) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:30:56.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:30:56.916+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:30:56.916+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:30:56.941+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:30:56.940+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:30:56.941+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:30:56.941+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:30:56.942+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:30:56.942+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:30:56.945+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:30:56.945+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:30:56.947+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:30:56.947+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:30:56.949+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:30:56.949+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:30:56.950+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:30:56.949+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:30:56.955+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:30:56.950+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:30:56.955+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:30:56.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.083 seconds
[2026-01-23T03:31:27.449+0000] {processor.py:161} INFO - Started process (PID=245) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:31:27.450+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:31:27.452+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:31:27.452+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:31:27.490+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:31:27.489+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:31:27.490+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:31:27.490+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:31:27.491+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:31:27.491+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:31:27.495+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:31:27.494+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:31:27.498+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:31:27.498+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:31:27.502+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:31:27.501+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:31:27.502+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:31:27.502+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:31:27.508+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:31:27.503+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:31:27.509+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:31:27.550+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.108 seconds
[2026-01-23T03:31:58.073+0000] {processor.py:161} INFO - Started process (PID=254) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:31:58.074+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:31:58.076+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:31:58.076+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:31:58.105+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:31:58.104+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:31:58.106+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:31:58.106+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:31:58.107+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:31:58.106+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:31:58.110+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:31:58.110+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:31:58.112+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:31:58.112+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:31:58.114+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:31:58.114+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:31:58.115+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:31:58.115+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:31:58.119+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:31:58.115+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:31:58.120+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:31:58.619+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.552 seconds
[2026-01-23T03:32:28.986+0000] {processor.py:161} INFO - Started process (PID=263) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:32:28.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:32:28.989+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:32:28.988+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:32:29.016+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:32:29.016+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:32:29.017+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:32:29.017+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:32:29.018+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:32:29.017+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:32:29.021+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:32:29.020+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:32:29.023+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:32:29.023+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:32:29.025+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:32:29.025+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:32:29.026+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:32:29.026+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:32:29.032+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:32:29.026+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:32:29.033+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:32:29.072+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.092 seconds
[2026-01-23T03:32:59.440+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:32:59.441+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:32:59.444+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:32:59.443+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:32:59.470+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:32:59.469+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:32:59.470+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:32:59.470+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:32:59.471+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:32:59.471+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:32:59.474+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:32:59.473+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:32:59.475+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:32:59.475+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:32:59.477+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:32:59.477+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:32:59.478+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:32:59.478+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:32:59.482+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:32:59.478+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:32:59.482+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:32:59.512+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.077 seconds
[2026-01-23T03:33:29.849+0000] {processor.py:161} INFO - Started process (PID=282) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:33:29.850+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:33:29.852+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:33:29.852+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:33:29.885+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:33:29.884+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:33:29.886+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:33:29.885+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:33:29.887+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:33:29.886+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:33:29.889+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:33:29.889+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:33:29.892+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:33:29.891+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:33:29.894+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:33:29.893+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:33:29.894+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:33:29.894+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:33:29.899+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:33:29.895+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:33:29.899+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:33:29.938+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.094 seconds
[2026-01-23T03:34:01.172+0000] {processor.py:161} INFO - Started process (PID=292) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:34:01.173+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:34:01.176+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:34:01.176+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:34:01.204+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:34:01.204+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:34:01.205+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:34:01.205+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:34:01.206+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:34:01.205+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:34:01.208+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:34:01.208+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:34:01.210+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:34:01.210+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:34:01.212+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:34:01.212+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:34:01.212+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:34:01.212+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:34:01.217+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:34:01.213+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:34:01.218+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:34:01.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.084 seconds
[2026-01-23T03:34:32.113+0000] {processor.py:161} INFO - Started process (PID=302) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:34:32.114+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:34:32.117+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:34:32.117+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:34:32.157+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:34:32.157+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:34:32.158+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:34:32.158+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:34:32.159+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:34:32.159+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:34:32.163+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:34:32.163+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:34:32.167+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:34:32.166+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:34:32.169+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:34:32.169+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:34:32.170+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:34:32.170+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:34:32.175+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:34:32.170+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:34:32.176+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:34:32.220+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.113 seconds
[2026-01-23T03:35:03.076+0000] {processor.py:161} INFO - Started process (PID=312) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:35:03.078+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:35:03.080+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:35:03.080+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:35:03.114+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:35:03.114+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:35:03.115+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:35:03.115+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:35:03.116+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:35:03.116+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:35:03.120+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:35:03.120+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:35:03.123+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:35:03.123+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:35:03.126+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:35:03.125+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:35:03.126+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:35:03.126+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:35:03.131+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:35:03.127+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:35:03.132+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:35:03.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.101 seconds
[2026-01-23T03:35:33.798+0000] {processor.py:161} INFO - Started process (PID=322) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:35:33.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:35:33.802+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:35:33.801+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:35:33.844+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:35:33.843+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:35:33.845+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:35:33.844+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:35:33.846+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:35:33.846+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:35:33.851+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:35:33.850+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:35:33.856+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:35:33.856+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:35:33.860+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:35:33.859+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:35:33.861+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:35:33.860+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:35:33.870+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:35:33.861+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:35:33.871+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:35:33.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.133 seconds
[2026-01-23T03:36:04.459+0000] {processor.py:161} INFO - Started process (PID=332) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:36:04.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:36:04.462+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:36:04.461+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:36:04.488+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:36:04.488+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:36:04.489+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:36:04.488+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:36:04.489+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:36:04.489+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:36:04.493+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:36:04.492+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:36:04.494+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:36:04.494+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:36:04.497+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:36:04.496+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:36:04.497+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:36:04.497+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:36:04.501+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:36:04.498+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:36:04.502+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:36:04.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.080 seconds
[2026-01-23T03:36:35.016+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:36:35.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:36:35.020+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:36:35.020+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:36:35.058+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:36:35.058+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:36:35.059+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:36:35.059+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:36:35.060+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:36:35.060+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:36:35.064+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:36:35.064+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:36:35.067+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:36:35.067+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:36:35.069+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:36:35.069+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:36:35.070+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:36:35.070+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:36:35.075+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:36:35.070+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:36:35.076+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:36:35.116+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.106 seconds
[2026-01-23T03:37:05.427+0000] {processor.py:161} INFO - Started process (PID=352) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:37:05.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:37:05.430+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:37:05.430+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:37:05.459+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:37:05.459+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:37:05.460+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:37:05.460+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:37:05.461+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:37:05.461+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:37:05.464+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:37:05.463+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:37:05.465+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:37:05.465+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:37:05.467+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:37:05.467+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:37:05.467+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:37:05.467+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:37:05.472+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:37:05.468+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:37:05.473+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:37:05.506+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.084 seconds
[2026-01-23T03:37:36.750+0000] {processor.py:161} INFO - Started process (PID=362) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:37:36.752+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:37:36.754+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:37:36.754+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:37:36.791+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:37:36.791+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:37:36.792+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:37:36.792+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:37:36.793+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:37:36.793+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:37:36.798+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:37:36.798+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:37:36.801+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:37:36.800+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:37:36.803+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:37:36.803+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:37:36.804+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:37:36.804+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:37:36.810+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:37:36.804+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:37:36.811+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:37:36.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.107 seconds
[2026-01-23T03:38:07.244+0000] {processor.py:161} INFO - Started process (PID=372) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:38:07.246+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:38:07.256+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:38:07.255+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:38:07.306+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:38:07.305+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:38:07.307+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:38:07.307+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:38:07.308+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:38:07.308+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:38:07.314+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:38:07.314+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:38:07.318+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:38:07.317+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:38:07.321+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:38:07.320+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:38:07.322+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:38:07.321+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:38:07.330+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:38:07.322+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:38:07.331+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:38:07.381+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.145 seconds
[2026-01-23T03:38:37.745+0000] {processor.py:161} INFO - Started process (PID=382) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:38:37.746+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:38:37.748+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:38:37.748+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:38:37.782+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:38:37.782+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:38:37.783+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:38:37.783+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:38:37.784+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:38:37.784+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:38:37.787+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:38:37.787+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:38:37.790+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:38:37.790+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:38:37.792+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:38:37.792+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:38:37.793+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:38:37.793+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:38:37.799+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:38:37.794+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:38:37.800+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:38:37.861+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.121 seconds
[2026-01-23T03:39:08.463+0000] {processor.py:161} INFO - Started process (PID=392) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:39:08.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:39:08.468+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:39:08.467+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:39:08.520+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:39:08.519+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:39:08.521+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:39:08.521+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:39:08.522+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:39:08.522+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:39:08.527+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:39:08.526+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:39:08.531+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:39:08.530+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:39:08.533+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:39:08.533+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:39:08.534+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:39:08.534+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:39:08.540+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:39:08.535+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:39:08.541+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:39:08.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.141 seconds
[2026-01-23T03:39:38.874+0000] {processor.py:161} INFO - Started process (PID=402) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:39:38.876+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:39:38.881+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:39:38.880+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:39:38.937+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:39:38.937+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:39:38.938+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:39:38.938+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:39:38.940+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:39:38.939+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:39:38.944+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:39:38.944+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:39:38.948+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:39:38.948+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:39:38.952+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:39:38.952+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:39:38.954+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:39:38.953+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:39:38.961+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:39:38.954+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:39:38.962+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:39:39.026+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.163 seconds
[2026-01-23T03:40:09.758+0000] {processor.py:161} INFO - Started process (PID=412) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:40:09.759+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:40:09.762+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:40:09.762+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:40:09.794+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:40:09.794+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:40:09.795+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:40:09.794+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:40:09.796+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:40:09.795+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:40:09.800+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:40:09.800+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:40:09.802+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:40:09.802+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:40:09.805+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:40:09.805+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:40:09.805+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:40:09.805+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:40:09.810+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:40:09.806+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:40:09.811+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:40:09.842+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.089 seconds
[2026-01-23T03:40:40.261+0000] {processor.py:161} INFO - Started process (PID=422) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:40:40.262+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:40:40.264+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:40:40.264+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:40:40.298+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:40:40.298+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:40:40.299+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:40:40.299+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:40:40.300+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:40:40.299+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:40:40.307+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:40:40.306+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:40:40.309+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:40:40.309+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:40:40.311+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:40:40.311+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:40:40.312+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:40:40.311+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:40:40.316+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:40:40.312+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:40:40.317+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:40:40.364+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.109 seconds
[2026-01-23T03:41:10.813+0000] {processor.py:161} INFO - Started process (PID=432) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:41:10.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:41:10.816+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:41:10.816+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:41:10.846+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:41:10.845+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:41:10.846+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:41:10.846+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:41:10.847+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:41:10.847+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:41:10.850+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:41:10.849+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:41:10.851+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:41:10.851+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:41:10.853+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:41:10.853+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:41:10.854+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:41:10.853+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:41:10.858+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:41:10.854+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:41:10.858+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:41:10.889+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.081 seconds
[2026-01-23T03:41:41.474+0000] {processor.py:161} INFO - Started process (PID=442) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:41:41.475+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:41:41.478+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:41:41.477+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:41:41.503+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:41:41.503+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:41:41.504+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:41:41.503+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:41:41.504+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:41:41.504+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:41:41.508+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:41:41.507+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:41:41.510+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:41:41.509+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:41:41.512+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:41:41.511+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:41:41.512+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:41:41.512+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:41:41.516+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:41:41.512+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:41:41.517+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:41:41.551+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.082 seconds
[2026-01-23T03:42:12.040+0000] {processor.py:161} INFO - Started process (PID=452) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:42:12.042+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:42:12.044+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:42:12.043+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:42:12.071+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:42:12.070+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:42:12.071+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:42:12.071+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:42:12.072+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:42:12.072+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:42:12.075+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:42:12.075+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:42:12.077+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:42:12.077+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:42:12.079+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:42:12.079+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:42:12.079+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:42:12.079+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:42:12.083+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:42:12.080+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:42:12.084+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:42:12.115+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.080 seconds
[2026-01-23T03:42:42.522+0000] {processor.py:161} INFO - Started process (PID=462) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:42:42.524+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:42:42.527+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:42:42.526+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:42:42.556+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:42:42.556+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:42:42.557+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:42:42.557+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:42:42.558+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:42:42.557+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:42:42.561+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:42:42.561+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:42:42.563+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:42:42.563+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:42:42.565+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:42:42.565+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:42:42.565+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:42:42.565+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:42:42.570+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:42:42.566+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:42:42.570+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:42:42.611+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.097 seconds
[2026-01-23T03:43:13.291+0000] {processor.py:161} INFO - Started process (PID=473) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:43:13.293+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:43:13.295+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:43:13.295+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:43:13.332+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:43:13.332+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:43:13.333+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:43:13.333+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:43:13.334+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:43:13.334+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:43:13.337+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:43:13.337+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:43:13.339+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:43:13.339+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:43:13.342+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:43:13.342+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:43:13.343+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:43:13.343+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:43:13.348+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:43:13.343+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:43:13.349+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:43:13.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.102 seconds
[2026-01-23T03:43:44.074+0000] {processor.py:161} INFO - Started process (PID=483) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:43:44.075+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:43:44.078+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:43:44.078+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:43:44.118+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:43:44.118+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:43:44.119+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:43:44.119+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:43:44.120+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:43:44.120+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:43:44.126+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:43:44.125+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:43:44.128+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:43:44.128+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:43:44.131+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:43:44.131+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:43:44.132+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:43:44.132+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:43:44.140+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:43:44.132+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:43:44.141+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:43:44.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.119 seconds
[2026-01-23T03:44:14.963+0000] {processor.py:161} INFO - Started process (PID=493) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:44:14.965+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:44:14.967+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:44:14.966+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:44:15.000+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:44:14.999+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:44:15.001+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:44:15.000+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:44:15.001+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:44:15.001+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:44:15.005+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:44:15.005+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:44:15.007+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:44:15.007+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:44:15.009+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:44:15.008+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:44:15.009+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:44:15.009+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:44:15.013+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:44:15.009+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:44:15.013+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:44:15.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.087 seconds
[2026-01-23T03:44:45.623+0000] {processor.py:161} INFO - Started process (PID=503) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:44:45.624+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:44:45.626+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:44:45.626+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:44:45.658+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:44:45.658+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:44:45.659+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:44:45.659+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:44:45.660+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:44:45.660+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:44:45.664+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:44:45.664+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:44:45.666+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:44:45.665+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:44:45.668+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:44:45.667+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:44:45.668+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:44:45.668+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:44:45.672+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:44:45.669+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:44:45.673+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:44:45.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.085 seconds
[2026-01-23T03:45:16.250+0000] {processor.py:161} INFO - Started process (PID=513) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:45:16.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:45:16.255+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:45:16.254+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:45:16.282+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:45:16.282+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:45:16.283+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:45:16.283+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:45:16.284+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:45:16.284+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:45:16.288+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:45:16.288+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:45:16.290+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:45:16.290+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:45:16.291+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:45:16.291+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:45:16.292+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:45:16.292+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:45:16.296+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:45:16.292+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:45:16.296+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:45:16.327+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.083 seconds
[2026-01-23T03:45:46.433+0000] {processor.py:161} INFO - Started process (PID=523) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:45:46.435+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:45:46.438+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:45:46.437+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:45:46.480+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:45:46.480+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:45:46.481+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:45:46.481+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:45:46.482+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:45:46.482+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:45:46.488+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:45:46.487+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:45:46.490+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:45:46.490+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:45:46.492+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:45:46.492+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:45:46.493+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:45:46.493+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:45:46.501+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:45:46.495+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:45:46.502+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:45:46.537+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.109 seconds
[2026-01-23T03:46:17.016+0000] {processor.py:161} INFO - Started process (PID=533) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:46:17.018+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:46:17.020+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:46:17.020+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:46:17.064+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:46:17.063+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:46:17.065+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:46:17.064+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:46:17.065+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:46:17.065+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:46:17.070+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:46:17.070+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:46:17.073+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:46:17.072+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:46:17.075+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:46:17.075+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:46:17.076+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:46:17.075+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:46:17.080+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:46:17.076+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:46:17.081+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:46:17.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.099 seconds
[2026-01-23T03:46:47.730+0000] {processor.py:161} INFO - Started process (PID=543) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:46:47.731+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:46:47.735+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:46:47.734+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:46:47.790+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:46:47.790+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:46:47.792+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:46:47.792+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:46:47.794+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:46:47.793+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:46:47.802+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:46:47.801+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:46:47.809+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:46:47.808+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:46:47.814+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:46:47.813+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:46:47.816+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:46:47.816+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:46:47.833+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:46:47.818+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:46:47.836+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:46:47.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.198 seconds
[2026-01-23T03:47:18.808+0000] {processor.py:161} INFO - Started process (PID=553) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:47:18.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:47:18.811+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:47:18.811+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:47:18.850+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:47:18.850+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:47:18.851+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:47:18.851+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:47:18.852+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:47:18.852+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:47:18.856+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:47:18.856+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:47:18.862+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:47:18.861+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:47:18.865+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:47:18.865+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:47:18.866+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:47:18.866+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:47:18.873+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:47:18.866+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:47:18.873+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:47:18.941+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.139 seconds
[2026-01-23T03:47:49.637+0000] {processor.py:161} INFO - Started process (PID=563) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:47:49.638+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:47:49.641+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:47:49.641+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:47:49.691+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:47:49.691+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:47:49.693+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:47:49.692+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:47:49.694+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:47:49.694+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:47:49.699+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:47:49.698+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:47:49.702+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:47:49.702+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:47:49.705+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:47:49.705+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:47:49.706+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:47:49.706+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:47:49.712+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:47:49.706+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:47:49.713+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:47:49.753+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.125 seconds
[2026-01-23T03:48:20.240+0000] {processor.py:161} INFO - Started process (PID=573) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:48:20.241+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:48:20.244+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:48:20.244+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:48:20.282+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:48:20.281+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:48:20.283+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:48:20.283+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:48:20.285+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:48:20.285+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:48:20.289+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:48:20.289+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:48:20.293+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:48:20.292+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:48:20.296+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:48:20.296+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:48:20.297+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:48:20.297+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:48:20.305+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:48:20.297+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:48:20.306+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:48:20.352+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.118 seconds
[2026-01-23T03:48:50.735+0000] {processor.py:161} INFO - Started process (PID=583) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:48:50.737+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:48:50.739+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:48:50.739+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:48:50.783+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:48:50.783+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:48:50.784+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:48:50.784+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:48:50.785+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:48:50.785+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:48:50.790+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:48:50.789+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:48:50.792+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:48:50.792+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:48:50.795+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:48:50.794+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:48:50.795+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:48:50.795+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:48:50.801+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:48:50.796+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:48:50.802+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:48:50.842+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.113 seconds
[2026-01-23T03:49:21.489+0000] {processor.py:161} INFO - Started process (PID=593) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:49:21.491+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:49:21.492+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:49:21.492+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:49:21.526+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:49:21.525+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:49:21.527+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:49:21.526+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:49:21.528+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:49:21.528+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:49:21.557+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:49:21.556+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:49:21.751+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:49:21.750+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:49:21.754+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:49:21.754+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:49:21.755+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:49:21.755+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:49:21.761+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:49:21.756+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:49:21.761+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:49:22.812+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 1.328 seconds
[2026-01-23T03:49:53.513+0000] {processor.py:161} INFO - Started process (PID=603) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:49:53.514+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:49:53.516+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:49:53.516+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:49:53.548+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:49:53.547+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:49:53.548+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:49:53.548+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:49:53.549+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:49:53.549+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:49:53.552+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:49:53.552+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:49:53.555+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:49:53.554+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:49:53.557+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:49:53.557+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:49:53.557+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:49:53.557+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:49:53.563+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:49:53.558+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:49:53.563+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:49:53.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.088 seconds
[2026-01-23T03:50:24.090+0000] {processor.py:161} INFO - Started process (PID=613) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:50:24.091+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:50:24.094+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:50:24.094+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:50:24.136+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:50:24.135+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:50:24.136+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:50:24.136+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:50:24.137+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:50:24.137+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:50:24.141+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:50:24.141+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:50:24.143+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:50:24.143+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:50:24.145+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:50:24.145+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:50:24.146+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:50:24.146+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:50:24.150+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:50:24.146+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:50:24.151+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:50:24.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.100 seconds
[2026-01-23T03:50:54.764+0000] {processor.py:161} INFO - Started process (PID=623) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:50:54.765+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:50:54.767+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:50:54.767+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:50:54.804+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:50:54.804+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:50:54.805+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:50:54.805+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:50:54.806+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:50:54.806+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:50:54.811+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:50:54.811+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:50:54.813+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:50:54.813+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:50:54.815+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:50:54.815+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:50:54.816+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:50:54.816+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:50:54.820+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:50:54.816+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:50:54.820+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:50:54.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.092 seconds
[2026-01-23T03:51:25.424+0000] {processor.py:161} INFO - Started process (PID=633) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:51:25.425+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:51:25.428+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:51:25.427+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:51:25.465+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:51:25.464+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:51:25.465+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:51:25.465+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:51:25.466+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:51:25.466+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:51:25.469+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:51:25.469+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:51:25.471+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:51:25.471+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:51:25.473+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:51:25.473+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:51:25.473+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:51:25.473+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:51:25.477+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:51:25.474+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:51:25.478+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:51:25.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.091 seconds
[2026-01-23T03:51:55.628+0000] {processor.py:161} INFO - Started process (PID=643) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:51:55.630+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:51:55.633+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:51:55.633+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:51:55.666+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:51:55.665+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:51:55.667+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:51:55.666+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:51:55.667+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:51:55.667+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:51:55.670+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:51:55.670+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:51:55.673+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:51:55.672+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:51:55.675+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:51:55.675+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:51:55.676+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:51:55.676+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:51:55.681+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:51:55.676+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:51:55.681+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:51:55.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.093 seconds
[2026-01-23T03:52:26.401+0000] {processor.py:161} INFO - Started process (PID=653) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:52:26.402+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:52:26.404+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:52:26.404+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:52:26.440+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:52:26.439+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:52:26.440+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:52:26.440+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:52:26.441+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:52:26.441+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:52:26.445+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:52:26.444+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:52:26.447+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:52:26.447+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:52:26.449+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:52:26.449+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:52:26.449+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:52:26.449+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:52:26.455+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:52:26.450+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:52:26.456+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:52:26.493+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.098 seconds
[2026-01-23T03:52:57.153+0000] {processor.py:161} INFO - Started process (PID=663) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:52:57.154+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:52:57.156+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:52:57.156+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:52:57.190+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:52:57.189+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:52:57.190+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:52:57.190+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:52:57.191+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:52:57.191+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:52:57.194+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:52:57.194+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:52:57.196+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:52:57.196+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:52:57.198+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:52:57.198+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:52:57.199+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:52:57.199+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:52:57.203+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:52:57.199+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:52:57.204+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:52:57.238+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.090 seconds
[2026-01-23T03:53:27.853+0000] {processor.py:161} INFO - Started process (PID=673) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:53:27.855+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:53:27.858+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:53:27.857+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:53:27.893+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:53:27.892+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:53:27.894+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:53:27.894+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:53:27.895+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:53:27.895+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:53:27.903+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:53:27.902+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:53:27.905+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:53:27.905+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:53:27.908+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:53:27.908+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:53:27.909+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:53:27.909+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:53:27.916+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:53:27.909+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:53:27.917+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:53:27.969+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.122 seconds
[2026-01-23T03:53:58.744+0000] {processor.py:161} INFO - Started process (PID=683) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:53:58.745+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:53:58.748+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:53:58.747+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:53:58.783+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:53:58.782+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:53:58.784+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:53:58.783+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:53:58.785+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:53:58.784+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:53:58.788+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:53:58.788+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:53:58.791+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:53:58.791+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:53:58.793+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:53:58.793+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:53:58.793+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:53:58.793+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:53:58.798+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:53:58.794+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:53:58.799+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:53:58.835+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.096 seconds
[2026-01-23T03:54:29.516+0000] {processor.py:161} INFO - Started process (PID=693) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:54:29.517+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:54:29.520+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:54:29.520+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:54:29.552+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:54:29.552+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:54:29.553+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:54:29.553+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:54:29.554+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:54:29.554+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:54:29.557+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:54:29.557+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:54:29.559+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:54:29.559+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:54:29.561+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:54:29.561+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:54:29.562+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:54:29.562+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:54:29.567+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:54:29.562+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:54:29.567+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:54:29.602+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.092 seconds
[2026-01-23T03:55:00.288+0000] {processor.py:161} INFO - Started process (PID=703) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:55:00.289+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T03:55:00.291+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:55:00.291+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:55:00.328+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:55:00.327+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T03:55:00.328+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:55:00.328+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T03:55:00.329+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:55:00.329+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T03:55:00.333+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:55:00.333+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:55:00.335+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:55:00.335+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:55:00.337+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:55:00.337+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T03:55:00.338+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:55:00.338+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T03:55:00.343+0000] {logging_mixin.py:188} INFO - [2026-01-23T03:55:00.338+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T03:55:00.344+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T03:55:00.379+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.097 seconds
[2026-01-23T04:12:36.108+0000] {processor.py:161} INFO - Started process (PID=708) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:12:36.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:12:36.114+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:12:36.113+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:12:36.163+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:12:36.163+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:12:36.164+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:12:36.164+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:12:36.165+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:12:36.165+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:12:36.170+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:12:36.170+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:12:36.175+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:12:36.174+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:12:36.179+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:12:36.179+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:12:36.180+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:12:36.180+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:12:36.187+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:12:36.181+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:12:36.189+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:12:36.235+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.143 seconds
[2026-01-23T04:13:06.503+0000] {processor.py:161} INFO - Started process (PID=718) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:13:06.504+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:13:06.507+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:13:06.507+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:13:06.543+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:13:06.543+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:13:06.544+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:13:06.544+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:13:06.545+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:13:06.545+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:13:06.548+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:13:06.548+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:13:06.551+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:13:06.551+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:13:06.553+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:13:06.553+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:13:06.554+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:13:06.554+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:13:06.561+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:13:06.555+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:13:06.562+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:13:06.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.100 seconds
[2026-01-23T04:13:37.329+0000] {processor.py:161} INFO - Started process (PID=728) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:13:37.331+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:13:37.334+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:13:37.334+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:13:37.367+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:13:37.366+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:13:37.367+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:13:37.367+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:13:37.368+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:13:37.368+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:13:37.373+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:13:37.372+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:13:37.375+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:13:37.375+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:13:37.378+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:13:37.378+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:13:37.379+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:13:37.379+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:13:37.384+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:13:37.379+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:13:37.385+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:13:37.430+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.107 seconds
[2026-01-23T04:14:08.001+0000] {processor.py:161} INFO - Started process (PID=738) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:14:08.002+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:14:08.004+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:14:08.003+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:14:08.033+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:14:08.032+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:14:08.033+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:14:08.033+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:14:08.034+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:14:08.034+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:14:08.037+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:14:08.037+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:14:08.039+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:14:08.039+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:14:08.041+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:14:08.041+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:14:08.042+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:14:08.042+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:14:08.048+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:14:08.042+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:14:08.049+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:14:08.085+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.090 seconds
[2026-01-23T04:14:38.635+0000] {processor.py:161} INFO - Started process (PID=748) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:14:38.636+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:14:38.639+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:14:38.638+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:14:38.667+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:14:38.667+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:14:38.668+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:14:38.668+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:14:38.669+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:14:38.669+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:14:38.672+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:14:38.672+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:14:38.675+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:14:38.674+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:14:38.676+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:14:38.676+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:14:38.677+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:14:38.677+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:14:38.682+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:14:38.677+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:14:38.683+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:14:38.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.084 seconds
[2026-01-23T04:15:09.643+0000] {processor.py:161} INFO - Started process (PID=758) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:15:09.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:15:09.646+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:15:09.645+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:15:09.676+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:15:09.675+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:15:09.676+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:15:09.676+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:15:09.677+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:15:09.677+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:15:09.680+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:15:09.680+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:15:09.682+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:15:09.682+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:15:09.684+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:15:09.684+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:15:09.685+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:15:09.685+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:15:09.691+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:15:09.685+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:15:09.692+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:15:09.726+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.088 seconds
[2026-01-23T04:15:40.452+0000] {processor.py:161} INFO - Started process (PID=768) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:15:40.453+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:15:40.455+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:15:40.455+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:15:40.485+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:15:40.485+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:15:40.486+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:15:40.486+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:15:40.487+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:15:40.487+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:15:40.490+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:15:40.490+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:15:40.492+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:15:40.492+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:15:40.494+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:15:40.494+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:15:40.495+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:15:40.495+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:15:40.499+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:15:40.495+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:15:40.500+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:15:40.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.093 seconds
[2026-01-23T04:16:11.045+0000] {processor.py:161} INFO - Started process (PID=778) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:16:11.046+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:16:11.048+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:16:11.048+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:16:11.082+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:16:11.081+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:16:11.082+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:16:11.082+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:16:11.083+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:16:11.083+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:16:11.087+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:16:11.086+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:16:11.089+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:16:11.089+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:16:11.091+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:16:11.090+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:16:11.091+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:16:11.091+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:16:11.095+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:16:11.091+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:16:11.096+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:16:11.131+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.091 seconds
[2026-01-23T04:16:41.927+0000] {processor.py:161} INFO - Started process (PID=788) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:16:41.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:16:41.931+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:16:41.930+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:16:41.962+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:16:41.962+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:16:41.963+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:16:41.963+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:16:41.964+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:16:41.964+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:16:41.968+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:16:41.968+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:16:41.971+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:16:41.971+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:16:41.974+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:16:41.974+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:16:41.975+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:16:41.975+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:16:41.983+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:16:41.976+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:16:41.984+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:16:42.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.098 seconds
[2026-01-23T04:17:12.705+0000] {processor.py:161} INFO - Started process (PID=798) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:17:12.706+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:17:12.708+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:17:12.708+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:17:12.737+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:17:12.736+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:17:12.737+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:17:12.737+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:17:12.738+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:17:12.738+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:17:12.742+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:17:12.742+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:17:12.745+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:17:12.745+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:17:12.747+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:17:12.747+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:17:12.747+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:17:12.747+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:17:12.752+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:17:12.748+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:17:12.752+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:17:12.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.082 seconds
[2026-01-23T04:17:43.610+0000] {processor.py:161} INFO - Started process (PID=808) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:17:43.611+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:17:43.613+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:17:43.613+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:17:43.646+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:17:43.646+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:17:43.647+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:17:43.647+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:17:43.647+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:17:43.647+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:17:43.651+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:17:43.651+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:17:43.655+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:17:43.654+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:17:43.657+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:17:43.657+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:17:43.658+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:17:43.658+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:17:43.663+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:17:43.658+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:17:43.664+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:17:43.708+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.103 seconds
[2026-01-23T04:18:14.390+0000] {processor.py:161} INFO - Started process (PID=818) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:18:14.391+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:18:14.394+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:18:14.393+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:18:14.437+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:18:14.437+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:18:14.438+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:18:14.438+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:18:14.439+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:18:14.439+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:18:14.442+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:18:14.442+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:18:14.445+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:18:14.445+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:18:14.447+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:18:14.447+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:18:14.448+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:18:14.448+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:18:14.455+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:18:14.448+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:18:14.455+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:18:14.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.114 seconds
[2026-01-23T04:18:45.066+0000] {processor.py:161} INFO - Started process (PID=828) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:18:45.067+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:18:45.070+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:18:45.070+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:18:45.096+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:18:45.096+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:18:45.097+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:18:45.096+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:18:45.097+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:18:45.097+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:18:45.100+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:18:45.100+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:18:45.102+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:18:45.102+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:18:45.103+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:18:45.103+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:18:45.104+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:18:45.104+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:18:45.108+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:18:45.104+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:18:45.109+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:18:45.142+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.081 seconds
[2026-01-23T04:19:15.936+0000] {processor.py:161} INFO - Started process (PID=838) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:19:15.938+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:19:15.940+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:19:15.939+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:19:15.968+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:19:15.968+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:19:15.969+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:19:15.969+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:19:15.970+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:19:15.970+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:19:15.973+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:19:15.972+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:19:15.975+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:19:15.974+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:19:15.976+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:19:15.976+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:19:15.977+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:19:15.977+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:19:15.980+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:19:15.977+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:19:15.981+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:19:16.012+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.081 seconds
[2026-01-23T04:19:46.786+0000] {processor.py:161} INFO - Started process (PID=848) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:19:46.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:19:46.788+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:19:46.788+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:19:46.814+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:19:46.814+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:19:46.815+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:19:46.814+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:19:46.815+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:19:46.815+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:19:46.818+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:19:46.818+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:19:46.820+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:19:46.820+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:19:46.822+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:19:46.822+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:19:46.822+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:19:46.822+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:19:46.826+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:19:46.823+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:19:46.827+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:19:46.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.077 seconds
[2026-01-23T04:20:17.530+0000] {processor.py:161} INFO - Started process (PID=858) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:20:17.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:20:17.534+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:20:17.534+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:20:17.568+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:20:17.567+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:20:17.568+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:20:17.568+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:20:17.569+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:20:17.569+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:20:17.572+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:20:17.572+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:20:17.575+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:20:17.575+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:20:17.578+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:20:17.577+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:20:17.578+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:20:17.578+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:20:17.583+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:20:17.579+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:20:17.583+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:20:17.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.087 seconds
[2026-01-23T04:20:48.251+0000] {processor.py:161} INFO - Started process (PID=868) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:20:48.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:20:48.255+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:20:48.255+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:20:48.288+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:20:48.287+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:20:48.288+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:20:48.288+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:20:48.289+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:20:48.289+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:20:48.293+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:20:48.293+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:20:48.296+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:20:48.296+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:20:48.300+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:20:48.300+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:20:48.301+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:20:48.301+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:20:48.307+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:20:48.301+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:20:48.307+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:20:48.347+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.102 seconds
[2026-01-23T04:21:19.066+0000] {processor.py:161} INFO - Started process (PID=878) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:21:19.068+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:21:19.070+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:21:19.070+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:21:19.096+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:21:19.095+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:21:19.096+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:21:19.096+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:21:19.097+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:21:19.097+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:21:19.100+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:21:19.100+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:21:19.102+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:21:19.102+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:21:19.104+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:21:19.104+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:21:19.105+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:21:19.105+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:21:19.109+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:21:19.105+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:21:19.110+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:21:19.150+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.089 seconds
[2026-01-23T04:21:50.111+0000] {processor.py:161} INFO - Started process (PID=888) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:21:50.113+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:21:50.115+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:21:50.114+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:21:50.171+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:21:50.170+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:21:50.172+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:21:50.171+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:21:50.173+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:21:50.173+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:21:50.178+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:21:50.178+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:21:50.182+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:21:50.182+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:21:50.186+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:21:50.185+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:21:50.186+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:21:50.186+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:21:50.195+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:21:50.187+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:21:50.195+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:21:50.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.138 seconds
[2026-01-23T04:22:20.617+0000] {processor.py:161} INFO - Started process (PID=898) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:22:20.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:22:20.621+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:22:20.621+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:22:20.655+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:22:20.655+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:22:20.656+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:22:20.656+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:22:20.657+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:22:20.657+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:22:20.660+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:22:20.660+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:22:20.663+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:22:20.663+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:22:20.665+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:22:20.665+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:22:20.666+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:22:20.666+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:22:20.671+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:22:20.666+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:22:20.672+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:22:20.711+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.101 seconds
[2026-01-23T04:22:51.498+0000] {processor.py:161} INFO - Started process (PID=908) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:22:51.500+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:22:51.502+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:22:51.502+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:22:51.538+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:22:51.538+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:22:51.539+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:22:51.539+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:22:51.540+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:22:51.539+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:22:51.543+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:22:51.543+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:22:51.545+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:22:51.545+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:22:51.547+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:22:51.547+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:22:51.548+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:22:51.548+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:22:51.554+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:22:51.549+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:22:51.555+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:22:51.592+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.101 seconds
[2026-01-23T04:23:22.354+0000] {processor.py:161} INFO - Started process (PID=918) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:23:22.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:23:22.357+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:23:22.357+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:23:22.384+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:23:22.384+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:23:22.385+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:23:22.385+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:23:22.385+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:23:22.385+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:23:22.388+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:23:22.388+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:23:22.390+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:23:22.390+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:23:22.392+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:23:22.392+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:23:22.393+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:23:22.393+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:23:22.398+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:23:22.393+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:23:22.398+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:23:22.567+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.218 seconds
[2026-01-23T04:23:53.300+0000] {processor.py:161} INFO - Started process (PID=928) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:23:53.302+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:23:53.304+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:23:53.304+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:23:53.337+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:23:53.336+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:23:53.338+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:23:53.337+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:23:53.338+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:23:53.338+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:23:53.343+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:23:53.342+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:23:53.346+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:23:53.346+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:23:53.349+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:23:53.349+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:23:53.350+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:23:53.350+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:23:53.357+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:23:53.350+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:23:53.358+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:23:53.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.105 seconds
[2026-01-23T04:24:24.005+0000] {processor.py:161} INFO - Started process (PID=938) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:24:24.006+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:24:24.008+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:24:24.007+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:24:24.035+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:24:24.035+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:24:24.036+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:24:24.035+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:24:24.036+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:24:24.036+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:24:24.039+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:24:24.039+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:24:24.041+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:24:24.041+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:24:24.044+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:24:24.044+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:24:24.045+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:24:24.045+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:24:24.049+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:24:24.045+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:24:24.050+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:24:24.079+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.080 seconds
[2026-01-23T04:24:55.026+0000] {processor.py:161} INFO - Started process (PID=948) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:24:55.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:24:55.028+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:24:55.028+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:24:55.054+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:24:55.053+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:24:55.054+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:24:55.054+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:24:55.055+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:24:55.055+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:24:55.058+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:24:55.058+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:24:55.061+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:24:55.061+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:24:55.063+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:24:55.063+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:24:55.064+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:24:55.064+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:24:55.071+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:24:55.064+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:24:55.072+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:24:55.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.089 seconds
[2026-01-23T04:25:25.936+0000] {processor.py:161} INFO - Started process (PID=958) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:25:25.937+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:25:25.939+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:25:25.939+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:25:25.967+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:25:25.967+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:25:25.968+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:25:25.968+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:25:25.969+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:25:25.968+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:25:25.971+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:25:25.971+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:25:25.973+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:25:25.973+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:25:25.975+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:25:25.975+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:25:25.976+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:25:25.975+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:25:25.980+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:25:25.976+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:25:25.980+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:25:26.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.080 seconds
[2026-01-23T04:25:56.831+0000] {processor.py:161} INFO - Started process (PID=968) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:25:56.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:25:56.834+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:25:56.834+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:25:56.867+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:25:56.867+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:25:56.868+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:25:56.868+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:25:56.869+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:25:56.869+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:25:56.872+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:25:56.872+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:25:56.874+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:25:56.874+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:25:56.877+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:25:56.877+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:25:56.878+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:25:56.877+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:25:56.882+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:25:56.878+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:25:56.883+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:25:56.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.088 seconds
[2026-01-23T04:26:28.260+0000] {processor.py:161} INFO - Started process (PID=978) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:26:28.261+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:26:28.264+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:26:28.263+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:26:28.306+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:26:28.306+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:26:28.307+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:26:28.307+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:26:28.308+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:26:28.308+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:26:28.312+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:26:28.312+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:26:28.314+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:26:28.314+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:26:28.316+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:26:28.316+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:26:28.316+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:26:28.316+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:26:28.323+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:26:28.317+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:26:28.323+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:26:28.364+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.110 seconds
[2026-01-23T04:26:58.816+0000] {processor.py:161} INFO - Started process (PID=988) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:26:58.818+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:26:58.821+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:26:58.821+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:26:58.861+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:26:58.860+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:26:58.862+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:26:58.862+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:26:58.863+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:26:58.863+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:26:58.867+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:26:58.867+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:26:58.870+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:26:58.870+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:26:58.873+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:26:58.872+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:26:58.873+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:26:58.873+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:26:58.879+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:26:58.874+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:26:58.880+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:26:58.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.113 seconds
[2026-01-23T04:27:29.510+0000] {processor.py:161} INFO - Started process (PID=998) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:27:29.513+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:27:29.516+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:27:29.516+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:27:29.568+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:27:29.567+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:27:29.569+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:27:29.568+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:27:29.570+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:27:29.569+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:27:29.573+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:27:29.573+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:27:29.575+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:27:29.575+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:27:29.578+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:27:29.578+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:27:29.579+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:27:29.579+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:27:29.584+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:27:29.579+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:27:29.584+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:27:29.619+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.118 seconds
[2026-01-23T04:28:00.340+0000] {processor.py:161} INFO - Started process (PID=1008) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:28:00.342+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:28:00.344+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:28:00.344+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:28:00.376+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:28:00.376+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:28:00.377+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:28:00.377+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:28:00.378+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:28:00.378+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:28:00.381+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:28:00.380+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:28:00.383+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:28:00.383+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:28:00.385+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:28:00.385+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:28:00.386+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:28:00.385+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:28:00.390+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:28:00.386+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:28:00.391+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:28:00.435+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.102 seconds
[2026-01-23T04:28:31.111+0000] {processor.py:161} INFO - Started process (PID=1019) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:28:31.113+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:28:31.115+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:28:31.114+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:28:31.147+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:28:31.147+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:28:31.148+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:28:31.148+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:28:31.149+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:28:31.149+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:28:31.152+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:28:31.152+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:28:31.154+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:28:31.154+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:28:31.156+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:28:31.156+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:28:31.156+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:28:31.156+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:28:31.161+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:28:31.157+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:28:31.161+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:28:31.190+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.084 seconds
[2026-01-23T04:29:01.655+0000] {processor.py:161} INFO - Started process (PID=1029) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:29:01.657+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:29:01.659+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:29:01.659+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:29:01.686+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:29:01.685+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:29:01.686+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:29:01.686+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:29:01.687+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:29:01.687+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:29:01.691+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:29:01.691+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:29:01.694+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:29:01.693+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:29:01.696+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:29:01.695+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:29:01.697+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:29:01.697+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:29:01.701+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:29:01.697+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:29:01.702+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:29:01.741+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.091 seconds
[2026-01-23T04:29:32.098+0000] {processor.py:161} INFO - Started process (PID=1039) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:29:32.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:29:32.102+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:29:32.101+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:29:32.132+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:29:32.131+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:29:32.132+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:29:32.132+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:29:32.133+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:29:32.133+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:29:32.136+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:29:32.136+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:29:32.138+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:29:32.138+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:29:32.141+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:29:32.140+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:29:32.141+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:29:32.141+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:29:32.145+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:29:32.141+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:29:32.146+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:29:32.177+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.084 seconds
[2026-01-23T04:30:03.636+0000] {processor.py:161} INFO - Started process (PID=1049) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:30:03.637+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:30:03.639+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:30:03.639+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:30:03.672+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:30:03.672+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:30:03.673+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:30:03.673+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:30:03.673+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:30:03.673+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:30:03.676+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:30:03.676+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:30:03.679+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:30:03.679+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:30:03.681+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:30:03.681+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:30:03.682+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:30:03.682+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:30:03.686+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:30:03.682+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:30:03.687+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:30:03.722+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.092 seconds
[2026-01-23T04:30:34.097+0000] {processor.py:161} INFO - Started process (PID=1059) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:30:34.098+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:30:34.100+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:30:34.100+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:30:34.134+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:30:34.134+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:30:34.135+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:30:34.134+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:30:34.135+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:30:34.135+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:30:34.138+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:30:34.138+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:30:34.140+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:30:34.140+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:30:34.142+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:30:34.142+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:30:34.142+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:30:34.142+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:30:34.147+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:30:34.143+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:30:34.147+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:30:34.177+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.085 seconds
[2026-01-23T04:31:04.726+0000] {processor.py:161} INFO - Started process (PID=1069) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:31:04.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:31:04.730+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:31:04.729+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:31:04.781+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:31:04.781+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:31:04.782+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:31:04.782+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:31:04.783+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:31:04.783+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:31:04.788+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:31:04.787+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:31:04.791+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:31:04.791+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:31:04.794+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:31:04.794+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:31:04.794+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:31:04.794+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:31:04.801+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:31:04.795+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:31:04.802+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:31:04.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.135 seconds
[2026-01-23T04:31:35.039+0000] {processor.py:161} INFO - Started process (PID=1079) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:31:35.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:31:35.043+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:31:35.042+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:31:35.074+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:31:35.074+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:31:35.075+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:31:35.075+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:31:35.076+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:31:35.075+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:31:35.079+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:31:35.078+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:31:35.082+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:31:35.081+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:31:35.084+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:31:35.084+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:31:35.085+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:31:35.084+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:31:35.089+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:31:35.085+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:31:35.089+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:31:35.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.087 seconds
[2026-01-23T04:32:05.848+0000] {processor.py:161} INFO - Started process (PID=1089) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:32:05.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:32:05.852+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:32:05.851+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:32:05.880+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:32:05.880+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:32:05.881+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:32:05.880+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:32:05.881+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:32:05.881+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:32:05.886+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:32:05.886+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:32:05.889+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:32:05.888+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:32:05.891+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:32:05.890+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:32:05.891+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:32:05.891+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:32:05.895+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:32:05.892+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:32:05.896+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:32:05.926+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.085 seconds
[2026-01-23T04:32:36.613+0000] {processor.py:161} INFO - Started process (PID=1099) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:32:36.615+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:32:36.616+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:32:36.616+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:32:36.645+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:32:36.645+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:32:36.646+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:32:36.645+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:32:36.646+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:32:36.646+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:32:36.650+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:32:36.649+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:32:36.653+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:32:36.652+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:32:36.655+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:32:36.655+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:32:36.655+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:32:36.655+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:32:36.661+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:32:36.656+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:32:36.661+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:32:36.693+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.085 seconds
[2026-01-23T04:33:07.414+0000] {processor.py:161} INFO - Started process (PID=1109) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:33:07.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:33:07.418+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:33:07.417+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:33:07.445+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:33:07.445+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:33:07.446+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:33:07.446+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:33:07.446+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:33:07.446+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:33:07.449+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:33:07.449+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:33:07.451+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:33:07.451+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:33:07.453+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:33:07.453+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:33:07.454+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:33:07.453+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:33:07.458+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:33:07.454+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:33:07.458+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:33:07.490+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.081 seconds
[2026-01-23T04:33:38.243+0000] {processor.py:161} INFO - Started process (PID=1119) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:33:38.245+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:33:38.247+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:33:38.246+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:33:38.277+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:33:38.277+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:33:38.278+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:33:38.278+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:33:38.279+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:33:38.279+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:33:38.282+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:33:38.282+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:33:38.284+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:33:38.284+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:33:38.286+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:33:38.286+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:33:38.287+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:33:38.287+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:33:38.291+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:33:38.287+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:33:38.292+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:33:38.337+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.099 seconds
[2026-01-23T04:34:09.303+0000] {processor.py:161} INFO - Started process (PID=1129) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:34:09.305+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:34:09.308+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:34:09.307+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:34:09.367+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:34:09.366+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:34:09.368+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:34:09.368+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:34:09.370+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:34:09.369+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:34:09.374+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:34:09.374+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:34:09.378+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:34:09.377+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:34:09.381+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:34:09.381+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:34:09.382+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:34:09.382+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:34:09.389+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:34:09.383+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:34:09.390+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:34:09.436+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.139 seconds
[2026-01-23T04:34:40.126+0000] {processor.py:161} INFO - Started process (PID=1139) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:34:40.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:34:40.129+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:34:40.129+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:34:40.158+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:34:40.157+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:34:40.158+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:34:40.158+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:34:40.159+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:34:40.159+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:34:40.163+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:34:40.162+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:34:40.165+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:34:40.164+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:34:40.166+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:34:40.166+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:34:40.167+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:34:40.167+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:34:40.171+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:34:40.167+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:34:40.171+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:34:40.204+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.083 seconds
[2026-01-23T04:35:11.161+0000] {processor.py:161} INFO - Started process (PID=1149) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:35:11.162+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:35:11.164+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:35:11.164+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:35:11.193+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:35:11.193+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:35:11.194+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:35:11.193+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:35:11.194+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:35:11.194+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:35:11.197+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:35:11.197+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:35:11.199+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:35:11.199+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:35:11.201+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:35:11.201+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:35:11.201+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:35:11.201+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:35:11.206+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:35:11.202+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:35:11.206+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:35:11.238+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.082 seconds
[2026-01-23T04:35:41.920+0000] {processor.py:161} INFO - Started process (PID=1159) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:35:41.921+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:35:41.924+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:35:41.924+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:35:41.964+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:35:41.963+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:35:41.964+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:35:41.964+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:35:41.966+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:35:41.965+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:35:41.970+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:35:41.969+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:35:41.973+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:35:41.972+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:35:41.976+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:35:41.976+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:35:41.977+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:35:41.977+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:35:41.984+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:35:41.977+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:35:41.985+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:35:42.038+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.126 seconds
[2026-01-23T04:36:12.698+0000] {processor.py:161} INFO - Started process (PID=1169) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:36:12.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:36:12.701+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:36:12.701+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:36:12.734+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:36:12.733+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:36:12.735+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:36:12.735+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:36:12.736+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:36:12.735+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:36:12.740+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:36:12.740+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:36:12.742+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:36:12.742+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:36:12.744+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:36:12.744+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:36:12.745+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:36:12.745+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:36:12.750+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:36:12.745+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:36:12.751+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:36:12.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.094 seconds
[2026-01-23T04:36:43.489+0000] {processor.py:161} INFO - Started process (PID=1179) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:36:43.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:36:43.492+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:36:43.491+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:36:43.521+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:36:43.521+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:36:43.522+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:36:43.522+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:36:43.523+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:36:43.522+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:36:43.526+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:36:43.525+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:36:43.528+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:36:43.527+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:36:43.529+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:36:43.529+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:36:43.530+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:36:43.530+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:36:43.535+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:36:43.530+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:36:43.535+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:36:43.567+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.083 seconds
[2026-01-23T04:37:13.661+0000] {processor.py:161} INFO - Started process (PID=1190) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:37:13.662+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:37:13.665+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:37:13.664+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:37:13.690+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:37:13.689+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:37:13.690+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:37:13.690+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:37:13.691+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:37:13.691+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:37:13.694+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:37:13.693+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:37:13.695+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:37:13.695+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:37:13.697+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:37:13.697+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:37:13.697+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:37:13.697+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:37:13.701+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:37:13.698+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:37:13.702+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:37:13.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.076 seconds
[2026-01-23T04:37:43.953+0000] {processor.py:161} INFO - Started process (PID=1201) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:37:43.955+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:37:43.956+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:37:43.956+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:37:43.986+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:37:43.986+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:37:43.987+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:37:43.987+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:37:43.988+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:37:43.988+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:37:43.991+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:37:43.991+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:37:43.993+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:37:43.993+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:37:43.995+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:37:43.995+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:37:43.995+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:37:43.995+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:37:43.999+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:37:43.996+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:37:44.000+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:37:44.040+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.092 seconds
[2026-01-23T04:38:14.657+0000] {processor.py:161} INFO - Started process (PID=1212) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:38:14.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:38:14.662+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:38:14.661+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:38:14.698+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:38:14.697+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:38:14.698+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:38:14.698+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:38:14.699+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:38:14.699+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:38:14.703+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:38:14.703+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:38:14.706+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:38:14.705+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:38:14.708+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:38:14.708+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:38:14.709+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:38:14.709+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:38:14.714+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:38:14.709+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:38:14.715+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:38:14.757+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.107 seconds
[2026-01-23T04:38:45.363+0000] {processor.py:161} INFO - Started process (PID=1222) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:38:45.364+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:38:45.366+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:38:45.366+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:38:45.396+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:38:45.395+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:38:45.396+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:38:45.396+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:38:45.397+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:38:45.397+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:38:45.400+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:38:45.400+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:38:45.402+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:38:45.402+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:38:45.406+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:38:45.406+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:38:45.407+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:38:45.406+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:38:45.412+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:38:45.407+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:38:45.412+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:38:45.449+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.092 seconds
[2026-01-23T04:39:15.928+0000] {processor.py:161} INFO - Started process (PID=1233) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:39:15.929+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:39:15.932+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:39:15.931+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:39:15.963+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:39:15.962+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:39:15.964+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:39:15.963+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:39:15.964+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:39:15.964+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:39:15.967+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:39:15.967+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:39:15.970+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:39:15.969+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:39:15.972+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:39:15.972+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:39:15.973+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:39:15.972+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:39:15.979+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:39:15.973+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:39:15.979+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:39:16.016+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.093 seconds
[2026-01-23T04:39:46.163+0000] {processor.py:161} INFO - Started process (PID=1243) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:39:46.165+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:39:46.168+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:39:46.168+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:39:46.212+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:39:46.212+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:39:46.213+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:39:46.213+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:39:46.214+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:39:46.214+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:39:46.219+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:39:46.219+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:39:46.222+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:39:46.222+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:39:46.225+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:39:46.225+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:39:46.226+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:39:46.225+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:39:46.231+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:39:46.226+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:39:46.232+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:39:46.274+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.120 seconds
[2026-01-23T04:40:16.898+0000] {processor.py:161} INFO - Started process (PID=1253) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:40:16.899+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:40:16.902+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:40:16.901+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:40:16.956+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:40:16.955+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:40:16.957+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:40:16.957+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:40:16.958+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:40:16.958+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:40:16.962+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:40:16.962+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:40:16.965+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:40:16.964+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:40:16.967+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:40:16.967+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:40:16.968+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:40:16.968+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:40:16.975+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:40:16.968+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:40:16.975+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:40:17.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.127 seconds
[2026-01-23T04:40:47.839+0000] {processor.py:161} INFO - Started process (PID=1263) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:40:47.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:40:47.843+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:40:47.842+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:40:47.878+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:40:47.878+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:40:47.879+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:40:47.879+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:40:47.880+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:40:47.880+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:40:47.883+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:40:47.883+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:40:47.887+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:40:47.886+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:40:47.890+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:40:47.889+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:40:47.890+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:40:47.890+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:40:47.895+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:40:47.891+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:40:47.896+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:40:47.933+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.101 seconds
[2026-01-23T04:41:18.625+0000] {processor.py:161} INFO - Started process (PID=1275) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:41:18.627+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:41:18.629+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:41:18.628+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:41:18.669+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:41:18.669+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:41:18.670+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:41:18.670+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:41:18.671+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:41:18.671+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:41:18.688+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:41:18.688+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:41:18.691+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:41:18.690+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:41:18.692+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:41:18.692+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:41:18.693+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:41:18.693+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:41:18.697+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:41:18.693+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:41:18.698+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:41:18.734+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.114 seconds
[2026-01-23T04:41:48.967+0000] {processor.py:161} INFO - Started process (PID=1285) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:41:48.969+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:41:48.971+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:41:48.971+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:41:49.011+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:41:49.011+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:41:49.012+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:41:49.012+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:41:49.013+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:41:49.013+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:41:49.017+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:41:49.016+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:41:49.019+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:41:49.019+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:41:49.022+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:41:49.021+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:41:49.022+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:41:49.022+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:41:49.031+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:41:49.023+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:41:49.031+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:41:49.076+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.119 seconds
[2026-01-23T04:42:19.932+0000] {processor.py:161} INFO - Started process (PID=1295) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:42:19.934+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:42:19.937+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:42:19.936+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:42:19.977+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:42:19.976+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:42:19.978+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:42:19.977+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:42:19.979+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:42:19.978+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:42:19.983+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:42:19.983+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:42:19.986+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:42:19.986+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:42:19.989+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:42:19.988+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:42:19.990+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:42:19.990+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:42:19.997+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:42:19.991+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:42:19.998+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:42:20.047+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.122 seconds
[2026-01-23T04:42:51.172+0000] {processor.py:161} INFO - Started process (PID=1305) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:42:51.173+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:42:51.177+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:42:51.176+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:42:51.228+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:42:51.228+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:42:51.229+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:42:51.229+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:42:51.230+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:42:51.230+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:42:51.234+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:42:51.233+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:42:51.237+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:42:51.237+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:42:51.239+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:42:51.239+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:42:51.240+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:42:51.240+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:42:51.245+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:42:51.240+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:42:51.245+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:42:51.284+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.119 seconds
[2026-01-23T04:43:21.842+0000] {processor.py:161} INFO - Started process (PID=1317) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:43:21.844+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:43:21.847+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:43:21.846+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:43:21.879+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:43:21.879+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:43:21.880+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:43:21.880+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:43:21.881+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:43:21.881+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:43:21.884+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:43:21.884+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:43:21.886+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:43:21.886+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:43:21.888+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:43:21.888+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:43:21.889+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:43:21.888+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:43:21.892+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:43:21.889+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:43:21.893+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:43:21.928+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.093 seconds
[2026-01-23T04:43:52.247+0000] {processor.py:161} INFO - Started process (PID=1327) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:43:52.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:43:52.250+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:43:52.250+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:43:52.279+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:43:52.279+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:43:52.280+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:43:52.280+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:43:52.281+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:43:52.281+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:43:52.285+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:43:52.284+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:43:52.287+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:43:52.286+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:43:52.289+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:43:52.288+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:43:52.289+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:43:52.289+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:43:52.293+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:43:52.290+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:43:52.294+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:43:52.325+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.083 seconds
[2026-01-23T04:44:22.933+0000] {processor.py:161} INFO - Started process (PID=1338) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:44:22.934+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:44:22.936+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:44:22.936+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:44:22.964+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:44:22.964+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:44:22.965+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:44:22.964+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:44:22.965+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:44:22.965+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:44:22.970+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:44:22.970+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:44:22.977+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:44:22.977+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:44:22.980+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:44:22.980+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:44:22.981+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:44:22.981+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:44:22.991+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:44:22.981+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:44:22.992+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:44:23.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.102 seconds
[2026-01-23T04:44:53.418+0000] {processor.py:161} INFO - Started process (PID=1350) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:44:53.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:44:53.422+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:44:53.421+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:44:53.453+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:44:53.453+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:44:53.454+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:44:53.454+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:44:53.455+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:44:53.454+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:44:53.458+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:44:53.457+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:44:53.460+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:44:53.460+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:44:53.462+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:44:53.462+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:44:53.463+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:44:53.462+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:44:53.467+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:44:53.463+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:44:53.468+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:44:53.503+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.091 seconds
[2026-01-23T04:45:24.170+0000] {processor.py:161} INFO - Started process (PID=1360) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:45:24.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:45:24.173+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:45:24.173+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:45:24.205+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:45:24.204+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:45:24.205+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:45:24.205+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:45:24.206+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:45:24.206+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:45:24.209+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:45:24.209+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:45:24.211+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:45:24.211+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:45:24.213+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:45:24.213+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:45:24.214+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:45:24.214+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:45:24.219+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:45:24.214+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:45:24.220+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:45:24.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.087 seconds
[2026-01-23T04:45:54.339+0000] {processor.py:161} INFO - Started process (PID=1371) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:45:54.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:45:54.344+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:45:54.344+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:45:54.383+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:45:54.382+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:45:54.385+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:45:54.384+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:45:54.386+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:45:54.385+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:45:54.389+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:45:54.389+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:45:54.392+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:45:54.392+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:45:54.394+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:45:54.394+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:45:54.395+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:45:54.395+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:45:54.399+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:45:54.395+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:45:54.401+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:45:54.475+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.141 seconds
[2026-01-23T04:46:24.897+0000] {processor.py:161} INFO - Started process (PID=1381) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:46:24.898+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:46:24.900+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:46:24.900+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:46:24.928+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:46:24.927+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:46:24.928+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:46:24.928+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:46:24.929+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:46:24.929+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:46:24.932+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:46:24.932+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:46:24.934+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:46:24.934+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:46:24.936+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:46:24.935+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:46:24.936+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:46:24.936+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:46:24.940+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:46:24.936+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:46:24.941+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:46:24.973+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.081 seconds
[2026-01-23T04:46:55.074+0000] {processor.py:161} INFO - Started process (PID=1392) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:46:55.075+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:46:55.077+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:46:55.077+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:46:55.108+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:46:55.107+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:46:55.109+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:46:55.108+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:46:55.109+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:46:55.109+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:46:55.112+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:46:55.112+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:46:55.115+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:46:55.114+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:46:55.118+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:46:55.117+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:46:55.118+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:46:55.118+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:46:55.125+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:46:55.119+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:46:55.125+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:46:55.188+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.120 seconds
[2026-01-23T04:47:25.808+0000] {processor.py:161} INFO - Started process (PID=1402) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:47:25.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:47:25.814+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:47:25.813+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:47:25.862+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:47:25.862+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:47:25.863+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:47:25.863+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:47:25.865+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:47:25.864+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:47:25.869+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:47:25.869+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:47:25.872+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:47:25.872+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:47:25.875+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:47:25.874+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:47:25.875+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:47:25.875+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:47:25.880+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:47:25.876+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:47:25.881+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:47:25.912+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.112 seconds
[2026-01-23T04:47:56.449+0000] {processor.py:161} INFO - Started process (PID=1412) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:47:56.451+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:47:56.453+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:47:56.452+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:47:56.481+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:47:56.481+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:47:56.482+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:47:56.482+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:47:56.483+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:47:56.483+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:47:56.486+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:47:56.486+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:47:56.488+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:47:56.488+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:47:56.491+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:47:56.490+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:47:56.491+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:47:56.491+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:47:56.497+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:47:56.492+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:47:56.498+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:47:56.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.098 seconds
[2026-01-23T04:48:27.145+0000] {processor.py:161} INFO - Started process (PID=1422) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:48:27.146+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:48:27.149+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:48:27.149+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:48:27.185+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:48:27.184+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:48:27.185+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:48:27.185+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:48:27.186+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:48:27.186+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:48:27.189+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:48:27.189+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:48:27.191+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:48:27.191+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:48:27.194+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:48:27.193+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:48:27.194+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:48:27.194+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:48:27.199+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:48:27.194+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:48:27.200+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:48:27.242+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.105 seconds
[2026-01-23T04:48:57.720+0000] {processor.py:161} INFO - Started process (PID=1433) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:48:57.721+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:48:57.725+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:48:57.724+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:48:57.759+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:48:57.759+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:48:57.760+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:48:57.760+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:48:57.761+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:48:57.761+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:48:57.764+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:48:57.764+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:48:57.766+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:48:57.766+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:48:57.768+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:48:57.768+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:48:57.769+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:48:57.769+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:48:57.773+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:48:57.769+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:48:57.774+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:48:57.806+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.094 seconds
[2026-01-23T04:49:27.959+0000] {processor.py:161} INFO - Started process (PID=1443) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:49:27.960+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:49:27.963+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:49:27.963+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:49:28.003+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:49:28.003+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:49:28.004+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:49:28.004+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:49:28.005+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:49:28.005+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:49:28.010+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:49:28.010+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:49:28.013+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:49:28.013+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:49:28.016+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:49:28.016+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:49:28.017+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:49:28.017+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:49:28.022+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:49:28.017+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:49:28.022+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:49:28.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.117 seconds
[2026-01-23T04:49:58.705+0000] {processor.py:161} INFO - Started process (PID=1453) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:49:58.707+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:49:58.710+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:49:58.709+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:49:58.756+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:49:58.755+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:49:58.757+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:49:58.756+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:49:58.758+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:49:58.757+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:49:58.761+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:49:58.761+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:49:58.764+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:49:58.763+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:49:58.766+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:49:58.766+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:49:58.767+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:49:58.767+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:49:58.773+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:49:58.768+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:49:58.773+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:49:58.812+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.113 seconds
[2026-01-23T04:50:29.083+0000] {processor.py:161} INFO - Started process (PID=1464) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:50:29.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:50:29.087+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:50:29.087+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:50:29.149+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:50:29.148+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:50:29.150+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:50:29.149+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:50:29.151+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:50:29.151+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:50:29.156+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:50:29.155+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:50:29.159+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:50:29.159+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:50:29.162+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:50:29.162+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:50:29.163+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:50:29.162+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:50:29.167+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:50:29.163+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:50:29.168+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:50:29.210+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.134 seconds
[2026-01-23T04:51:00.000+0000] {processor.py:161} INFO - Started process (PID=1474) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:51:00.004+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:51:00.012+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:51:00.011+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:51:00.136+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:51:00.135+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:51:00.138+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:51:00.137+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:51:00.139+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:51:00.139+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:51:00.152+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:51:00.152+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:51:00.159+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:51:00.158+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:51:00.164+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:51:00.163+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:51:00.165+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:51:00.164+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:51:00.172+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:51:00.165+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:51:00.173+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:51:00.224+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.242 seconds
[2026-01-23T04:51:31.051+0000] {processor.py:161} INFO - Started process (PID=1484) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:51:31.054+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:51:31.057+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:51:31.056+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:51:31.102+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:51:31.102+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:51:31.103+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:51:31.103+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:51:31.104+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:51:31.104+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:51:31.108+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:51:31.108+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:51:31.110+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:51:31.110+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:51:31.113+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:51:31.112+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:51:31.113+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:51:31.113+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:51:31.118+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:51:31.113+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:51:31.118+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:51:31.149+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.106 seconds
[2026-01-23T04:52:01.895+0000] {processor.py:161} INFO - Started process (PID=1494) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:52:01.896+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:52:01.898+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:52:01.898+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:52:01.931+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:52:01.931+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:52:01.932+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:52:01.932+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:52:01.933+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:52:01.932+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:52:01.936+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:52:01.936+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:52:01.938+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:52:01.938+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:52:01.941+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:52:01.941+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:52:01.941+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:52:01.941+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:52:01.946+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:52:01.942+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:52:01.947+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:52:01.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.097 seconds
[2026-01-23T04:52:32.161+0000] {processor.py:161} INFO - Started process (PID=1504) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:52:32.162+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:52:32.165+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:52:32.164+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:52:32.199+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:52:32.199+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:52:32.200+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:52:32.200+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:52:32.201+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:52:32.201+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:52:32.204+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:52:32.204+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:52:32.206+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:52:32.206+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:52:32.208+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:52:32.208+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:52:32.208+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:52:32.208+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:52:32.213+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:52:32.209+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:52:32.214+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:52:32.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.097 seconds
[2026-01-23T04:53:02.750+0000] {processor.py:161} INFO - Started process (PID=1514) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:53:02.752+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:53:02.754+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:53:02.754+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:53:02.789+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:53:02.789+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:53:02.790+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:53:02.790+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:53:02.791+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:53:02.791+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:53:02.795+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:53:02.795+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:53:02.797+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:53:02.797+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:53:02.800+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:53:02.799+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:53:02.800+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:53:02.800+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:53:02.805+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:53:02.801+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:53:02.806+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:53:02.846+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.101 seconds
[2026-01-23T04:53:33.694+0000] {processor.py:161} INFO - Started process (PID=1524) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:53:33.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:53:33.698+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:53:33.697+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:53:33.735+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:53:33.735+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:53:33.736+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:53:33.736+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:53:33.736+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:53:33.736+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:53:33.740+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:53:33.740+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:53:33.742+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:53:33.742+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:53:33.744+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:53:33.744+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:53:33.745+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:53:33.744+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:53:33.750+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:53:33.745+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:53:33.750+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:53:33.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.097 seconds
[2026-01-23T04:54:04.517+0000] {processor.py:161} INFO - Started process (PID=1585) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:54:04.519+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:54:04.521+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:54:04.520+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:54:04.553+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:54:04.553+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:54:04.554+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:54:04.554+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:54:04.555+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:54:04.555+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:54:04.558+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:54:04.557+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:54:04.560+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:54:04.560+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:54:04.562+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:54:04.562+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:54:04.563+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:54:04.563+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:54:04.570+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:54:04.564+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:54:04.570+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:54:04.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.093 seconds
[2026-01-23T04:54:34.808+0000] {processor.py:161} INFO - Started process (PID=1639) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:54:34.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:54:34.813+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:54:34.812+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:54:34.844+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:54:34.844+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:54:34.845+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:54:34.844+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:54:34.845+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:54:34.845+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:54:34.850+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:54:34.850+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:54:34.852+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:54:34.852+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:54:34.854+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:54:34.854+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:54:34.854+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:54:34.854+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:54:34.859+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:54:34.855+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:54:34.859+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:54:34.934+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.133 seconds
[2026-01-23T04:55:05.655+0000] {processor.py:161} INFO - Started process (PID=1649) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:55:05.657+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:55:05.660+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:55:05.660+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:55:05.718+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:55:05.717+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:55:05.719+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:55:05.719+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:55:05.721+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:55:05.720+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:55:05.724+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:55:05.724+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:55:05.728+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:55:05.727+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:55:05.731+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:55:05.730+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:55:05.732+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:55:05.731+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:55:05.738+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:55:05.732+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:55:05.739+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:55:05.788+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.138 seconds
[2026-01-23T04:55:36.302+0000] {processor.py:161} INFO - Started process (PID=1659) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:55:36.303+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:55:36.305+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:55:36.305+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:55:36.331+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:55:36.331+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:55:36.332+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:55:36.332+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:55:36.332+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:55:36.332+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:55:36.335+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:55:36.335+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:55:36.337+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:55:36.337+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:55:36.339+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:55:36.339+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:55:36.340+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:55:36.339+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:55:36.343+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:55:36.340+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:55:36.344+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:55:36.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.078 seconds
[2026-01-23T04:56:06.953+0000] {processor.py:161} INFO - Started process (PID=1669) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:56:06.954+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:56:06.956+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:56:06.956+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:56:06.984+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:56:06.984+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:56:06.985+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:56:06.985+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:56:06.986+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:56:06.985+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:56:06.989+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:56:06.989+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:56:06.991+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:56:06.991+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:56:06.993+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:56:06.993+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:56:06.994+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:56:06.993+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:56:06.999+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:56:06.994+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:56:06.999+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:56:07.028+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.081 seconds
[2026-01-23T04:56:37.754+0000] {processor.py:161} INFO - Started process (PID=1679) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:56:37.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:56:37.758+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:56:37.757+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:56:37.785+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:56:37.785+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:56:37.786+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:56:37.786+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:56:37.787+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:56:37.786+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:56:37.790+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:56:37.790+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:56:37.793+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:56:37.792+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:56:37.794+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:56:37.794+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:56:37.795+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:56:37.795+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:56:37.799+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:56:37.795+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:56:37.800+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:56:37.831+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.082 seconds
[2026-01-23T04:57:08.406+0000] {processor.py:161} INFO - Started process (PID=1689) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:57:08.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:57:08.409+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:57:08.409+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:57:08.437+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:57:08.437+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:57:08.438+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:57:08.438+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:57:08.438+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:57:08.438+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:57:08.441+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:57:08.441+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:57:08.443+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:57:08.443+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:57:08.445+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:57:08.445+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:57:08.446+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:57:08.445+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:57:08.451+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:57:08.446+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:57:08.451+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:57:08.483+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.083 seconds
[2026-01-23T04:57:38.845+0000] {processor.py:161} INFO - Started process (PID=1699) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:57:38.846+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:57:38.848+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:57:38.848+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:57:38.878+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:57:38.877+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:57:38.878+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:57:38.878+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:57:38.879+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:57:38.879+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:57:38.883+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:57:38.882+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:57:38.885+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:57:38.885+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:57:38.887+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:57:38.887+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:57:38.888+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:57:38.888+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:57:38.894+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:57:38.888+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:57:38.894+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:57:38.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.104 seconds
[2026-01-23T04:58:09.771+0000] {processor.py:161} INFO - Started process (PID=1709) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:58:09.772+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:58:09.774+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:58:09.774+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:58:09.807+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:58:09.806+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:58:09.808+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:58:09.807+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:58:09.808+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:58:09.808+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:58:09.812+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:58:09.812+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:58:09.815+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:58:09.814+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:58:09.817+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:58:09.817+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:58:09.818+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:58:09.818+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:58:09.823+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:58:09.818+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:58:09.824+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:58:09.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.092 seconds
[2026-01-23T04:58:41.796+0000] {processor.py:161} INFO - Started process (PID=1736) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:58:41.798+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:58:41.799+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:58:41.799+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:58:41.829+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:58:41.829+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:58:41.830+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:58:41.829+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:58:41.830+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:58:41.830+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:58:41.833+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:58:41.833+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:58:41.835+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:58:41.835+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:58:41.837+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:58:41.837+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:58:41.837+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:58:41.837+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:58:41.842+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:58:41.838+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:58:41.843+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:58:41.874+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.084 seconds
[2026-01-23T04:59:13.814+0000] {processor.py:161} INFO - Started process (PID=1800) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:59:13.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:59:13.817+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:59:13.817+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:59:13.855+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:59:13.854+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:59:13.856+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:59:13.856+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:59:13.857+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:59:13.856+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:59:13.860+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:59:13.860+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:59:13.863+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:59:13.863+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:59:13.866+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:59:13.865+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:59:13.866+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:59:13.866+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:59:13.873+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:59:13.867+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:59:13.874+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:59:13.911+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.103 seconds
[2026-01-23T04:59:46.676+0000] {processor.py:161} INFO - Started process (PID=1864) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:59:46.677+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T04:59:46.679+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:59:46.679+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:59:46.707+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:59:46.707+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T04:59:46.708+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:59:46.708+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T04:59:46.709+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:59:46.708+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T04:59:46.711+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:59:46.711+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:59:46.713+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:59:46.713+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:59:46.715+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:59:46.715+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T04:59:46.716+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:59:46.716+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T04:59:46.720+0000] {logging_mixin.py:188} INFO - [2026-01-23T04:59:46.716+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T04:59:46.720+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T04:59:46.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.079 seconds
[2026-01-23T05:00:17.178+0000] {processor.py:161} INFO - Started process (PID=1928) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:00:17.179+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:00:17.181+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:00:17.181+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:00:17.212+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:00:17.212+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:00:17.213+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:00:17.213+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:00:17.214+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:00:17.214+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:00:17.217+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:00:17.217+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:00:17.220+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:00:17.219+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:00:17.222+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:00:17.222+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:00:17.222+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:00:17.222+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:00:17.227+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:00:17.223+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:00:17.227+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:00:17.268+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.096 seconds
[2026-01-23T05:00:47.584+0000] {processor.py:161} INFO - Started process (PID=1965) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:00:47.585+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:00:47.587+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:00:47.587+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:00:47.619+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:00:47.618+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:00:47.620+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:00:47.619+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:00:47.620+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:00:47.620+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:00:47.623+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:00:47.623+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:00:47.626+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:00:47.626+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:00:47.628+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:00:47.628+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:00:47.629+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:00:47.628+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:00:47.634+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:00:47.629+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:00:47.635+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:00:47.668+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.089 seconds
[2026-01-23T05:01:18.717+0000] {processor.py:161} INFO - Started process (PID=1975) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:01:18.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:01:18.720+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:01:18.720+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:01:18.756+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:01:18.756+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:01:18.757+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:01:18.757+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:01:18.758+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:01:18.758+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:01:18.762+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:01:18.762+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:01:18.764+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:01:18.764+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:01:18.766+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:01:18.766+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:01:18.766+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:01:18.766+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:01:18.771+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:01:18.767+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:01:18.771+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:01:18.801+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.090 seconds
[2026-01-23T05:01:49.452+0000] {processor.py:161} INFO - Started process (PID=1985) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:01:49.454+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:01:49.456+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:01:49.456+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:01:49.486+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:01:49.485+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:01:49.486+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:01:49.486+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:01:49.487+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:01:49.487+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:01:49.491+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:01:49.490+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:01:49.494+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:01:49.493+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:01:49.497+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:01:49.496+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:01:49.497+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:01:49.497+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:01:49.502+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:01:49.497+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:01:49.502+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:01:49.541+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.094 seconds
[2026-01-23T05:02:20.238+0000] {processor.py:161} INFO - Started process (PID=1995) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:02:20.240+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:02:20.243+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:02:20.242+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:02:20.280+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:02:20.280+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:02:20.281+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:02:20.281+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:02:20.281+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:02:20.281+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:02:20.284+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:02:20.284+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:02:20.287+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:02:20.287+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:02:20.289+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:02:20.289+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:02:20.290+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:02:20.290+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:02:20.294+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:02:20.290+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:02:20.295+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:02:20.327+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.095 seconds
[2026-01-23T05:02:51.262+0000] {processor.py:161} INFO - Started process (PID=2005) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:02:51.264+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:02:51.267+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:02:51.266+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:02:51.318+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:02:51.318+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:02:51.319+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:02:51.319+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:02:51.320+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:02:51.320+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:02:51.324+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:02:51.324+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:02:51.327+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:02:51.327+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:02:51.331+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:02:51.330+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:02:51.332+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:02:51.331+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:02:51.340+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:02:51.332+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:02:51.341+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:02:51.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.133 seconds
[2026-01-23T05:03:22.071+0000] {processor.py:161} INFO - Started process (PID=2015) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:03:22.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:03:22.075+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:03:22.074+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:03:22.103+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:03:22.103+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:03:22.104+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:03:22.104+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:03:22.105+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:03:22.105+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:03:22.109+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:03:22.109+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:03:22.112+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:03:22.112+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:03:22.114+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:03:22.114+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:03:22.115+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:03:22.115+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:03:22.120+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:03:22.115+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:03:22.121+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:03:22.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.087 seconds
[2026-01-23T05:03:53.087+0000] {processor.py:161} INFO - Started process (PID=2025) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:03:53.088+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:03:53.093+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:03:53.092+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:03:53.164+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:03:53.163+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:03:53.165+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:03:53.165+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:03:53.166+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:03:53.166+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:03:53.171+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:03:53.170+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:03:53.174+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:03:53.174+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:03:53.178+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:03:53.177+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:03:53.178+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:03:53.178+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:03:53.186+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:03:53.179+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:03:53.187+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:03:53.235+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.157 seconds
[2026-01-23T05:04:23.783+0000] {processor.py:161} INFO - Started process (PID=2035) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:04:23.784+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:04:23.786+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:04:23.786+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:04:23.822+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:04:23.821+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:04:23.823+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:04:23.822+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:04:23.823+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:04:23.823+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:04:23.827+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:04:23.826+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:04:23.829+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:04:23.829+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:04:23.832+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:04:23.832+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:04:23.833+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:04:23.833+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:04:23.839+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:04:23.833+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:04:23.840+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:04:23.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.102 seconds
[2026-01-23T05:04:54.612+0000] {processor.py:161} INFO - Started process (PID=2045) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:04:54.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:04:54.616+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:04:54.615+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:04:54.655+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:04:54.655+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:04:54.657+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:04:54.656+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:04:54.658+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:04:54.658+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:04:54.664+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:04:54.664+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:04:54.666+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:04:54.666+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:04:54.669+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:04:54.669+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:04:54.670+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:04:54.670+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:04:54.676+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:04:54.670+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:04:54.677+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:04:54.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.109 seconds
[2026-01-23T05:05:25.442+0000] {processor.py:161} INFO - Started process (PID=2055) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:05:25.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:05:25.445+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:05:25.445+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:05:25.474+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:05:25.474+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:05:25.475+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:05:25.475+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:05:25.476+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:05:25.476+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:05:25.479+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:05:25.478+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:05:25.481+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:05:25.481+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:05:25.483+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:05:25.483+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:05:25.483+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:05:25.483+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:05:25.488+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:05:25.484+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:05:25.489+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:05:25.523+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.086 seconds
[2026-01-23T05:05:56.185+0000] {processor.py:161} INFO - Started process (PID=2065) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:05:56.186+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:05:56.189+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:05:56.189+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:05:56.219+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:05:56.219+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:05:56.220+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:05:56.220+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:05:56.221+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:05:56.221+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:05:56.225+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:05:56.225+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:05:56.228+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:05:56.227+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:05:56.230+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:05:56.230+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:05:56.231+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:05:56.230+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:05:56.236+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:05:56.231+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:05:56.236+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:05:56.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.096 seconds
[2026-01-23T05:06:27.025+0000] {processor.py:161} INFO - Started process (PID=2075) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:06:27.026+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:06:27.028+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:06:27.027+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:06:27.060+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:06:27.059+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:06:27.060+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:06:27.060+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:06:27.061+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:06:27.061+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:06:27.064+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:06:27.064+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:06:27.066+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:06:27.066+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:06:27.069+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:06:27.068+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:06:27.069+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:06:27.069+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:06:27.074+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:06:27.070+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:06:27.075+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:06:27.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.095 seconds
[2026-01-23T05:06:57.869+0000] {processor.py:161} INFO - Started process (PID=2085) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:06:57.870+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:06:57.872+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:06:57.872+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:06:57.903+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:06:57.903+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:06:57.904+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:06:57.904+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:06:57.905+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:06:57.905+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:06:57.908+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:06:57.908+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:06:57.910+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:06:57.910+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:06:57.912+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:06:57.912+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:06:57.913+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:06:57.913+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:06:57.918+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:06:57.913+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:06:57.919+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:06:57.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.091 seconds
[2026-01-23T05:07:28.595+0000] {processor.py:161} INFO - Started process (PID=2095) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:07:28.597+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:07:28.599+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:07:28.599+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:07:28.638+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:07:28.638+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:07:28.639+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:07:28.638+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:07:28.640+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:07:28.640+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:07:28.645+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:07:28.645+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:07:28.647+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:07:28.647+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:07:28.650+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:07:28.650+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:07:28.651+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:07:28.651+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:07:28.658+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:07:28.652+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:07:28.658+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:07:28.698+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.109 seconds
[2026-01-23T05:07:59.413+0000] {processor.py:161} INFO - Started process (PID=2105) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:07:59.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:07:59.417+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:07:59.417+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:07:59.447+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:07:59.446+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:07:59.448+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:07:59.447+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:07:59.448+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:07:59.448+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:07:59.452+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:07:59.452+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:07:59.455+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:07:59.455+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:07:59.457+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:07:59.457+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:07:59.458+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:07:59.458+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:07:59.462+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:07:59.458+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:07:59.462+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:07:59.494+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.086 seconds
[2026-01-23T05:08:29.790+0000] {processor.py:161} INFO - Started process (PID=2115) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:08:29.791+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:08:29.793+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:08:29.792+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:08:29.823+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:08:29.823+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:08:29.824+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:08:29.824+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:08:29.825+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:08:29.825+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:08:29.829+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:08:29.829+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:08:29.831+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:08:29.831+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:08:29.833+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:08:29.833+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:08:29.834+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:08:29.834+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:08:29.842+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:08:29.834+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:08:29.843+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:08:29.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.091 seconds
[2026-01-23T05:09:00.076+0000] {processor.py:161} INFO - Started process (PID=2125) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:09:00.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:09:00.079+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:09:00.079+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:09:00.108+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:09:00.108+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:09:00.109+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:09:00.109+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:09:00.110+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:09:00.110+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:09:00.114+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:09:00.113+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:09:00.116+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:09:00.116+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:09:00.118+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:09:00.118+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:09:00.119+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:09:00.119+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:09:00.124+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:09:00.119+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:09:00.125+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:09:00.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.091 seconds
[2026-01-23T05:09:30.988+0000] {processor.py:161} INFO - Started process (PID=2135) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:09:30.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:09:30.992+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:09:30.991+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:09:31.020+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:09:31.020+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:09:31.021+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:09:31.021+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:09:31.022+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:09:31.022+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:09:31.025+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:09:31.025+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:09:31.027+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:09:31.027+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:09:31.029+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:09:31.028+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:09:31.029+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:09:31.029+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:09:31.033+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:09:31.030+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:09:31.034+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:09:31.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.087 seconds
[2026-01-23T05:10:01.745+0000] {processor.py:161} INFO - Started process (PID=2145) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:10:01.746+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:10:01.748+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:10:01.747+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:10:01.778+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:10:01.778+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:10:01.779+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:10:01.779+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:10:01.780+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:10:01.780+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:10:01.785+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:10:01.785+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:10:01.787+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:10:01.787+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:10:01.789+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:10:01.789+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:10:01.790+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:10:01.790+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:10:01.794+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:10:01.790+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:10:01.794+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:10:01.828+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.088 seconds
[2026-01-23T05:10:32.501+0000] {processor.py:161} INFO - Started process (PID=2155) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:10:32.503+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:10:32.505+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:10:32.504+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:10:32.538+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:10:32.537+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:10:32.539+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:10:32.538+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:10:32.540+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:10:32.539+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:10:32.543+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:10:32.543+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:10:32.545+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:10:32.545+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:10:32.547+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:10:32.547+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:10:32.548+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:10:32.548+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:10:32.552+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:10:32.548+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:10:32.552+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:10:32.585+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.089 seconds
[2026-01-23T05:11:03.326+0000] {processor.py:161} INFO - Started process (PID=2165) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:11:03.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:11:03.331+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:11:03.330+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:11:03.365+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:11:03.365+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:11:03.366+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:11:03.366+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:11:03.367+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:11:03.367+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:11:03.370+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:11:03.370+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:11:03.373+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:11:03.372+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:11:03.375+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:11:03.375+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:11:03.376+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:11:03.376+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:11:03.382+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:11:03.376+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:11:03.383+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:11:03.431+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.111 seconds
[2026-01-23T05:11:34.102+0000] {processor.py:161} INFO - Started process (PID=2175) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:11:34.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:11:34.106+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:11:34.105+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:11:34.139+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:11:34.139+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:11:34.140+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:11:34.140+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:11:34.141+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:11:34.140+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:11:34.144+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:11:34.143+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:11:34.146+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:11:34.146+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:11:34.148+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:11:34.148+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:11:34.148+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:11:34.148+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:11:34.153+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:11:34.149+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:11:34.154+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:11:34.188+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.091 seconds
[2026-01-23T05:12:04.888+0000] {processor.py:161} INFO - Started process (PID=2185) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:12:04.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:12:04.891+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:12:04.891+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:12:04.922+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:12:04.922+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:12:04.923+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:12:04.923+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:12:04.924+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:12:04.924+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:12:04.927+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:12:04.927+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:12:04.929+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:12:04.929+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:12:04.931+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:12:04.931+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:12:04.932+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:12:04.932+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:12:04.939+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:12:04.932+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:12:04.940+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:12:04.979+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.096 seconds
[2026-01-23T05:12:35.629+0000] {processor.py:161} INFO - Started process (PID=2195) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:12:35.630+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:12:35.632+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:12:35.632+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:12:35.668+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:12:35.668+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:12:35.669+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:12:35.669+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:12:35.671+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:12:35.670+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:12:35.675+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:12:35.674+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:12:35.677+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:12:35.677+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:12:35.679+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:12:35.678+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:12:35.679+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:12:35.679+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:12:35.684+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:12:35.679+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:12:35.685+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:12:35.723+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.100 seconds
[2026-01-23T05:13:06.458+0000] {processor.py:161} INFO - Started process (PID=2205) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:13:06.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:13:06.462+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:13:06.462+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:13:06.496+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:13:06.496+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:13:06.497+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:13:06.497+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:13:06.497+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:13:06.497+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:13:06.507+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:13:06.506+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:13:06.513+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:13:06.512+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:13:06.516+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:13:06.515+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:13:06.516+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:13:06.516+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:13:06.523+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:13:06.517+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:13:06.524+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:13:06.565+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.112 seconds
[2026-01-23T05:13:37.397+0000] {processor.py:161} INFO - Started process (PID=2215) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:13:37.399+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:13:37.401+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:13:37.401+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:13:37.433+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:13:37.432+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:13:37.433+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:13:37.433+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:13:37.434+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:13:37.434+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:13:37.438+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:13:37.437+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:13:37.440+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:13:37.440+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:13:37.443+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:13:37.442+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:13:37.443+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:13:37.443+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:13:37.450+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:13:37.444+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:13:37.450+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:13:37.486+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.095 seconds
[2026-01-23T05:14:08.289+0000] {processor.py:161} INFO - Started process (PID=2225) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:14:08.290+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:14:08.292+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:14:08.292+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:14:08.320+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:14:08.320+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:14:08.321+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:14:08.321+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:14:08.322+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:14:08.322+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:14:08.325+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:14:08.324+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:14:08.326+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:14:08.326+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:14:08.328+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:14:08.328+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:14:08.329+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:14:08.329+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:14:08.333+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:14:08.329+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:14:08.334+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:14:08.364+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.080 seconds
[2026-01-23T05:14:39.075+0000] {processor.py:161} INFO - Started process (PID=2235) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:14:39.076+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:14:39.079+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:14:39.079+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:14:39.115+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:14:39.114+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:14:39.115+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:14:39.115+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:14:39.116+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:14:39.116+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:14:39.120+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:14:39.120+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:14:39.123+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:14:39.123+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:14:39.126+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:14:39.126+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:14:39.127+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:14:39.127+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:14:39.133+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:14:39.127+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:14:39.133+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:14:39.189+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.120 seconds
[2026-01-23T05:15:09.794+0000] {processor.py:161} INFO - Started process (PID=2245) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:15:09.795+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:15:09.798+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:15:09.798+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:15:09.839+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:15:09.839+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:15:09.840+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:15:09.840+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:15:09.841+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:15:09.841+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:15:09.845+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:15:09.845+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:15:09.848+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:15:09.848+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:15:09.851+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:15:09.850+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:15:09.851+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:15:09.851+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:15:09.859+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:15:09.852+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:15:09.859+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:15:09.907+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.119 seconds
[2026-01-23T05:15:40.529+0000] {processor.py:161} INFO - Started process (PID=2255) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:15:40.530+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:15:40.532+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:15:40.532+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:15:40.569+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:15:40.568+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:15:40.570+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:15:40.570+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:15:40.570+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:15:40.570+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:15:40.574+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:15:40.574+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:15:40.576+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:15:40.576+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:15:40.578+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:15:40.578+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:15:40.579+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:15:40.579+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:15:40.584+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:15:40.579+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:15:40.585+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:15:40.623+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.100 seconds
[2026-01-23T05:16:11.206+0000] {processor.py:161} INFO - Started process (PID=2265) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:16:11.207+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:16:11.209+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:16:11.209+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:16:11.243+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:16:11.243+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:16:11.244+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:16:11.244+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:16:11.245+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:16:11.245+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:16:11.248+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:16:11.248+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:16:11.250+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:16:11.250+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:16:11.252+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:16:11.251+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:16:11.252+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:16:11.252+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:16:11.256+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:16:11.252+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:16:11.257+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:16:11.288+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.088 seconds
[2026-01-23T05:16:41.794+0000] {processor.py:161} INFO - Started process (PID=2275) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:16:41.795+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:16:41.798+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:16:41.797+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:16:41.831+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:16:41.830+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:16:41.832+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:16:41.831+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:16:41.832+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:16:41.832+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:16:41.835+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:16:41.835+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:16:41.838+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:16:41.838+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:16:41.841+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:16:41.841+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:16:41.842+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:16:41.842+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:16:41.847+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:16:41.842+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:16:41.848+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:16:41.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.097 seconds
[2026-01-23T05:17:12.470+0000] {processor.py:161} INFO - Started process (PID=2285) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:17:12.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:17:12.473+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:17:12.473+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:17:12.506+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:17:12.506+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:17:12.507+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:17:12.507+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:17:12.508+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:17:12.508+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:17:12.511+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:17:12.511+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:17:12.514+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:17:12.513+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:17:12.516+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:17:12.515+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:17:12.516+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:17:12.516+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:17:12.521+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:17:12.516+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:17:12.522+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:17:12.556+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.092 seconds
[2026-01-23T05:17:43.228+0000] {processor.py:161} INFO - Started process (PID=2295) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:17:43.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:17:43.231+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:17:43.231+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:17:43.258+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:17:43.258+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:17:43.259+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:17:43.259+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:17:43.260+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:17:43.259+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:17:43.262+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:17:43.262+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:17:43.265+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:17:43.264+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:17:43.266+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:17:43.266+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:17:43.267+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:17:43.266+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:17:43.271+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:17:43.267+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:17:43.271+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:17:43.301+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.078 seconds
[2026-01-23T05:18:13.556+0000] {processor.py:161} INFO - Started process (PID=2305) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:18:13.557+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:18:13.559+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:18:13.558+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:18:13.584+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:18:13.584+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:18:13.585+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:18:13.585+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:18:13.586+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:18:13.586+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:18:13.589+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:18:13.589+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:18:13.591+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:18:13.591+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:18:13.593+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:18:13.593+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:18:13.594+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:18:13.594+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:18:13.598+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:18:13.594+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:18:13.599+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:18:13.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.081 seconds
[2026-01-23T05:18:43.984+0000] {processor.py:161} INFO - Started process (PID=2315) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:18:43.985+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:18:43.987+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:18:43.987+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:18:44.021+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:18:44.021+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:18:44.022+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:18:44.022+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:18:44.022+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:18:44.022+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:18:44.026+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:18:44.026+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:18:44.029+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:18:44.028+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:18:44.031+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:18:44.031+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:18:44.032+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:18:44.032+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:18:44.038+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:18:44.032+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:18:44.039+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:18:44.081+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.103 seconds
[2026-01-23T05:19:14.334+0000] {processor.py:161} INFO - Started process (PID=2326) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:19:14.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:19:14.337+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:19:14.337+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:19:14.366+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:19:14.366+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:19:14.367+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:19:14.367+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:19:14.368+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:19:14.368+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:19:14.370+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:19:14.370+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:19:14.373+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:19:14.373+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:19:14.375+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:19:14.375+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:19:14.375+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:19:14.375+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:19:14.380+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:19:14.376+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:19:14.381+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:19:14.416+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.088 seconds
[2026-01-23T05:19:45.280+0000] {processor.py:161} INFO - Started process (PID=2336) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:19:45.281+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:19:45.284+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:19:45.283+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:19:45.312+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:19:45.311+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:19:45.312+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:19:45.312+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:19:45.313+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:19:45.313+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:19:45.316+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:19:45.316+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:19:45.319+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:19:45.318+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:19:45.321+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:19:45.320+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:19:45.321+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:19:45.321+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:19:45.326+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:19:45.321+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:19:45.327+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:19:45.360+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.086 seconds
[2026-01-23T05:20:15.857+0000] {processor.py:161} INFO - Started process (PID=2346) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:20:15.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:20:15.860+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:20:15.860+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:20:15.889+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:20:15.889+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:20:15.890+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:20:15.890+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:20:15.891+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:20:15.891+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:20:15.894+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:20:15.894+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:20:15.897+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:20:15.897+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:20:15.899+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:20:15.899+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:20:15.899+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:20:15.899+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:20:15.904+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:20:15.900+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:20:15.905+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:20:15.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.084 seconds
[2026-01-23T05:20:46.437+0000] {processor.py:161} INFO - Started process (PID=2356) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:20:46.439+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:20:46.441+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:20:46.441+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:20:46.479+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:20:46.478+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:20:46.479+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:20:46.479+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:20:46.480+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:20:46.480+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:20:46.485+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:20:46.484+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:20:46.488+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:20:46.487+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:20:46.491+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:20:46.490+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:20:46.492+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:20:46.491+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:20:46.499+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:20:46.492+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:20:46.500+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:20:46.566+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.136 seconds
[2026-01-23T05:21:16.692+0000] {processor.py:161} INFO - Started process (PID=2366) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:21:16.693+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:21:16.696+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:21:16.695+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:21:16.722+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:21:16.721+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:21:16.722+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:21:16.722+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:21:16.723+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:21:16.723+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:21:16.726+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:21:16.726+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:21:16.728+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:21:16.728+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:21:16.730+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:21:16.730+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:21:16.731+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:21:16.731+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:21:16.735+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:21:16.731+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:21:16.735+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:21:16.773+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.087 seconds
[2026-01-23T05:21:47.279+0000] {processor.py:161} INFO - Started process (PID=2376) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:21:47.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:21:47.283+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:21:47.282+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:21:47.315+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:21:47.315+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:21:47.316+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:21:47.316+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:21:47.317+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:21:47.317+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:21:47.321+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:21:47.321+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:21:47.323+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:21:47.323+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:21:47.325+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:21:47.325+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:21:47.327+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:21:47.326+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:21:47.333+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:21:47.327+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:21:47.334+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:21:47.373+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.099 seconds
[2026-01-23T05:22:17.956+0000] {processor.py:161} INFO - Started process (PID=2386) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:22:17.958+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:22:17.960+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:22:17.960+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:22:17.993+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:22:17.992+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:22:17.993+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:22:17.993+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:22:17.994+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:22:17.994+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:22:17.997+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:22:17.997+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:22:17.999+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:22:17.999+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:22:18.001+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:22:18.001+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:22:18.001+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:22:18.001+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:22:18.006+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:22:18.002+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:22:18.006+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:22:18.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.088 seconds
[2026-01-23T05:22:48.643+0000] {processor.py:161} INFO - Started process (PID=2396) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:22:48.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:22:48.648+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:22:48.648+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:22:48.681+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:22:48.681+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:22:48.682+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:22:48.682+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:22:48.683+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:22:48.683+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:22:48.686+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:22:48.686+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:22:48.688+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:22:48.688+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:22:48.690+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:22:48.690+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:22:48.691+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:22:48.691+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:22:48.695+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:22:48.691+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:22:48.696+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:22:48.734+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.097 seconds
[2026-01-23T05:23:19.356+0000] {processor.py:161} INFO - Started process (PID=2406) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:23:19.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:23:19.360+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:23:19.360+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:23:19.399+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:23:19.398+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:23:19.400+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:23:19.399+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:23:19.400+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:23:19.400+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:23:19.405+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:23:19.404+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:23:19.408+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:23:19.407+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:23:19.410+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:23:19.410+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:23:19.411+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:23:19.410+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:23:19.415+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:23:19.411+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:23:19.416+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:23:19.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.107 seconds
[2026-01-23T05:23:49.876+0000] {processor.py:161} INFO - Started process (PID=2416) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:23:49.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:23:49.879+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:23:49.879+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:23:49.908+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:23:49.907+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:23:49.908+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:23:49.908+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:23:49.909+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:23:49.909+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:23:49.912+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:23:49.912+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:23:49.914+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:23:49.914+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:23:49.916+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:23:49.916+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:23:49.917+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:23:49.917+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:23:49.921+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:23:49.917+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:23:49.921+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:23:49.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.082 seconds
[2026-01-23T05:24:21.347+0000] {processor.py:161} INFO - Started process (PID=2426) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:24:21.350+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:24:21.351+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:24:21.351+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:24:21.379+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:24:21.378+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:24:21.379+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:24:21.379+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:24:21.380+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:24:21.380+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:24:21.383+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:24:21.383+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:24:21.385+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:24:21.385+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:24:21.387+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:24:21.387+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:24:21.388+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:24:21.388+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:24:21.392+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:24:21.388+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:24:21.393+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:24:21.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.087 seconds
[2026-01-23T05:24:51.962+0000] {processor.py:161} INFO - Started process (PID=2436) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:24:51.963+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:24:51.966+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:24:51.965+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:24:52.004+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:24:52.003+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:24:52.005+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:24:52.004+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:24:52.005+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:24:52.005+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:24:52.009+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:24:52.008+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:24:52.011+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:24:52.011+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:24:52.013+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:24:52.013+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:24:52.014+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:24:52.014+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:24:52.019+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:24:52.014+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:24:52.020+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:24:52.056+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.100 seconds
[2026-01-23T05:25:22.538+0000] {processor.py:161} INFO - Started process (PID=2446) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:25:22.539+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:25:22.541+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:25:22.541+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:25:22.581+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:25:22.581+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:25:22.582+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:25:22.582+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:25:22.583+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:25:22.583+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:25:22.586+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:25:22.586+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:25:22.588+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:25:22.588+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:25:22.591+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:25:22.591+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:25:22.592+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:25:22.591+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:25:22.598+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:25:22.592+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:25:22.599+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:25:22.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.098 seconds
[2026-01-23T05:25:53.056+0000] {processor.py:161} INFO - Started process (PID=2456) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:25:53.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:25:53.059+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:25:53.059+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:25:53.086+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:25:53.086+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:25:53.087+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:25:53.087+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:25:53.088+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:25:53.087+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:25:53.090+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:25:53.090+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:25:53.093+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:25:53.092+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:25:53.095+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:25:53.094+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:25:53.095+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:25:53.095+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:25:53.101+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:25:53.095+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:25:53.102+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:25:53.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.085 seconds
[2026-01-23T05:26:23.738+0000] {processor.py:161} INFO - Started process (PID=2466) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:26:23.740+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:26:23.743+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:26:23.743+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:26:23.785+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:26:23.785+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:26:23.786+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:26:23.786+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:26:23.787+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:26:23.787+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:26:23.791+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:26:23.791+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:26:23.794+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:26:23.794+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:26:23.797+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:26:23.796+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:26:23.798+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:26:23.797+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:26:23.803+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:26:23.798+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:26:23.804+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:26:23.846+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.114 seconds
[2026-01-23T05:26:54.710+0000] {processor.py:161} INFO - Started process (PID=2476) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:26:54.711+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:26:54.713+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:26:54.713+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:26:54.762+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:26:54.762+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:26:54.763+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:26:54.763+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:26:54.765+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:26:54.764+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:26:54.768+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:26:54.768+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:26:54.771+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:26:54.770+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:26:54.773+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:26:54.773+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:26:54.774+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:26:54.773+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:26:54.781+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:26:54.774+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:26:54.782+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:26:54.823+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.119 seconds
[2026-01-23T05:27:25.714+0000] {processor.py:161} INFO - Started process (PID=2486) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:27:25.715+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:27:25.717+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:27:25.717+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:27:25.743+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:27:25.743+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:27:25.744+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:27:25.744+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:27:25.744+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:27:25.744+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:27:25.747+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:27:25.747+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:27:25.749+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:27:25.749+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:27:25.751+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:27:25.751+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:27:25.751+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:27:25.751+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:27:25.756+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:27:25.752+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:27:25.756+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:27:25.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.080 seconds
[2026-01-23T05:27:56.442+0000] {processor.py:161} INFO - Started process (PID=2496) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:27:56.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:27:56.445+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:27:56.445+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:27:56.471+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:27:56.471+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:27:56.472+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:27:56.471+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:27:56.472+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:27:56.472+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:27:56.475+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:27:56.475+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:27:56.477+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:27:56.477+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:27:56.479+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:27:56.479+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:27:56.480+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:27:56.480+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:27:56.484+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:27:56.480+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:27:56.484+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:27:56.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.082 seconds
[2026-01-23T05:28:27.245+0000] {processor.py:161} INFO - Started process (PID=2506) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:28:27.247+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:28:27.249+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:28:27.248+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:28:27.285+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:28:27.284+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:28:27.285+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:28:27.285+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:28:27.286+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:28:27.286+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:28:27.290+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:28:27.289+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:28:27.292+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:28:27.292+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:28:27.294+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:28:27.294+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:28:27.295+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:28:27.295+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:28:27.300+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:28:27.295+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:28:27.300+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:28:27.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.109 seconds
[2026-01-23T05:28:58.067+0000] {processor.py:161} INFO - Started process (PID=2516) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:28:58.069+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:28:58.070+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:28:58.070+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:28:58.100+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:28:58.100+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:28:58.102+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:28:58.101+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:28:58.102+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:28:58.102+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:28:58.105+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:28:58.105+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:28:58.108+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:28:58.107+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:28:58.109+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:28:58.109+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:28:58.110+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:28:58.110+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:28:58.114+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:28:58.110+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:28:58.115+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:28:58.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.085 seconds
[2026-01-23T05:29:28.880+0000] {processor.py:161} INFO - Started process (PID=2526) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:29:28.881+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:29:28.883+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:29:28.882+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:29:28.911+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:29:28.910+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:29:28.911+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:29:28.911+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:29:28.912+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:29:28.912+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:29:28.915+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:29:28.915+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:29:28.917+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:29:28.917+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:29:28.919+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:29:28.919+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:29:28.920+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:29:28.920+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:29:28.925+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:29:28.920+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:29:28.925+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:29:28.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.084 seconds
[2026-01-23T05:29:59.698+0000] {processor.py:161} INFO - Started process (PID=2536) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:29:59.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:29:59.701+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:29:59.701+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:29:59.729+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:29:59.729+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:29:59.730+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:29:59.730+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:29:59.731+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:29:59.730+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:29:59.734+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:29:59.733+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:29:59.736+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:29:59.735+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:29:59.738+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:29:59.738+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:29:59.739+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:29:59.738+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:29:59.743+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:29:59.739+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:29:59.744+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:29:59.775+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.081 seconds
[2026-01-23T05:30:30.483+0000] {processor.py:161} INFO - Started process (PID=2546) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:30:30.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:30:30.487+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:30:30.487+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:30:30.536+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:30:30.536+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:30:30.537+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:30:30.537+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:30:30.539+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:30:30.539+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:30:30.544+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:30:30.544+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:30:30.547+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:30:30.546+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:30:30.549+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:30:30.549+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:30:30.550+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:30:30.550+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:30:30.556+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:30:30.550+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:30:30.556+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:30:30.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.129 seconds
[2026-01-23T05:31:01.290+0000] {processor.py:161} INFO - Started process (PID=2556) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:31:01.291+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:31:01.293+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:31:01.293+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:31:01.326+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:31:01.326+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:31:01.327+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:31:01.327+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:31:01.327+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:31:01.327+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:31:01.331+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:31:01.331+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:31:01.333+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:31:01.333+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:31:01.336+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:31:01.336+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:31:01.338+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:31:01.337+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:31:01.342+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:31:01.338+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:31:01.343+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:31:01.376+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.093 seconds
[2026-01-23T05:31:32.095+0000] {processor.py:161} INFO - Started process (PID=2566) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:31:32.096+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:31:32.099+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:31:32.099+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:31:32.140+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:31:32.139+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:31:32.140+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:31:32.140+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:31:32.141+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:31:32.141+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:31:32.145+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:31:32.145+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:31:32.148+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:31:32.148+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:31:32.150+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:31:32.150+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:31:32.151+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:31:32.151+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:31:32.158+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:31:32.151+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:31:32.158+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:31:32.204+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.116 seconds
[2026-01-23T05:32:02.759+0000] {processor.py:161} INFO - Started process (PID=2576) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:32:02.760+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:32:02.762+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:32:02.761+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:32:02.795+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:32:02.794+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:32:02.796+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:32:02.795+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:32:02.796+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:32:02.796+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:32:02.800+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:32:02.800+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:32:02.803+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:32:02.803+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:32:02.805+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:32:02.805+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:32:02.806+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:32:02.806+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:32:02.811+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:32:02.806+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:32:02.811+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:32:02.852+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.099 seconds
[2026-01-23T05:32:33.519+0000] {processor.py:161} INFO - Started process (PID=2586) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:32:33.520+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:32:33.523+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:32:33.522+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:32:33.558+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:32:33.557+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:32:33.558+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:32:33.558+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:32:33.559+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:32:33.559+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:32:33.563+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:32:33.562+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:32:33.565+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:32:33.564+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:32:33.567+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:32:33.567+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:32:33.568+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:32:33.567+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:32:33.573+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:32:33.568+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:32:33.574+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:32:33.608+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.095 seconds
[2026-01-23T05:33:04.356+0000] {processor.py:161} INFO - Started process (PID=2596) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:33:04.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:33:04.360+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:33:04.360+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:33:04.386+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:33:04.385+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:33:04.386+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:33:04.386+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:33:04.387+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:33:04.387+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:33:04.390+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:33:04.390+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:33:04.393+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:33:04.393+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:33:04.395+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:33:04.395+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:33:04.396+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:33:04.396+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:33:04.401+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:33:04.396+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:33:04.402+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:33:04.436+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.085 seconds
[2026-01-23T05:33:35.265+0000] {processor.py:161} INFO - Started process (PID=2606) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:33:35.266+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:33:35.268+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:33:35.268+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:33:35.301+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:33:35.301+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:33:35.302+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:33:35.301+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:33:35.302+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:33:35.302+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:33:35.306+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:33:35.306+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:33:35.309+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:33:35.309+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:33:35.312+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:33:35.312+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:33:35.313+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:33:35.313+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:33:35.321+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:33:35.313+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:33:35.322+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:33:35.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.107 seconds
[2026-01-23T05:34:06.148+0000] {processor.py:161} INFO - Started process (PID=2616) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:34:06.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:34:06.151+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:34:06.151+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:34:06.182+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:34:06.181+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:34:06.183+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:34:06.183+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:34:06.184+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:34:06.184+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:34:06.188+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:34:06.187+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:34:06.190+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:34:06.189+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:34:06.192+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:34:06.191+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:34:06.192+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:34:06.192+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:34:06.196+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:34:06.193+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:34:06.197+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:34:06.230+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.087 seconds
[2026-01-23T05:34:36.933+0000] {processor.py:161} INFO - Started process (PID=2626) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:34:36.934+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:34:36.937+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:34:36.936+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:34:36.962+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:34:36.962+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:34:36.963+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:34:36.963+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:34:36.963+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:34:36.963+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:34:36.967+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:34:36.967+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:34:36.969+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:34:36.969+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:34:36.971+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:34:36.970+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:34:36.971+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:34:36.971+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:34:36.976+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:34:36.971+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:34:36.976+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:34:37.009+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.081 seconds
[2026-01-23T05:35:07.606+0000] {processor.py:161} INFO - Started process (PID=2636) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:35:07.607+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:35:07.609+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:35:07.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:35:07.647+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:35:07.647+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:35:07.648+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:35:07.647+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:35:07.648+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:35:07.648+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:35:07.651+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:35:07.651+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:35:07.653+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:35:07.653+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:35:07.655+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:35:07.655+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:35:07.656+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:35:07.656+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:35:07.661+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:35:07.656+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:35:07.661+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:35:07.693+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.093 seconds
[2026-01-23T05:35:38.419+0000] {processor.py:161} INFO - Started process (PID=2646) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:35:38.421+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:35:38.423+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:35:38.423+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:35:38.472+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:35:38.472+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:35:38.473+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:35:38.473+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:35:38.474+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:35:38.474+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:35:38.478+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:35:38.477+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:35:38.480+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:35:38.479+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:35:38.482+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:35:38.481+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:35:38.482+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:35:38.482+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:35:38.487+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:35:38.483+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:35:38.487+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:35:38.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.106 seconds
[2026-01-23T05:36:09.184+0000] {processor.py:161} INFO - Started process (PID=2656) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:36:09.185+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:36:09.187+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:36:09.186+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:36:09.217+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:36:09.217+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:36:09.218+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:36:09.218+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:36:09.219+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:36:09.219+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:36:09.223+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:36:09.223+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:36:09.225+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:36:09.225+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:36:09.228+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:36:09.227+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:36:09.228+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:36:09.228+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:36:09.232+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:36:09.228+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:36:09.233+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:36:09.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.086 seconds
[2026-01-23T05:36:39.829+0000] {processor.py:161} INFO - Started process (PID=2666) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:36:39.830+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:36:39.832+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:36:39.831+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:36:39.859+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:36:39.859+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:36:39.860+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:36:39.860+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:36:39.861+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:36:39.861+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:36:39.864+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:36:39.864+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:36:39.866+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:36:39.866+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:36:39.868+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:36:39.868+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:36:39.869+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:36:39.869+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:36:39.873+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:36:39.869+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:36:39.874+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:36:39.905+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.082 seconds
[2026-01-23T05:37:09.965+0000] {processor.py:161} INFO - Started process (PID=2676) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:37:09.966+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:37:09.968+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:37:09.968+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:37:10.002+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:37:10.002+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:37:10.003+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:37:10.003+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:37:10.004+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:37:10.004+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:37:10.008+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:37:10.007+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:37:10.010+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:37:10.010+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:37:10.013+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:37:10.012+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:37:10.013+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:37:10.013+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:37:10.019+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:37:10.013+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:37:10.020+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:37:10.056+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.097 seconds
[2026-01-23T05:37:40.679+0000] {processor.py:161} INFO - Started process (PID=2686) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:37:40.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:37:40.682+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:37:40.682+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:37:40.711+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:37:40.711+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:37:40.712+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:37:40.712+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:37:40.713+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:37:40.713+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:37:40.716+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:37:40.716+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:37:40.718+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:37:40.718+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:37:40.720+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:37:40.720+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:37:40.721+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:37:40.721+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:37:40.725+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:37:40.721+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:37:40.726+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:37:40.758+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.084 seconds
[2026-01-23T05:38:11.515+0000] {processor.py:161} INFO - Started process (PID=2696) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:38:11.517+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:38:11.520+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:38:11.519+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:38:11.559+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:38:11.559+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:38:11.560+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:38:11.560+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:38:11.561+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:38:11.561+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:38:11.565+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:38:11.565+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:38:11.568+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:38:11.568+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:38:11.571+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:38:11.570+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:38:11.572+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:38:11.571+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:38:11.578+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:38:11.572+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:38:11.579+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:38:11.621+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.112 seconds
[2026-01-23T05:38:42.273+0000] {processor.py:161} INFO - Started process (PID=2706) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:38:42.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:38:42.278+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:38:42.277+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:38:42.313+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:38:42.312+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:38:42.313+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:38:42.313+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:38:42.314+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:38:42.314+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:38:42.317+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:38:42.317+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:38:42.319+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:38:42.319+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:38:42.321+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:38:42.321+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:38:42.322+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:38:42.322+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:38:42.326+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:38:42.322+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:38:42.327+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:38:42.361+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.095 seconds
[2026-01-23T05:39:13.042+0000] {processor.py:161} INFO - Started process (PID=2716) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:39:13.043+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:39:13.045+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:39:13.045+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:39:13.077+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:39:13.077+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:39:13.078+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:39:13.078+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:39:13.079+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:39:13.079+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:39:13.082+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:39:13.082+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:39:13.084+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:39:13.083+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:39:13.085+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:39:13.085+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:39:13.086+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:39:13.086+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:39:13.091+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:39:13.086+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:39:13.091+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:39:13.123+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.086 seconds
[2026-01-23T05:39:43.699+0000] {processor.py:161} INFO - Started process (PID=2726) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:39:43.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:39:43.702+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:39:43.701+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:39:43.739+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:39:43.739+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:39:43.740+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:39:43.740+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:39:43.741+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:39:43.741+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:39:43.744+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:39:43.744+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:39:43.747+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:39:43.746+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:39:43.748+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:39:43.748+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:39:43.749+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:39:43.749+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:39:43.753+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:39:43.749+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:39:43.753+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:39:43.783+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.090 seconds
[2026-01-23T05:40:14.564+0000] {processor.py:161} INFO - Started process (PID=2736) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:40:14.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:40:14.568+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:40:14.567+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:40:14.598+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:40:14.598+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:40:14.599+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:40:14.599+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:40:14.600+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:40:14.600+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:40:14.604+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:40:14.604+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:40:14.606+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:40:14.606+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:40:14.608+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:40:14.608+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:40:14.609+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:40:14.608+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:40:14.613+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:40:14.609+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:40:14.613+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:40:14.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.087 seconds
[2026-01-23T05:40:45.239+0000] {processor.py:161} INFO - Started process (PID=2746) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:40:45.240+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:40:45.241+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:40:45.241+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:40:45.269+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:40:45.269+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:40:45.270+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:40:45.270+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:40:45.271+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:40:45.270+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:40:45.274+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:40:45.273+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:40:45.276+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:40:45.275+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:40:45.278+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:40:45.278+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:40:45.278+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:40:45.278+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:40:45.283+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:40:45.279+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:40:45.283+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:40:45.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.081 seconds
[2026-01-23T05:41:15.904+0000] {processor.py:161} INFO - Started process (PID=2756) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:41:15.905+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:41:15.908+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:41:15.907+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:41:15.946+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:41:15.946+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:41:15.947+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:41:15.947+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:41:15.948+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:41:15.948+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:41:15.951+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:41:15.951+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:41:15.953+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:41:15.953+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:41:15.955+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:41:15.955+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:41:15.955+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:41:15.955+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:41:15.960+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:41:15.956+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:41:15.961+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:41:15.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.100 seconds
[2026-01-23T05:41:46.667+0000] {processor.py:161} INFO - Started process (PID=2766) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:41:46.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:41:46.670+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:41:46.670+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:41:46.702+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:41:46.702+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:41:46.703+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:41:46.703+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:41:46.704+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:41:46.704+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:41:46.707+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:41:46.707+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:41:46.710+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:41:46.710+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:41:46.712+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:41:46.712+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:41:46.713+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:41:46.713+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:41:46.718+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:41:46.713+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:41:46.719+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:41:46.753+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.092 seconds
[2026-01-23T05:42:17.229+0000] {processor.py:161} INFO - Started process (PID=2776) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:42:17.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:42:17.233+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:42:17.233+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:42:17.266+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:42:17.265+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:42:17.267+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:42:17.267+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:42:17.268+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:42:17.267+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:42:17.271+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:42:17.271+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:42:17.273+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:42:17.273+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:42:17.275+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:42:17.275+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:42:17.276+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:42:17.276+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:42:17.280+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:42:17.276+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:42:17.281+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:42:17.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.093 seconds
[2026-01-23T05:42:47.618+0000] {processor.py:161} INFO - Started process (PID=2786) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:42:47.620+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:42:47.622+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:42:47.622+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:42:47.652+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:42:47.652+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:42:47.653+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:42:47.653+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:42:47.653+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:42:47.653+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:42:47.657+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:42:47.656+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:42:47.659+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:42:47.659+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:42:47.661+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:42:47.661+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:42:47.662+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:42:47.661+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:42:47.666+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:42:47.662+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:42:47.667+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:42:47.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.089 seconds
[2026-01-23T05:43:18.669+0000] {processor.py:161} INFO - Started process (PID=2796) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:43:18.670+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:43:18.672+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:43:18.671+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:43:18.701+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:43:18.700+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:43:18.701+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:43:18.701+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:43:18.702+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:43:18.702+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:43:18.705+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:43:18.705+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:43:18.707+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:43:18.707+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:43:18.709+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:43:18.709+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:43:18.710+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:43:18.709+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:43:18.716+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:43:18.710+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:43:18.717+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:43:18.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.088 seconds
[2026-01-23T05:43:49.049+0000] {processor.py:161} INFO - Started process (PID=2806) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:43:49.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:43:49.052+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:43:49.052+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:43:49.086+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:43:49.085+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:43:49.087+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:43:49.086+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:43:49.087+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:43:49.087+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:43:49.091+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:43:49.091+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:43:49.094+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:43:49.093+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:43:49.096+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:43:49.096+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:43:49.097+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:43:49.096+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:43:49.103+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:43:49.098+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:43:49.104+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:43:49.144+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.101 seconds
[2026-01-23T05:44:19.813+0000] {processor.py:161} INFO - Started process (PID=2816) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:44:19.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:44:19.817+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:44:19.817+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:44:19.845+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:44:19.845+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:44:19.846+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:44:19.846+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:44:19.847+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:44:19.847+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:44:19.851+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:44:19.850+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:44:19.853+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:44:19.853+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:44:19.855+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:44:19.855+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:44:19.856+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:44:19.855+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:44:19.860+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:44:19.856+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:44:19.861+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:44:19.895+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.088 seconds
[2026-01-23T05:44:50.644+0000] {processor.py:161} INFO - Started process (PID=2826) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:44:50.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:44:50.648+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:44:50.647+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:44:50.698+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:44:50.697+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:44:50.700+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:44:50.699+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:44:50.701+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:44:50.701+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:44:50.706+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:44:50.705+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:44:50.709+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:44:50.708+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:44:50.711+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:44:50.711+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:44:50.712+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:44:50.712+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:44:50.721+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:44:50.712+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:44:50.722+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:44:50.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.134 seconds
[2026-01-23T05:45:21.437+0000] {processor.py:161} INFO - Started process (PID=2836) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:45:21.438+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:45:21.441+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:45:21.440+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:45:21.471+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:45:21.470+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:45:21.471+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:45:21.471+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:45:21.472+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:45:21.472+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:45:21.476+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:45:21.475+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:45:21.478+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:45:21.478+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:45:21.481+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:45:21.480+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:45:21.481+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:45:21.481+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:45:21.486+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:45:21.482+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:45:21.486+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:45:21.522+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.091 seconds
[2026-01-23T05:45:52.235+0000] {processor.py:161} INFO - Started process (PID=2846) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:45:52.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:45:52.238+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:45:52.238+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:45:52.273+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:45:52.273+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:45:52.274+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:45:52.273+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:45:52.275+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:45:52.275+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:45:52.279+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:45:52.278+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:45:52.281+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:45:52.281+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:45:52.284+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:45:52.283+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:45:52.284+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:45:52.284+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:45:52.289+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:45:52.284+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:45:52.289+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:45:52.323+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.095 seconds
[2026-01-23T05:46:22.979+0000] {processor.py:161} INFO - Started process (PID=2856) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:46:22.980+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:46:22.982+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:46:22.981+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:46:23.008+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:46:23.008+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T05:46:23.009+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:46:23.009+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T05:46:23.010+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:46:23.010+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T05:46:23.013+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:46:23.013+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:46:23.015+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:46:23.015+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:46:23.017+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:46:23.017+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T05:46:23.017+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:46:23.017+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T05:46:23.021+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:46:23.018+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T05:46:23.022+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:46:23.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.080 seconds
[2026-01-23T05:46:58.183+0000] {processor.py:161} INFO - Started process (PID=2866) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T05:46:58.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T05:46:58.204+0000] {logging_mixin.py:188} INFO - [2026-01-23T05:46:58.203+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:17:41.443+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:17:41.442+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:17:41.470+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:17:41.469+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:17:41.483+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:17:41.482+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:17:41.519+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:17:41.517+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:17:41.554+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:17:41.554+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:17:41.578+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:17:41.577+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:17:41.585+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:17:41.583+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:17:41.672+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:17:41.590+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:17:41.687+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:17:42.094+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 3.137 seconds
[2026-01-23T09:18:13.430+0000] {processor.py:161} INFO - Started process (PID=2876) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:18:13.432+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:18:13.437+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:18:13.436+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:18:13.516+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:18:13.516+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:18:13.519+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:18:13.518+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:18:13.521+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:18:13.520+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:18:13.528+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:18:13.528+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:18:13.534+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:18:13.534+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:18:13.540+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:18:13.539+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:18:13.541+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:18:13.541+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:18:13.556+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:18:13.542+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:18:13.559+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:18:13.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.239 seconds
[2026-01-23T09:18:44.656+0000] {processor.py:161} INFO - Started process (PID=2885) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:18:44.658+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:18:44.662+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:18:44.662+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:18:44.743+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:18:44.742+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:18:44.744+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:18:44.744+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:18:44.745+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:18:44.745+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:18:44.752+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:18:44.751+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:18:44.757+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:18:44.756+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:18:44.764+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:18:44.763+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:18:44.765+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:18:44.765+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:18:44.778+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:18:44.766+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:18:44.779+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:18:44.859+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.212 seconds
[2026-01-23T09:19:15.720+0000] {processor.py:161} INFO - Started process (PID=2895) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:19:15.723+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:19:15.728+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:19:15.727+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:19:15.795+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:19:15.795+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:19:15.797+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:19:15.796+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:19:15.798+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:19:15.798+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:19:15.805+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:19:15.804+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:19:15.810+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:19:15.810+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:19:15.816+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:19:15.815+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:19:15.817+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:19:15.817+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:19:15.831+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:19:15.819+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:19:15.833+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:19:15.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.208 seconds
[2026-01-23T09:19:47.024+0000] {processor.py:161} INFO - Started process (PID=2905) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:19:47.026+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:19:47.029+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:19:47.029+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:19:47.091+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:19:47.090+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:19:47.092+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:19:47.092+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:19:47.093+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:19:47.093+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:19:47.101+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:19:47.101+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:19:47.106+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:19:47.106+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:19:47.111+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:19:47.110+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:19:47.112+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:19:47.111+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:19:47.123+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:19:47.112+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:19:47.125+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:19:47.197+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.182 seconds
[2026-01-23T09:20:17.805+0000] {processor.py:161} INFO - Started process (PID=2915) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:20:17.807+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:20:17.810+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:20:17.810+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:20:17.877+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:20:17.877+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:20:17.879+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:20:17.878+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:20:17.880+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:20:17.880+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:20:17.888+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:20:17.888+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:20:17.895+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:20:17.894+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:20:17.899+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:20:17.899+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:20:17.902+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:20:17.901+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:20:17.914+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:20:17.903+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:20:17.915+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:20:17.992+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.197 seconds
[2026-01-23T09:20:48.642+0000] {processor.py:161} INFO - Started process (PID=2925) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:20:48.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:20:48.648+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:20:48.647+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:20:48.714+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:20:48.713+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:20:48.716+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:20:48.715+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:20:48.718+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:20:48.717+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:20:48.724+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:20:48.723+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:20:48.728+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:20:48.728+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:20:48.734+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:20:48.733+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:20:48.735+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:20:48.735+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:20:48.746+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:20:48.736+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:20:48.747+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:20:48.828+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.196 seconds
[2026-01-23T09:21:20.218+0000] {processor.py:161} INFO - Started process (PID=2935) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:21:20.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:21:20.225+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:21:20.225+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:21:20.300+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:21:20.299+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:21:20.301+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:21:20.301+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:21:20.302+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:21:20.302+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:21:20.309+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:21:20.309+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:21:20.325+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:21:20.324+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:21:20.330+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:21:20.329+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:21:20.331+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:21:20.331+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:21:20.343+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:21:20.331+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:21:20.344+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:21:20.426+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.225 seconds
[2026-01-23T09:21:51.726+0000] {processor.py:161} INFO - Started process (PID=2945) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:21:51.729+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:21:51.733+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:21:51.732+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:21:51.803+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:21:51.803+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:21:51.805+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:21:51.804+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:21:51.807+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:21:51.806+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:21:51.813+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:21:51.813+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:21:51.817+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:21:51.817+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:21:51.822+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:21:51.821+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:21:51.823+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:21:51.823+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:21:51.833+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:21:51.824+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:21:51.835+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:21:51.904+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.185 seconds
[2026-01-23T09:22:22.336+0000] {processor.py:161} INFO - Started process (PID=2955) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:22:22.339+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:22:22.342+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:22:22.342+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:22:22.430+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:22:22.429+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:22:22.431+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:22:22.431+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:22:22.432+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:22:22.432+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:22:22.440+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:22:22.440+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:22:22.445+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:22:22.445+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:22:22.450+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:22:22.449+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:22:22.451+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:22:22.451+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:22:22.465+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:22:22.452+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:22:22.467+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:22:22.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.233 seconds
[2026-01-23T09:22:53.910+0000] {processor.py:161} INFO - Started process (PID=2965) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:22:53.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:22:53.914+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:22:53.914+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:22:53.978+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:22:53.978+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:22:53.980+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:22:53.980+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:22:53.982+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:22:53.982+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:22:53.991+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:22:53.990+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:22:53.995+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:22:53.995+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:22:54.001+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:22:54.000+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:22:54.003+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:22:54.002+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:22:54.020+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:22:54.004+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:22:54.022+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:22:54.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.209 seconds
[2026-01-23T09:23:24.946+0000] {processor.py:161} INFO - Started process (PID=2975) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:23:24.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:23:24.951+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:23:24.950+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:23:25.021+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:23:25.021+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:23:25.022+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:23:25.022+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:23:25.024+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:23:25.024+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:23:25.032+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:23:25.031+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:23:25.037+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:23:25.036+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:23:25.041+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:23:25.041+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:23:25.042+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:23:25.042+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:23:25.054+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:23:25.043+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:23:25.055+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:23:25.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.192 seconds
[2026-01-23T09:23:55.803+0000] {processor.py:161} INFO - Started process (PID=2985) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:23:55.805+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:23:55.809+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:23:55.808+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:23:55.883+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:23:55.882+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:23:55.885+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:23:55.884+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:23:55.886+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:23:55.886+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:23:55.894+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:23:55.894+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:23:55.899+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:23:55.899+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:23:55.905+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:23:55.905+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:23:55.907+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:23:55.906+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:23:55.921+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:23:55.908+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:23:55.923+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:23:56.009+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.221 seconds
[2026-01-23T09:24:27.216+0000] {processor.py:161} INFO - Started process (PID=2995) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:24:27.218+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:24:27.222+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:24:27.221+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:24:27.303+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:24:27.302+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:24:27.305+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:24:27.305+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:24:27.306+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:24:27.306+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:24:27.313+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:24:27.312+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:24:27.319+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:24:27.318+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:24:27.324+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:24:27.324+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:24:27.326+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:24:27.325+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:24:27.341+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:24:27.327+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:24:27.343+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:24:27.436+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.228 seconds
[2026-01-23T09:24:58.405+0000] {processor.py:161} INFO - Started process (PID=3005) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:24:58.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:24:58.410+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:24:58.410+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:24:58.480+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:24:58.480+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:24:58.482+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:24:58.481+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:24:58.483+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:24:58.483+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:24:58.491+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:24:58.490+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:24:58.497+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:24:58.497+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:24:58.503+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:24:58.503+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:24:58.505+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:24:58.504+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:24:58.521+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:24:58.506+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:24:58.523+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:24:58.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.217 seconds
[2026-01-23T09:25:29.734+0000] {processor.py:161} INFO - Started process (PID=3015) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:25:29.736+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:25:29.741+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:25:29.740+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:25:29.825+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:25:29.824+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:25:29.827+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:25:29.826+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:25:29.829+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:25:29.829+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:25:29.838+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:25:29.837+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:25:29.845+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:25:29.843+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:25:29.851+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:25:29.850+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:25:29.852+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:25:29.852+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:25:29.867+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:25:29.853+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:25:29.868+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:25:29.946+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.220 seconds
[2026-01-23T09:26:00.411+0000] {processor.py:161} INFO - Started process (PID=3025) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:26:00.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:26:00.422+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:26:00.420+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:26:00.555+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:26:00.554+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:26:00.559+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:26:00.558+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:26:00.562+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:26:00.561+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:26:00.570+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:26:00.570+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:26:00.577+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:26:00.576+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:26:00.583+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:26:00.583+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:26:00.585+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:26:00.584+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:26:00.604+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:26:00.586+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:26:00.606+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:26:00.723+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.329 seconds
[2026-01-23T09:26:30.949+0000] {processor.py:161} INFO - Started process (PID=3034) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:26:30.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:26:30.955+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:26:30.954+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:26:31.031+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:26:31.030+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:26:31.032+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:26:31.032+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:26:31.033+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:26:31.033+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:26:31.039+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:26:31.039+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:26:31.044+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:26:31.043+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:26:31.048+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:26:31.048+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:26:31.049+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:26:31.049+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:26:31.060+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:26:31.050+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:26:31.061+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:26:31.137+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.205 seconds
[2026-01-23T09:27:02.589+0000] {processor.py:161} INFO - Started process (PID=3044) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:27:02.592+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:27:02.595+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:27:02.595+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:27:02.684+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:27:02.684+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:27:02.686+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:27:02.686+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:27:02.687+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:27:02.687+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:27:02.694+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:27:02.694+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:27:02.698+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:27:02.698+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:27:02.703+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:27:02.703+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:27:02.705+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:27:02.705+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:27:02.720+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:27:02.705+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:27:02.721+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:27:02.813+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.231 seconds
[2026-01-23T09:27:33.328+0000] {processor.py:161} INFO - Started process (PID=3054) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:27:33.331+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:27:33.337+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:27:33.336+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:27:33.400+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:27:33.399+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:27:33.401+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:27:33.401+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:27:33.402+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:27:33.402+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:27:33.409+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:27:33.409+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:27:33.414+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:27:33.413+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:27:33.417+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:27:33.417+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:27:33.418+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:27:33.418+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:27:33.430+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:27:33.419+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:27:33.431+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:27:33.507+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.189 seconds
[2026-01-23T09:28:04.527+0000] {processor.py:161} INFO - Started process (PID=3064) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:28:04.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:28:04.532+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:28:04.532+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:28:04.597+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:28:04.597+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:28:04.598+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:28:04.598+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:28:04.600+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:28:04.600+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:28:04.608+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:28:04.608+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:28:04.613+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:28:04.613+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:28:04.619+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:28:04.618+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:28:04.620+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:28:04.620+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:28:04.634+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:28:04.621+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:28:04.635+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:28:04.737+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.220 seconds
[2026-01-23T09:28:35.778+0000] {processor.py:161} INFO - Started process (PID=3074) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:28:35.781+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:28:35.784+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:28:35.784+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:28:35.874+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:28:35.874+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:28:35.876+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:28:35.876+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:28:35.878+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:28:35.877+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:28:35.886+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:28:35.885+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:28:35.892+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:28:35.891+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:28:35.898+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:28:35.898+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:28:35.899+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:28:35.899+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:28:35.916+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:28:35.900+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:28:35.917+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:28:36.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.261 seconds
[2026-01-23T09:29:06.853+0000] {processor.py:161} INFO - Started process (PID=3084) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:29:06.855+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:29:06.859+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:29:06.859+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:29:06.940+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:29:06.940+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:29:06.942+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:29:06.942+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:29:06.943+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:29:06.943+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:29:06.949+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:29:06.948+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:29:06.952+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:29:06.952+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:29:06.956+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:29:06.955+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:29:06.957+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:29:06.957+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:29:06.971+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:29:06.958+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:29:06.972+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:29:07.054+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.209 seconds
[2026-01-23T09:29:38.225+0000] {processor.py:161} INFO - Started process (PID=3094) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:29:38.227+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:29:38.232+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:29:38.232+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:29:38.293+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:29:38.292+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:29:38.294+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:29:38.294+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:29:38.295+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:29:38.295+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:29:38.301+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:29:38.300+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:29:38.305+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:29:38.304+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:29:38.309+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:29:38.309+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:29:38.310+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:29:38.310+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:29:38.321+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:29:38.311+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:29:38.322+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:29:38.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.183 seconds
[2026-01-23T09:30:09.659+0000] {processor.py:161} INFO - Started process (PID=3104) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:30:09.662+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:30:09.665+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:30:09.664+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:30:09.732+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:30:09.732+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:30:09.734+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:30:09.733+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:30:09.735+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:30:09.735+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:30:09.743+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:30:09.742+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:30:09.748+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:30:09.747+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:30:09.753+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:30:09.752+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:30:09.754+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:30:09.754+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:30:09.765+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:30:09.755+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:30:09.766+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:30:09.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.207 seconds
[2026-01-23T09:30:40.494+0000] {processor.py:161} INFO - Started process (PID=3114) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:30:40.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:30:40.500+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:30:40.499+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:30:40.608+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:30:40.607+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:30:40.610+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:30:40.610+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:30:40.612+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:30:40.612+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:30:40.621+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:30:40.620+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:30:40.627+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:30:40.627+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:30:40.634+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:30:40.633+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:30:40.636+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:30:40.635+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:30:40.655+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:30:40.637+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:30:40.657+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:30:40.762+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.279 seconds
[2026-01-23T09:31:11.597+0000] {processor.py:161} INFO - Started process (PID=3124) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:31:11.600+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:31:11.604+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:31:11.603+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:31:11.674+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:31:11.674+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:31:11.675+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:31:11.675+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:31:11.676+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:31:11.676+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:31:11.683+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:31:11.682+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:31:11.687+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:31:11.686+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:31:11.691+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:31:11.691+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:31:11.692+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:31:11.692+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:31:11.704+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:31:11.693+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:31:11.706+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:31:11.778+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.192 seconds
[2026-01-23T09:31:42.546+0000] {processor.py:161} INFO - Started process (PID=3134) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:31:42.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:31:42.553+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:31:42.552+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:31:42.620+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:31:42.620+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:31:42.621+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:31:42.621+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:31:42.623+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:31:42.623+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:31:42.630+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:31:42.630+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:31:42.636+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:31:42.635+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:31:42.642+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:31:42.641+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:31:42.643+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:31:42.642+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:31:42.657+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:31:42.643+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:31:42.658+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:31:42.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.203 seconds
[2026-01-23T09:32:13.945+0000] {processor.py:161} INFO - Started process (PID=3144) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:32:13.947+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:32:13.950+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:32:13.950+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:32:14.019+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:32:14.018+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:32:14.021+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:32:14.021+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:32:14.023+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:32:14.023+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:32:14.029+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:32:14.029+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:32:14.036+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:32:14.035+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:32:14.040+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:32:14.039+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:32:14.041+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:32:14.041+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:32:14.052+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:32:14.042+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:32:14.054+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:32:14.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.210 seconds
[2026-01-23T09:32:44.870+0000] {processor.py:161} INFO - Started process (PID=3154) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:32:44.872+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:32:44.875+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:32:44.874+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:32:44.963+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:32:44.962+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:32:44.964+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:32:44.964+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:32:44.966+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:32:44.966+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:32:44.976+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:32:44.975+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:32:44.982+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:32:44.981+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:32:44.988+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:32:44.988+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:32:44.990+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:32:44.989+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:32:45.008+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:32:44.991+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:32:45.010+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:32:45.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.234 seconds
[2026-01-23T09:33:15.288+0000] {processor.py:161} INFO - Started process (PID=3164) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:33:15.290+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:33:15.294+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:33:15.293+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:33:15.356+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:33:15.355+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:33:15.357+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:33:15.357+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:33:15.359+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:33:15.358+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:33:15.366+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:33:15.366+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:33:15.371+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:33:15.370+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:33:15.376+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:33:15.376+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:33:15.377+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:33:15.377+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:33:15.389+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:33:15.378+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:33:15.390+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:33:15.464+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.184 seconds
[2026-01-23T09:33:46.038+0000] {processor.py:161} INFO - Started process (PID=3174) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:33:46.041+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:33:46.045+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:33:46.044+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:33:46.136+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:33:46.135+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:33:46.137+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:33:46.137+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:33:46.139+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:33:46.139+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:33:46.147+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:33:46.147+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:33:46.152+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:33:46.152+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:33:46.158+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:33:46.157+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:33:46.159+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:33:46.159+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:33:46.171+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:33:46.160+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:33:46.172+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:33:46.248+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.221 seconds
[2026-01-23T09:34:16.655+0000] {processor.py:161} INFO - Started process (PID=3184) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:34:16.657+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:34:16.661+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:34:16.661+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:34:16.763+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:34:16.762+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:34:16.764+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:34:16.764+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:34:16.767+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:34:16.766+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:34:16.775+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:34:16.775+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:34:16.780+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:34:16.779+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:34:16.785+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:34:16.785+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:34:16.786+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:34:16.786+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:34:16.803+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:34:16.787+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:34:16.804+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:34:16.907+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.259 seconds
[2026-01-23T09:34:47.613+0000] {processor.py:161} INFO - Started process (PID=3194) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:34:47.615+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:34:47.618+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:34:47.618+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:34:47.722+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:34:47.721+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:34:47.724+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:34:47.723+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:34:47.726+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:34:47.726+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:34:47.735+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:34:47.734+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:34:47.741+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:34:47.740+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:34:47.748+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:34:47.747+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:34:47.749+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:34:47.749+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:34:47.767+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:34:47.750+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:34:47.769+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:34:47.860+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.255 seconds
[2026-01-23T09:35:18.333+0000] {processor.py:161} INFO - Started process (PID=3204) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:35:18.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:35:18.340+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:35:18.339+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:35:18.405+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:35:18.404+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:35:18.407+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:35:18.406+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:35:18.408+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:35:18.408+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:35:18.415+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:35:18.414+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:35:18.419+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:35:18.419+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:35:18.425+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:35:18.425+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:35:18.427+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:35:18.426+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:35:18.436+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:35:18.427+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:35:18.438+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:35:18.511+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.191 seconds
[2026-01-23T09:35:48.874+0000] {processor.py:161} INFO - Started process (PID=3214) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:35:48.879+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:35:48.888+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:35:48.887+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:35:48.979+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:35:48.978+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:35:48.980+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:35:48.980+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:35:48.981+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:35:48.981+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:35:48.988+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:35:48.988+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:35:48.994+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:35:48.993+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:35:49.001+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:35:49.000+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:35:49.002+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:35:49.002+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:35:49.017+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:35:49.004+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:35:49.020+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:35:49.115+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.261 seconds
[2026-01-23T09:36:20.303+0000] {processor.py:161} INFO - Started process (PID=3224) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:36:20.305+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:36:20.308+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:36:20.308+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:36:20.371+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:36:20.370+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:36:20.372+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:36:20.372+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:36:20.374+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:36:20.373+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:36:20.380+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:36:20.379+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:36:20.387+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:36:20.387+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:36:20.392+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:36:20.392+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:36:20.393+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:36:20.393+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:36:20.404+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:36:20.394+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:36:20.405+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:36:20.503+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.211 seconds
[2026-01-23T09:36:51.447+0000] {processor.py:161} INFO - Started process (PID=3234) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:36:51.450+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:36:51.455+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:36:51.454+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:36:51.526+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:36:51.526+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:36:51.527+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:36:51.527+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:36:51.528+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:36:51.528+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:36:51.534+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:36:51.534+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:36:51.538+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:36:51.538+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:36:51.543+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:36:51.542+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:36:51.544+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:36:51.544+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:36:51.559+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:36:51.545+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:36:51.560+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:36:51.655+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.225 seconds
[2026-01-23T09:37:22.452+0000] {processor.py:161} INFO - Started process (PID=3244) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:37:22.454+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:37:22.458+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:37:22.458+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:37:22.529+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:37:22.529+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:37:22.531+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:37:22.531+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:37:22.532+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:37:22.532+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:37:22.538+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:37:22.538+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:37:22.542+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:37:22.541+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:37:22.547+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:37:22.546+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:37:22.548+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:37:22.547+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:37:22.561+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:37:22.548+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:37:22.563+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:37:22.637+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.193 seconds
[2026-01-23T09:37:52.997+0000] {processor.py:161} INFO - Started process (PID=3254) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:37:52.999+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:37:53.003+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:37:53.002+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:37:53.064+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:37:53.064+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:37:53.066+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:37:53.066+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:37:53.067+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:37:53.067+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:37:53.072+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:37:53.071+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:37:53.076+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:37:53.076+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:37:53.080+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:37:53.079+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:37:53.081+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:37:53.080+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:37:53.090+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:37:53.081+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:37:53.092+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:37:53.153+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.166 seconds
[2026-01-23T09:38:23.608+0000] {processor.py:161} INFO - Started process (PID=3264) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:38:23.610+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:38:23.613+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:38:23.613+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:38:23.675+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:38:23.675+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:38:23.676+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:38:23.676+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:38:23.678+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:38:23.677+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:38:23.684+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:38:23.683+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:38:23.689+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:38:23.688+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:38:23.694+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:38:23.693+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:38:23.695+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:38:23.694+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:38:23.705+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:38:23.695+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:38:23.707+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:38:23.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.182 seconds
[2026-01-23T09:38:54.316+0000] {processor.py:161} INFO - Started process (PID=3274) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:38:54.319+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:38:54.324+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:38:54.323+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:38:54.429+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:38:54.428+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:38:54.430+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:38:54.430+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:38:54.433+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:38:54.432+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:38:54.442+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:38:54.441+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:38:54.448+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:38:54.448+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:38:54.455+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:38:54.454+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:38:54.456+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:38:54.456+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:38:54.475+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:38:54.458+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:38:54.477+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:38:54.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.298 seconds
[2026-01-23T09:39:24.827+0000] {processor.py:161} INFO - Started process (PID=3284) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:39:24.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:39:24.832+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:39:24.831+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:39:24.910+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:39:24.910+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:39:24.911+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:39:24.911+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:39:24.912+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:39:24.912+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:39:24.917+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:39:24.917+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:39:24.922+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:39:24.921+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:39:24.926+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:39:24.926+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:39:24.927+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:39:24.927+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:39:24.939+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:39:24.928+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:39:24.940+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:39:25.016+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.198 seconds
[2026-01-23T09:39:55.851+0000] {processor.py:161} INFO - Started process (PID=3294) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:39:55.855+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:39:55.860+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:39:55.860+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:39:55.978+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:39:55.978+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:39:55.980+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:39:55.979+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:39:55.982+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:39:55.981+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:39:55.989+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:39:55.988+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:39:55.995+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:39:55.994+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:39:56.000+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:39:55.999+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:39:56.001+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:39:56.001+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:39:56.016+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:39:56.002+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:39:56.017+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:39:56.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.275 seconds
[2026-01-23T09:40:26.611+0000] {processor.py:161} INFO - Started process (PID=3304) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:40:26.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:40:26.616+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:40:26.616+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:40:26.690+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:40:26.690+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:40:26.692+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:40:26.692+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:40:26.694+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:40:26.693+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:40:26.701+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:40:26.700+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:40:26.706+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:40:26.705+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:40:26.710+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:40:26.710+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:40:26.712+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:40:26.711+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:40:26.728+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:40:26.712+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:40:26.730+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:40:26.825+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.222 seconds
[2026-01-23T09:40:57.710+0000] {processor.py:161} INFO - Started process (PID=3314) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:40:57.712+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:40:57.717+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:40:57.716+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:40:57.791+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:40:57.790+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:40:57.792+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:40:57.792+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:40:57.794+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:40:57.794+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:40:57.801+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:40:57.801+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:40:57.807+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:40:57.806+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:40:57.811+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:40:57.810+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:40:57.812+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:40:57.811+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:40:57.824+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:40:57.813+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:40:57.825+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:40:57.899+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.202 seconds
[2026-01-23T09:41:28.685+0000] {processor.py:161} INFO - Started process (PID=3324) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:41:28.688+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:41:28.692+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:41:28.692+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:41:28.791+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:41:28.790+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:41:28.793+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:41:28.793+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:41:28.795+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:41:28.794+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:41:28.802+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:41:28.801+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:41:28.806+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:41:28.805+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:41:28.811+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:41:28.811+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:41:28.813+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:41:28.813+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:41:28.830+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:41:28.814+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:41:28.831+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:41:28.927+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.254 seconds
[2026-01-23T09:41:59.944+0000] {processor.py:161} INFO - Started process (PID=3334) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:41:59.946+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:41:59.950+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:41:59.950+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:42:00.024+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:42:00.023+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:42:00.025+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:42:00.025+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:42:00.027+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:42:00.026+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:42:00.033+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:42:00.033+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:42:00.038+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:42:00.037+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:42:00.050+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:42:00.049+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:42:00.051+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:42:00.051+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:42:00.064+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:42:00.052+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:42:00.065+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:42:00.142+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.209 seconds
[2026-01-23T09:42:31.041+0000] {processor.py:161} INFO - Started process (PID=3344) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:42:31.044+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:42:31.047+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:42:31.046+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:42:31.105+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:42:31.104+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:42:31.106+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:42:31.106+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:42:31.108+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:42:31.107+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:42:31.114+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:42:31.113+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:42:31.118+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:42:31.117+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:42:31.122+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:42:31.122+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:42:31.123+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:42:31.123+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:42:31.135+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:42:31.124+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:42:31.136+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:42:31.204+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.171 seconds
[2026-01-23T09:43:02.108+0000] {processor.py:161} INFO - Started process (PID=3354) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:43:02.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:43:02.114+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:43:02.113+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:43:02.190+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:43:02.190+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:43:02.192+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:43:02.192+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:43:02.193+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:43:02.193+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:43:02.199+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:43:02.199+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:43:02.203+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:43:02.203+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:43:02.207+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:43:02.207+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:43:02.208+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:43:02.208+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:43:02.217+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:43:02.209+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:43:02.219+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:43:02.282+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.182 seconds
[2026-01-23T09:43:32.932+0000] {processor.py:161} INFO - Started process (PID=3364) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:43:32.934+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:43:32.937+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:43:32.936+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:43:32.988+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:43:32.987+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:43:32.989+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:43:32.989+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:43:32.990+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:43:32.990+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:43:32.996+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:43:32.996+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:43:33.002+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:43:33.001+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:43:33.007+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:43:33.006+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:43:33.008+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:43:33.008+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:43:33.020+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:43:33.008+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:43:33.021+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:43:33.096+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.172 seconds
[2026-01-23T09:44:04.137+0000] {processor.py:161} INFO - Started process (PID=3374) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:44:04.139+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:44:04.142+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:44:04.141+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:44:04.199+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:44:04.199+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:44:04.200+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:44:04.200+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:44:04.201+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:44:04.201+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:44:04.208+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:44:04.207+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:44:04.212+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:44:04.212+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:44:04.217+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:44:04.217+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:44:04.218+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:44:04.218+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:44:04.232+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:44:04.219+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:44:04.234+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:44:04.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.207 seconds
[2026-01-23T09:44:34.666+0000] {processor.py:161} INFO - Started process (PID=3384) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:44:34.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:44:34.671+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:44:34.671+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:44:34.736+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:44:34.735+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:44:34.737+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:44:34.736+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:44:34.738+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:44:34.738+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:44:34.743+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:44:34.743+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:44:34.749+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:44:34.748+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:44:34.755+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:44:34.755+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:44:34.756+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:44:34.756+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:44:34.770+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:44:34.757+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:44:34.772+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:44:34.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.228 seconds
[2026-01-23T09:52:48.089+0000] {processor.py:161} INFO - Started process (PID=3390) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:52:48.091+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:52:48.095+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:52:48.094+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:52:48.177+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:52:48.176+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:52:48.179+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:52:48.178+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:52:48.181+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:52:48.180+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:52:48.188+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:52:48.188+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:52:48.193+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:52:48.192+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:52:48.199+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:52:48.199+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:52:48.201+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:52:48.200+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:52:48.213+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:52:48.202+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:52:48.215+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:52:48.295+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.222 seconds
[2026-01-23T09:53:19.613+0000] {processor.py:161} INFO - Started process (PID=3400) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:53:19.615+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:53:19.618+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:53:19.618+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:53:19.681+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:53:19.680+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:53:19.682+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:53:19.682+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:53:19.684+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:53:19.683+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:53:19.690+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:53:19.689+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:53:19.695+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:53:19.695+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:53:19.701+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:53:19.700+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:53:19.702+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:53:19.702+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:53:19.713+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:53:19.703+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:53:19.714+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:53:19.793+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.189 seconds
[2026-01-23T09:53:51.216+0000] {processor.py:161} INFO - Started process (PID=3410) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:53:51.219+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:53:51.224+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:53:51.223+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:53:51.297+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:53:51.296+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:53:51.299+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:53:51.298+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:53:51.300+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:53:51.300+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:53:51.307+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:53:51.307+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:53:51.312+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:53:51.312+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:53:51.317+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:53:51.317+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:53:51.318+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:53:51.318+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:53:51.330+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:53:51.319+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:53:51.331+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:53:51.410+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.208 seconds
[2026-01-23T09:54:21.754+0000] {processor.py:161} INFO - Started process (PID=3420) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:54:21.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:54:21.759+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:54:21.759+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:54:21.847+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:54:21.847+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:54:21.849+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:54:21.849+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:54:21.851+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:54:21.850+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:54:21.859+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:54:21.859+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:54:21.864+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:54:21.864+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:54:21.870+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:54:21.870+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:54:21.872+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:54:21.871+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:54:21.886+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:54:21.872+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:54:21.888+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:54:21.965+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.218 seconds
[2026-01-23T09:54:53.293+0000] {processor.py:161} INFO - Started process (PID=3430) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:54:53.295+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:54:53.301+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:54:53.301+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:54:53.400+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:54:53.400+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:54:53.402+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:54:53.402+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:54:53.404+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:54:53.403+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:54:53.411+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:54:53.410+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:54:53.416+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:54:53.416+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:54:53.422+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:54:53.421+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:54:53.423+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:54:53.423+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:54:53.442+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:54:53.424+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:54:53.444+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:54:53.556+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.271 seconds
[2026-01-23T09:55:24.353+0000] {processor.py:161} INFO - Started process (PID=3440) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:55:24.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:55:24.358+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:55:24.358+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:55:24.445+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:55:24.444+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:55:24.446+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:55:24.446+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:55:24.448+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:55:24.448+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:55:24.455+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:55:24.455+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:55:24.459+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:55:24.459+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:55:24.464+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:55:24.464+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:55:24.465+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:55:24.465+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:55:24.480+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:55:24.466+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:55:24.481+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:55:24.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.230 seconds
[2026-01-23T09:55:55.903+0000] {processor.py:161} INFO - Started process (PID=3450) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:55:55.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:55:55.910+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:55:55.910+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:55:55.974+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:55:55.973+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:55:55.975+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:55:55.975+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:55:55.976+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:55:55.976+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:55:55.982+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:55:55.982+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:55:55.987+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:55:55.987+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:55:55.992+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:55:55.991+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:55:55.993+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:55:55.992+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:55:56.004+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:55:55.993+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:55:56.006+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:55:56.087+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.191 seconds
[2026-01-23T09:56:26.404+0000] {processor.py:161} INFO - Started process (PID=3460) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:56:26.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:56:26.411+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:56:26.410+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:56:26.486+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:56:26.485+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:56:26.487+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:56:26.487+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:56:26.489+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:56:26.488+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:56:26.494+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:56:26.494+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:56:26.499+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:56:26.499+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:56:26.504+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:56:26.504+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:56:26.506+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:56:26.505+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:56:26.519+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:56:26.507+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:56:26.522+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:56:26.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.210 seconds
[2026-01-23T09:56:57.830+0000] {processor.py:161} INFO - Started process (PID=3470) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:56:57.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:56:57.837+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:56:57.836+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:56:57.902+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:56:57.901+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:56:57.903+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:56:57.903+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:56:57.905+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:56:57.904+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:56:57.912+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:56:57.911+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:56:57.917+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:56:57.916+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:56:57.922+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:56:57.922+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:56:57.923+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:56:57.923+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:56:57.935+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:56:57.923+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:56:57.936+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:56:58.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.189 seconds
[2026-01-23T09:57:28.845+0000] {processor.py:161} INFO - Started process (PID=3480) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:57:28.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:57:28.852+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:57:28.852+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:57:28.913+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:57:28.913+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:57:28.915+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:57:28.915+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:57:28.916+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:57:28.916+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:57:28.923+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:57:28.922+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:57:28.927+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:57:28.927+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:57:28.932+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:57:28.932+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:57:28.933+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:57:28.933+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:57:28.942+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:57:28.934+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:57:28.944+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:57:29.027+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.191 seconds
[2026-01-23T09:57:59.277+0000] {processor.py:161} INFO - Started process (PID=3490) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:57:59.279+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:57:59.283+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:57:59.283+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:57:59.409+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:57:59.408+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:57:59.412+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:57:59.411+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:57:59.415+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:57:59.414+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:57:59.424+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:57:59.423+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:57:59.429+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:57:59.429+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:57:59.436+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:57:59.435+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:57:59.437+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:57:59.437+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:57:59.455+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:57:59.438+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:57:59.457+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:57:59.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.303 seconds
[2026-01-23T09:58:30.492+0000] {processor.py:161} INFO - Started process (PID=3500) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:58:30.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:58:30.497+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:58:30.496+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:58:30.579+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:58:30.578+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:58:30.581+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:58:30.580+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:58:30.582+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:58:30.582+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:58:30.589+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:58:30.588+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:58:30.594+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:58:30.594+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:58:30.601+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:58:30.601+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:58:30.602+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:58:30.602+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:58:30.617+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:58:30.603+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:58:30.618+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:58:30.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.228 seconds
[2026-01-23T09:59:01.651+0000] {processor.py:161} INFO - Started process (PID=3510) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:59:01.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:59:01.658+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:59:01.657+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:59:01.749+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:59:01.749+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:59:01.751+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:59:01.750+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:59:01.752+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:59:01.752+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:59:01.760+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:59:01.760+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:59:01.765+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:59:01.765+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:59:01.771+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:59:01.771+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:59:01.772+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:59:01.772+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:59:01.786+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:59:01.773+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:59:01.787+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:59:01.884+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.240 seconds
[2026-01-23T09:59:32.370+0000] {processor.py:161} INFO - Started process (PID=3520) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:59:32.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T09:59:32.377+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:59:32.376+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:59:32.465+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:59:32.465+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T09:59:32.467+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:59:32.467+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T09:59:32.468+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:59:32.468+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T09:59:32.474+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:59:32.474+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:59:32.479+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:59:32.478+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:59:32.484+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:59:32.483+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T09:59:32.485+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:59:32.485+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T09:59:32.501+0000] {logging_mixin.py:188} INFO - [2026-01-23T09:59:32.486+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T09:59:32.503+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T09:59:32.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.233 seconds
[2026-01-23T10:00:03.349+0000] {processor.py:161} INFO - Started process (PID=3530) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:00:03.352+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:00:03.356+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:00:03.356+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:00:03.467+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:00:03.466+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:00:03.469+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:00:03.468+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:00:03.471+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:00:03.471+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:00:03.478+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:00:03.478+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:00:03.483+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:00:03.483+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:00:03.489+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:00:03.488+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:00:03.490+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:00:03.490+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:00:03.507+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:00:03.492+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:00:03.509+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:00:03.621+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.281 seconds
[2026-01-23T10:00:33.930+0000] {processor.py:161} INFO - Started process (PID=3540) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:00:33.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:00:33.936+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:00:33.936+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:00:34.025+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:00:34.025+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:00:34.028+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:00:34.027+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:00:34.029+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:00:34.029+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:00:34.036+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:00:34.036+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:00:34.041+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:00:34.041+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:00:34.047+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:00:34.046+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:00:34.048+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:00:34.048+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:00:34.065+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:00:34.049+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:00:34.066+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:00:34.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.252 seconds
[2026-01-23T10:01:05.721+0000] {processor.py:161} INFO - Started process (PID=3550) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:01:05.723+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:01:05.727+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:01:05.727+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:01:05.806+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:01:05.805+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:01:05.807+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:01:05.807+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:01:05.809+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:01:05.808+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:01:05.816+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:01:05.815+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:01:05.820+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:01:05.820+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:01:05.825+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:01:05.825+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:01:05.827+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:01:05.827+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:01:05.844+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:01:05.828+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:01:05.845+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:01:05.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.240 seconds
[2026-01-23T10:01:36.584+0000] {processor.py:161} INFO - Started process (PID=3560) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:01:36.587+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:01:36.590+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:01:36.589+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:01:36.661+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:01:36.660+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:01:36.662+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:01:36.662+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:01:36.663+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:01:36.663+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:01:36.670+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:01:36.670+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:01:36.676+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:01:36.675+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:01:36.681+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:01:36.680+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:01:36.682+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:01:36.682+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:01:36.758+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:01:36.682+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:01:36.770+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:01:37.218+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.643 seconds
[2026-01-23T10:02:08.254+0000] {processor.py:161} INFO - Started process (PID=3570) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:02:08.256+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:02:08.260+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:02:08.259+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:02:08.344+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:02:08.344+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:02:08.346+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:02:08.346+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:02:08.347+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:02:08.347+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:02:08.353+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:02:08.353+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:02:08.357+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:02:08.357+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:02:08.363+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:02:08.362+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:02:08.364+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:02:08.364+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:02:08.376+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:02:08.364+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:02:08.377+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:02:08.445+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.199 seconds
[2026-01-23T10:02:39.466+0000] {processor.py:161} INFO - Started process (PID=3580) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:02:39.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:02:39.471+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:02:39.471+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:02:39.535+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:02:39.534+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:02:39.569+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:02:39.568+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:02:39.607+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:02:39.607+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:02:39.617+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:02:39.616+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:02:39.627+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:02:39.626+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:02:39.638+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:02:39.637+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:02:39.639+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:02:39.639+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:02:39.651+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:02:39.640+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:02:39.652+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:02:39.728+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.270 seconds
[2026-01-23T10:03:10.415+0000] {processor.py:161} INFO - Started process (PID=3590) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:03:10.417+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:03:10.421+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:03:10.421+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:03:10.488+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:03:10.487+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:03:10.489+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:03:10.489+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:03:10.491+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:03:10.491+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:03:10.498+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:03:10.498+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:03:10.503+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:03:10.502+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:03:10.509+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:03:10.508+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:03:10.510+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:03:10.510+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:03:10.522+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:03:10.511+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:03:10.523+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:03:10.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.210 seconds
[2026-01-23T10:03:41.837+0000] {processor.py:161} INFO - Started process (PID=3600) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:03:41.839+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:03:41.843+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:03:41.842+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:03:41.928+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:03:41.928+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:03:41.930+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:03:41.929+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:03:41.931+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:03:41.931+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:03:41.938+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:03:41.938+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:03:41.944+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:03:41.943+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:03:41.949+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:03:41.949+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:03:41.950+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:03:41.950+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:03:41.963+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:03:41.951+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:03:41.965+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:03:42.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.224 seconds
[2026-01-23T10:04:13.200+0000] {processor.py:161} INFO - Started process (PID=3610) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:04:13.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:04:13.208+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:04:13.207+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:04:13.300+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:04:13.299+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:04:13.302+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:04:13.301+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:04:13.304+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:04:13.304+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:04:13.312+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:04:13.312+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:04:13.319+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:04:13.318+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:04:13.325+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:04:13.324+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:04:13.327+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:04:13.326+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:04:13.337+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:04:13.327+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:04:13.339+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:04:13.431+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.247 seconds
[2026-01-23T10:04:44.777+0000] {processor.py:161} INFO - Started process (PID=3620) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:04:44.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:04:44.783+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:04:44.782+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:04:44.871+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:04:44.870+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:04:44.872+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:04:44.872+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:04:44.873+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:04:44.873+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:04:44.879+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:04:44.879+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:04:44.883+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:04:44.883+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:04:44.888+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:04:44.888+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:04:44.889+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:04:44.889+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:04:44.903+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:04:44.890+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:04:44.904+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:04:44.987+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.219 seconds
[2026-01-23T10:05:15.251+0000] {processor.py:161} INFO - Started process (PID=3630) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:05:15.253+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:05:15.258+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:05:15.257+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:05:15.327+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:05:15.327+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:05:15.329+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:05:15.328+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:05:15.330+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:05:15.330+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:05:15.337+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:05:15.337+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:05:15.343+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:05:15.342+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:05:15.348+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:05:15.348+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:05:15.350+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:05:15.350+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:05:15.370+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:05:15.351+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:05:15.372+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:05:15.465+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.225 seconds
[2026-01-23T10:05:46.455+0000] {processor.py:161} INFO - Started process (PID=3640) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:05:46.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:05:46.460+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:05:46.459+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:05:46.531+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:05:46.530+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:05:46.532+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:05:46.532+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:05:46.534+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:05:46.533+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:05:46.541+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:05:46.541+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:05:46.546+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:05:46.546+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:05:46.553+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:05:46.552+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:05:46.555+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:05:46.554+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:05:46.565+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:05:46.555+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:05:46.567+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:05:46.640+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.193 seconds
[2026-01-23T10:12:51.172+0000] {processor.py:161} INFO - Started process (PID=3649) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:12:51.175+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:12:51.179+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:12:51.178+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:12:51.250+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:12:51.249+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:12:51.252+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:12:51.251+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:12:51.254+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:12:51.254+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:12:51.262+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:12:51.261+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:12:51.268+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:12:51.268+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:12:51.275+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:12:51.274+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:12:51.276+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:12:51.276+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:12:51.289+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:12:51.277+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:12:51.290+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:12:51.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.231 seconds
[2026-01-23T10:13:21.936+0000] {processor.py:161} INFO - Started process (PID=3659) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:13:21.938+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:13:21.941+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:13:21.941+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:13:22.023+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:13:22.023+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:13:22.024+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:13:22.024+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:13:22.025+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:13:22.025+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:13:22.034+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:13:22.033+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:13:22.039+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:13:22.039+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:13:22.044+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:13:22.044+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:13:22.046+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:13:22.045+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:13:22.060+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:13:22.047+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:13:22.061+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:13:22.143+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.214 seconds
[2026-01-23T10:13:53.200+0000] {processor.py:161} INFO - Started process (PID=3669) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:13:53.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:13:53.205+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:13:53.204+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:13:53.295+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:13:53.294+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:13:53.297+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:13:53.297+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:13:53.300+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:13:53.299+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:13:53.309+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:13:53.308+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:13:53.315+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:13:53.315+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:13:53.321+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:13:53.321+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:13:53.322+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:13:53.322+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:13:53.335+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:13:53.323+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:13:53.337+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:13:53.448+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.265 seconds
[2026-01-23T10:14:23.774+0000] {processor.py:161} INFO - Started process (PID=3679) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:14:23.776+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:14:23.779+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:14:23.778+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:14:23.875+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:14:23.874+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:14:23.877+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:14:23.876+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:14:23.878+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:14:23.878+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:14:23.887+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:14:23.887+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:14:23.894+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:14:23.893+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:14:23.900+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:14:23.899+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:14:23.901+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:14:23.901+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:14:23.916+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:14:23.902+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:14:23.917+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:14:24.026+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.260 seconds
[2026-01-23T10:14:55.442+0000] {processor.py:161} INFO - Started process (PID=3689) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:14:55.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:14:55.451+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:14:55.450+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:14:55.541+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:14:55.541+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:14:55.542+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:14:55.542+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:14:55.543+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:14:55.543+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:14:55.549+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:14:55.549+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:14:55.554+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:14:55.554+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:14:55.561+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:14:55.560+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:14:55.562+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:14:55.562+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:14:55.574+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:14:55.563+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:14:55.575+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:14:55.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.243 seconds
[2026-01-23T10:15:26.984+0000] {processor.py:161} INFO - Started process (PID=3699) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:15:26.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:15:26.989+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:15:26.989+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:15:27.070+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:15:27.069+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:15:27.071+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:15:27.071+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:15:27.073+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:15:27.072+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:15:27.079+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:15:27.079+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:15:27.084+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:15:27.083+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:15:27.089+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:15:27.089+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:15:27.091+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:15:27.090+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:15:27.106+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:15:27.092+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:15:27.107+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:15:27.194+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.218 seconds
[2026-01-23T10:15:57.434+0000] {processor.py:161} INFO - Started process (PID=3709) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:15:57.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:15:57.440+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:15:57.439+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:15:57.501+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:15:57.501+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:15:57.502+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:15:57.502+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:15:57.504+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:15:57.503+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:15:57.512+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:15:57.512+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:15:57.517+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:15:57.517+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:15:57.523+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:15:57.522+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:15:57.524+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:15:57.524+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:15:57.537+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:15:57.525+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:15:57.539+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:15:57.627+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.201 seconds
[2026-01-23T10:16:29.250+0000] {processor.py:161} INFO - Started process (PID=3719) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:16:29.253+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:16:29.256+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:16:29.256+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:16:29.327+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:16:29.326+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:16:29.328+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:16:29.328+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:16:29.329+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:16:29.329+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:16:29.336+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:16:29.335+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:16:29.340+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:16:29.340+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:16:29.344+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:16:29.344+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:16:29.345+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:16:29.345+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:16:29.355+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:16:29.346+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:16:29.356+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:16:29.426+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.183 seconds
[2026-01-23T10:17:00.597+0000] {processor.py:161} INFO - Started process (PID=3729) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:17:00.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:17:00.606+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:17:00.605+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:17:00.714+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:17:00.713+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:17:00.715+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:17:00.715+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:17:00.717+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:17:00.716+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:17:00.723+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:17:00.722+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:17:00.728+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:17:00.728+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:17:00.735+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:17:00.734+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:17:00.736+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:17:00.736+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:17:00.750+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:17:00.737+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:17:00.752+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:17:00.850+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.266 seconds
[2026-01-23T10:17:31.461+0000] {processor.py:161} INFO - Started process (PID=3739) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:17:31.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:17:31.468+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:17:31.467+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:17:31.560+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:17:31.559+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:17:31.563+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:17:31.562+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:17:31.565+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:17:31.565+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:17:31.574+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:17:31.573+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:17:31.580+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:17:31.579+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:17:31.586+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:17:31.586+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:17:31.588+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:17:31.588+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:17:31.606+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:17:31.589+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:17:31.608+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:17:31.703+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.250 seconds
[2026-01-23T10:18:01.925+0000] {processor.py:161} INFO - Started process (PID=3749) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:18:01.927+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:18:01.932+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:18:01.932+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:18:02.033+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:18:02.032+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:18:02.035+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:18:02.034+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:18:02.037+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:18:02.036+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:18:02.045+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:18:02.044+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:18:02.050+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:18:02.049+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:18:02.055+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:18:02.055+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:18:02.057+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:18:02.056+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:18:02.074+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:18:02.058+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:18:02.076+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:18:02.179+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.265 seconds
[2026-01-23T10:18:32.652+0000] {processor.py:161} INFO - Started process (PID=3759) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:18:32.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:18:32.659+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:18:32.659+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:18:32.758+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:18:32.758+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:18:32.759+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:18:32.759+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:18:32.761+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:18:32.760+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:18:32.767+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:18:32.767+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:18:32.771+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:18:32.771+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:18:32.776+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:18:32.776+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:18:32.777+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:18:32.777+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:18:32.790+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:18:32.777+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:18:32.791+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:18:32.870+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.230 seconds
[2026-01-23T10:19:03.505+0000] {processor.py:161} INFO - Started process (PID=3769) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:19:03.507+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:19:03.511+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:19:03.510+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:19:03.610+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:19:03.610+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:19:03.612+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:19:03.612+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:19:03.614+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:19:03.614+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:19:03.623+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:19:03.622+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:19:03.629+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:19:03.629+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:19:03.636+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:19:03.635+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:19:03.638+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:19:03.637+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:19:03.653+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:19:03.639+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:19:03.655+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:19:03.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.241 seconds
[2026-01-23T10:19:34.773+0000] {processor.py:161} INFO - Started process (PID=3779) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:19:34.776+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:19:34.780+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:19:34.779+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:19:34.871+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:19:34.870+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:19:34.872+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:19:34.872+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:19:34.874+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:19:34.873+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:19:34.880+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:19:34.880+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:19:34.885+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:19:34.885+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:19:34.890+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:19:34.890+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:19:34.892+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:19:34.891+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:19:34.903+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:19:34.892+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:19:34.905+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:19:34.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.222 seconds
[2026-01-23T10:20:06.229+0000] {processor.py:161} INFO - Started process (PID=3789) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:20:06.231+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:20:06.234+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:20:06.233+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:20:06.294+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:20:06.294+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:20:06.295+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:20:06.295+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:20:06.297+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:20:06.296+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:20:06.303+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:20:06.302+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:20:06.307+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:20:06.307+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:20:06.310+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:20:06.310+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:20:06.311+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:20:06.311+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:20:06.322+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:20:06.312+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:20:06.324+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:20:06.397+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.177 seconds
[2026-01-23T10:22:50.008+0000] {processor.py:161} INFO - Started process (PID=3799) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:22:50.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:22:50.018+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:22:50.017+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:22:50.100+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:22:50.099+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:22:50.101+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:22:50.101+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:22:50.104+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:22:50.104+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:22:50.117+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:22:50.116+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:22:50.130+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:22:50.129+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:22:50.137+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:22:50.137+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:22:50.138+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:22:50.138+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:22:50.149+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:22:50.139+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:22:50.151+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:22:50.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.234 seconds
[2026-01-23T10:23:21.887+0000] {processor.py:161} INFO - Started process (PID=3809) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:23:21.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:23:21.895+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:23:21.894+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:23:21.991+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:23:21.990+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:23:21.993+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:23:21.992+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:23:21.995+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:23:21.994+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:23:22.002+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:23:22.002+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:23:22.008+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:23:22.007+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:23:22.014+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:23:22.014+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:23:22.016+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:23:22.016+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:23:22.032+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:23:22.017+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:23:22.034+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:23:22.143+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.268 seconds
[2026-01-23T10:23:53.421+0000] {processor.py:161} INFO - Started process (PID=3819) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:23:53.423+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:23:53.426+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:23:53.426+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:23:53.488+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:23:53.488+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:23:53.490+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:23:53.489+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:23:53.491+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:23:53.491+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:23:53.497+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:23:53.496+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:23:53.501+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:23:53.501+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:23:53.506+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:23:53.505+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:23:53.507+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:23:53.507+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:23:53.521+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:23:53.508+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:23:53.523+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:23:53.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.216 seconds
[2026-01-23T10:24:24.639+0000] {processor.py:161} INFO - Started process (PID=3829) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:24:24.641+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:24:24.645+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:24:24.644+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:24:24.712+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:24:24.711+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:24:24.714+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:24:24.714+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:24:24.716+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:24:24.716+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:24:24.725+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:24:24.724+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:24:24.732+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:24:24.731+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:24:24.738+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:24:24.738+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:24:24.739+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:24:24.739+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:24:24.750+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:24:24.740+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:24:24.751+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:24:24.856+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.226 seconds
[2026-01-23T10:24:55.058+0000] {processor.py:161} INFO - Started process (PID=3839) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:24:55.061+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:24:55.065+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:24:55.064+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:24:55.165+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:24:55.164+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:24:55.166+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:24:55.166+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:24:55.167+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:24:55.167+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:24:55.174+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:24:55.173+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:24:55.179+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:24:55.178+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:24:55.183+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:24:55.183+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:24:55.185+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:24:55.185+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:24:55.198+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:24:55.186+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:24:55.199+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:24:55.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.245 seconds
[2026-01-23T10:25:26.097+0000] {processor.py:161} INFO - Started process (PID=3849) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:25:26.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:25:26.104+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:25:26.103+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:25:26.234+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:25:26.234+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:25:26.237+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:25:26.237+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:25:26.240+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:25:26.240+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:25:26.250+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:25:26.249+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:25:26.256+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:25:26.256+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:25:26.263+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:25:26.262+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:25:26.265+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:25:26.265+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:25:26.282+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:25:26.266+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:25:26.284+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:25:26.392+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.307 seconds
[2026-01-23T10:25:56.910+0000] {processor.py:161} INFO - Started process (PID=3859) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:25:56.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:25:56.917+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:25:56.917+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:25:57.034+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:25:57.034+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:25:57.036+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:25:57.036+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:25:57.038+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:25:57.037+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:25:57.045+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:25:57.044+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:25:57.050+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:25:57.050+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:25:57.055+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:25:57.055+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:25:57.056+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:25:57.056+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:25:57.071+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:25:57.057+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:25:57.073+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:25:57.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.250 seconds
[2026-01-23T10:26:28.005+0000] {processor.py:161} INFO - Started process (PID=3869) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:26:28.007+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:26:28.010+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:26:28.010+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:26:28.073+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:26:28.073+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:26:28.075+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:26:28.074+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:26:28.076+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:26:28.076+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:26:28.082+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:26:28.082+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:26:28.086+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:26:28.085+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:26:28.091+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:26:28.090+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:26:28.092+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:26:28.092+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:26:28.102+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:26:28.093+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:26:28.103+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:26:28.188+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.190 seconds
[2026-01-23T10:26:58.912+0000] {processor.py:161} INFO - Started process (PID=3879) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:26:58.914+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:26:58.918+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:26:58.918+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:26:59.001+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:26:59.001+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:26:59.002+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:26:59.002+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:26:59.003+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:26:59.003+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:26:59.011+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:26:59.010+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:26:59.016+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:26:59.016+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:26:59.022+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:26:59.022+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:26:59.023+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:26:59.023+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:26:59.040+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:26:59.024+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:26:59.042+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:26:59.134+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.231 seconds
[2026-01-23T10:27:30.179+0000] {processor.py:161} INFO - Started process (PID=3889) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:27:30.181+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:27:30.184+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:27:30.183+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:27:30.245+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:27:30.244+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:27:30.246+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:27:30.246+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:27:30.248+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:27:30.248+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:27:30.256+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:27:30.256+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:27:30.262+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:27:30.261+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:27:30.266+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:27:30.266+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:27:30.267+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:27:30.267+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:27:30.280+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:27:30.268+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:27:30.281+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:27:30.367+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.197 seconds
[2026-01-23T10:28:01.227+0000] {processor.py:161} INFO - Started process (PID=3899) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:28:01.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:28:01.232+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:28:01.231+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:28:01.295+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:28:01.295+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:28:01.297+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:28:01.296+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:28:01.298+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:28:01.298+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:28:01.304+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:28:01.303+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:28:01.308+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:28:01.308+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:28:01.314+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:28:01.314+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:28:01.317+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:28:01.317+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:28:01.329+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:28:01.318+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:28:01.330+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:28:01.405+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.189 seconds
[2026-01-23T10:28:32.267+0000] {processor.py:161} INFO - Started process (PID=3909) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:28:32.269+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:28:32.276+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:28:32.274+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:28:32.368+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:28:32.367+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:28:32.369+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:28:32.369+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:28:32.371+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:28:32.371+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:28:32.379+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:28:32.378+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:28:32.386+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:28:32.385+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:28:32.392+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:28:32.392+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:28:32.393+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:28:32.393+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:28:32.406+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:28:32.394+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:28:32.407+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:28:32.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.254 seconds
[2026-01-23T10:29:03.067+0000] {processor.py:161} INFO - Started process (PID=3919) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:29:03.069+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:29:03.072+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:29:03.072+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:29:03.150+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:29:03.149+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:29:03.151+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:29:03.151+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:29:03.152+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:29:03.152+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:29:03.160+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:29:03.159+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:29:03.165+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:29:03.164+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:29:03.171+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:29:03.170+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:29:03.172+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:29:03.171+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:29:03.182+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:29:03.173+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:29:03.183+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:29:03.262+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.203 seconds
[2026-01-23T10:29:33.954+0000] {processor.py:161} INFO - Started process (PID=3929) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:29:33.957+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:29:33.960+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:29:33.960+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:29:34.055+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:29:34.055+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:29:34.057+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:29:34.056+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:29:34.058+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:29:34.058+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:29:34.064+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:29:34.064+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:29:34.070+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:29:34.069+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:29:34.075+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:29:34.075+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:29:34.077+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:29:34.076+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:29:34.095+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:29:34.078+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:29:34.096+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:29:34.204+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.259 seconds
[2026-01-23T10:30:04.519+0000] {processor.py:161} INFO - Started process (PID=3939) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:30:04.522+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:30:04.525+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:30:04.525+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:30:04.599+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:30:04.599+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:30:04.601+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:30:04.600+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:30:04.602+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:30:04.602+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:30:04.608+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:30:04.607+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:30:04.612+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:30:04.612+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:30:04.618+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:30:04.617+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:30:04.619+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:30:04.619+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:30:04.629+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:30:04.620+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:30:04.631+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:30:04.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.205 seconds
[2026-01-23T10:30:36.068+0000] {processor.py:161} INFO - Started process (PID=3949) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:30:36.070+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:30:36.073+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:30:36.073+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:30:36.161+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:30:36.160+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:30:36.162+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:30:36.162+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:30:36.164+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:30:36.164+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:30:36.171+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:30:36.170+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:30:36.176+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:30:36.175+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:30:36.182+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:30:36.181+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:30:36.184+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:30:36.183+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:30:36.196+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:30:36.185+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:30:36.198+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:30:36.310+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.250 seconds
[2026-01-23T10:31:07.270+0000] {processor.py:161} INFO - Started process (PID=3959) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:31:07.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:31:07.277+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:31:07.277+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:31:07.344+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:31:07.343+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:31:07.346+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:31:07.345+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:31:07.348+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:31:07.347+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:31:07.355+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:31:07.354+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:31:07.361+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:31:07.360+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:31:07.367+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:31:07.366+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:31:07.368+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:31:07.368+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:31:07.381+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:31:07.369+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:31:07.382+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:31:07.464+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.204 seconds
[2026-01-23T10:31:37.873+0000] {processor.py:161} INFO - Started process (PID=3969) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:31:37.875+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:31:37.879+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:31:37.878+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:31:37.967+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:31:37.966+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:31:37.968+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:31:37.968+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:31:37.970+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:31:37.970+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:31:37.979+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:31:37.978+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:31:37.984+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:31:37.984+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:31:37.990+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:31:37.989+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:31:37.991+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:31:37.991+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:31:38.006+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:31:37.992+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:31:38.008+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:31:38.100+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.240 seconds
[2026-01-23T10:32:08.644+0000] {processor.py:161} INFO - Started process (PID=3979) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:32:08.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:32:08.659+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:32:08.658+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:32:08.731+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:32:08.730+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:32:08.732+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:32:08.732+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:32:08.735+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:32:08.734+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:32:08.742+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:32:08.742+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:32:08.747+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:32:08.747+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:32:08.752+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:32:08.751+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:32:08.753+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:32:08.753+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:32:08.763+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:32:08.754+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:32:08.765+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:32:08.838+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.206 seconds
[2026-01-23T10:32:39.880+0000] {processor.py:161} INFO - Started process (PID=3989) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:32:39.882+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:32:39.885+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:32:39.885+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:32:39.974+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:32:39.973+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:32:39.975+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:32:39.975+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:32:39.977+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:32:39.977+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:32:39.985+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:32:39.984+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:32:39.989+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:32:39.989+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:32:39.994+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:32:39.994+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:32:39.996+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:32:39.995+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:32:40.012+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:32:39.996+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:32:40.014+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:32:40.105+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.234 seconds
[2026-01-23T10:33:10.670+0000] {processor.py:161} INFO - Started process (PID=3999) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:33:10.673+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:33:10.678+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:33:10.676+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:33:10.776+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:33:10.775+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:33:10.778+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:33:10.777+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:33:10.779+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:33:10.779+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:33:10.787+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:33:10.786+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:33:10.792+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:33:10.792+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:33:10.798+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:33:10.797+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:33:10.799+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:33:10.799+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:33:10.817+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:33:10.800+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:33:10.819+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:33:10.916+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.259 seconds
[2026-01-23T10:33:41.176+0000] {processor.py:161} INFO - Started process (PID=4009) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:33:41.178+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:33:41.181+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:33:41.180+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:33:41.246+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:33:41.245+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:33:41.247+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:33:41.247+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:33:41.248+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:33:41.248+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:33:41.254+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:33:41.254+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:33:41.259+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:33:41.259+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:33:41.264+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:33:41.263+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:33:41.265+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:33:41.265+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:33:41.277+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:33:41.266+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:33:41.278+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:33:41.342+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.176 seconds
[2026-01-23T10:34:12.505+0000] {processor.py:161} INFO - Started process (PID=4019) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:34:12.507+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:34:12.510+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:34:12.509+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:34:12.587+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:34:12.586+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:34:12.588+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:34:12.588+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:34:12.590+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:34:12.590+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:34:12.596+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:34:12.596+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:34:12.601+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:34:12.601+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:34:12.607+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:34:12.606+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:34:12.608+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:34:12.608+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:34:12.620+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:34:12.609+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:34:12.621+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:34:12.703+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.206 seconds
[2026-01-23T10:34:43.251+0000] {processor.py:161} INFO - Started process (PID=4029) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:34:43.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:34:43.258+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:34:43.258+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:34:43.348+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:34:43.347+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:34:43.350+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:34:43.350+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:34:43.353+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:34:43.352+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:34:43.361+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:34:43.360+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:34:43.368+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:34:43.368+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:34:43.375+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:34:43.375+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:34:43.377+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:34:43.377+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:34:43.393+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:34:43.378+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:34:43.396+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:34:43.482+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.245 seconds
[2026-01-23T10:35:14.275+0000] {processor.py:161} INFO - Started process (PID=4039) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:35:14.279+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:35:14.285+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:35:14.284+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:35:14.386+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:35:14.385+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:35:14.390+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:35:14.389+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:35:14.392+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:35:14.392+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:35:14.402+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:35:14.401+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:35:14.406+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:35:14.406+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:35:14.411+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:35:14.411+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:35:14.413+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:35:14.413+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:35:14.425+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:35:14.414+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:35:14.427+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:35:14.502+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.244 seconds
[2026-01-23T10:35:45.311+0000] {processor.py:161} INFO - Started process (PID=4049) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:35:45.314+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:35:45.318+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:35:45.317+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:35:45.381+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:35:45.380+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:35:45.383+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:35:45.382+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:35:45.384+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:35:45.384+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:35:45.390+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:35:45.390+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:35:45.395+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:35:45.394+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:35:45.399+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:35:45.398+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:35:45.400+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:35:45.399+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:35:45.409+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:35:45.400+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:35:45.411+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:35:45.485+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.186 seconds
[2026-01-23T10:36:16.206+0000] {processor.py:161} INFO - Started process (PID=4059) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:36:16.208+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:36:16.212+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:36:16.211+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:36:16.305+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:36:16.305+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:36:16.307+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:36:16.307+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:36:16.309+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:36:16.308+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:36:16.316+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:36:16.315+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:36:16.322+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:36:16.321+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:36:16.327+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:36:16.326+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:36:16.328+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:36:16.328+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:36:16.346+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:36:16.329+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:36:16.348+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:36:16.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.284 seconds
[2026-01-23T10:36:48.083+0000] {processor.py:161} INFO - Started process (PID=4069) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:36:48.085+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:36:48.088+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:36:48.088+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:36:48.160+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:36:48.159+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:36:48.161+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:36:48.161+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:36:48.162+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:36:48.162+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:36:48.170+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:36:48.170+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:36:48.175+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:36:48.175+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:36:48.180+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:36:48.179+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:36:48.181+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:36:48.181+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:36:48.195+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:36:48.182+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:36:48.196+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:36:48.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.206 seconds
[2026-01-23T10:37:18.976+0000] {processor.py:161} INFO - Started process (PID=4079) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:37:18.979+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:37:18.984+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:37:18.983+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:37:19.085+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:37:19.084+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:37:19.087+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:37:19.087+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:37:19.090+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:37:19.089+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:37:19.098+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:37:19.098+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:37:19.103+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:37:19.103+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:37:19.110+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:37:19.109+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:37:19.111+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:37:19.111+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:37:19.133+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:37:19.113+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:37:19.135+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:37:19.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.285 seconds
[2026-01-23T10:37:49.964+0000] {processor.py:161} INFO - Started process (PID=4089) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:37:49.966+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:37:49.970+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:37:49.969+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:37:50.066+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:37:50.066+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:37:50.068+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:37:50.068+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:37:50.070+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:37:50.069+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:37:50.077+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:37:50.077+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:37:50.082+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:37:50.082+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:37:50.088+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:37:50.088+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:37:50.090+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:37:50.089+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:37:50.109+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:37:50.091+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:37:50.111+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:37:50.210+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.255 seconds
[2026-01-23T10:38:21.076+0000] {processor.py:161} INFO - Started process (PID=4099) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:38:21.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:38:21.082+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:38:21.081+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:38:21.179+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:38:21.179+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:38:21.182+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:38:21.181+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:38:21.184+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:38:21.184+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:38:21.193+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:38:21.192+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:38:21.199+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:38:21.198+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:38:21.206+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:38:21.206+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:38:21.208+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:38:21.208+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:38:21.233+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:38:21.210+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:38:21.235+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:38:21.348+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.281 seconds
[2026-01-23T10:38:52.365+0000] {processor.py:161} INFO - Started process (PID=4109) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:38:52.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:38:52.376+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:38:52.375+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:38:52.478+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:38:52.477+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:38:52.479+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:38:52.479+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:38:52.481+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:38:52.480+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:38:52.490+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:38:52.489+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:38:52.495+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:38:52.494+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:38:52.501+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:38:52.501+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:38:52.503+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:38:52.502+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:38:52.518+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:38:52.504+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:38:52.520+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:38:52.601+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.250 seconds
[2026-01-23T10:39:22.788+0000] {processor.py:161} INFO - Started process (PID=4119) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:39:22.790+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:39:22.792+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:39:22.792+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:39:22.878+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:39:22.878+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:39:22.880+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:39:22.879+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:39:22.881+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:39:22.881+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:39:22.886+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:39:22.886+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:39:22.890+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:39:22.890+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:39:22.895+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:39:22.895+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:39:22.897+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:39:22.897+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:39:22.911+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:39:22.897+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:39:22.913+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:39:23.005+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.225 seconds
[2026-01-23T10:39:53.976+0000] {processor.py:161} INFO - Started process (PID=4129) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:39:53.977+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:39:53.980+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:39:53.980+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:39:54.048+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:39:54.048+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:39:54.050+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:39:54.050+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:39:54.052+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:39:54.052+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:39:54.058+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:39:54.058+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:39:54.064+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:39:54.063+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:39:54.069+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:39:54.069+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:39:54.070+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:39:54.070+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:39:54.083+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:39:54.071+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:39:54.084+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:39:54.168+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.203 seconds
[2026-01-23T10:40:24.687+0000] {processor.py:161} INFO - Started process (PID=4139) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:40:24.689+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:40:24.695+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:40:24.695+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:40:24.785+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:40:24.784+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:40:24.786+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:40:24.786+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:40:24.787+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:40:24.787+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:40:24.794+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:40:24.794+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:40:24.800+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:40:24.799+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:40:24.806+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:40:24.805+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:40:24.807+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:40:24.807+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:40:24.823+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:40:24.808+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:40:24.824+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:40:24.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.246 seconds
[2026-01-23T10:40:56.523+0000] {processor.py:161} INFO - Started process (PID=4149) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:40:56.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:40:56.529+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:40:56.528+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:40:56.628+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:40:56.628+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:40:56.630+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:40:56.630+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:40:56.631+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:40:56.631+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:40:56.640+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:40:56.639+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:40:56.645+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:40:56.644+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:40:56.650+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:40:56.649+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:40:56.651+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:40:56.651+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:40:56.668+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:40:56.652+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:40:56.669+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:40:56.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.256 seconds
[2026-01-23T10:41:27.566+0000] {processor.py:161} INFO - Started process (PID=4159) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:41:27.569+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:41:27.572+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:41:27.571+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:41:27.676+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:41:27.675+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:41:27.677+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:41:27.677+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:41:27.679+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:41:27.679+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:41:27.687+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:41:27.687+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:41:27.692+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:41:27.691+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:41:27.698+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:41:27.698+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:41:27.700+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:41:27.700+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:41:27.716+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:41:27.701+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:41:27.718+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:41:27.822+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.265 seconds
[2026-01-23T10:41:58.415+0000] {processor.py:161} INFO - Started process (PID=4169) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:41:58.418+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:41:58.422+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:41:58.421+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:41:58.524+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:41:58.524+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:41:58.526+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:41:58.526+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:41:58.528+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:41:58.527+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:41:58.535+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:41:58.534+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:41:58.540+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:41:58.540+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:41:58.546+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:41:58.545+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:41:58.547+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:41:58.547+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:41:58.568+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:41:58.548+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:41:58.569+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:41:58.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.255 seconds
[2026-01-23T10:42:29.352+0000] {processor.py:161} INFO - Started process (PID=4179) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:42:29.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:42:29.359+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:42:29.358+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:42:29.432+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:42:29.431+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:42:29.433+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:42:29.433+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:42:29.434+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:42:29.434+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:42:29.441+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:42:29.441+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:42:29.447+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:42:29.446+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:42:29.451+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:42:29.451+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:42:29.452+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:42:29.452+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:42:29.464+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:42:29.453+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:42:29.465+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:42:29.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.203 seconds
[2026-01-23T10:43:00.487+0000] {processor.py:161} INFO - Started process (PID=4189) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:43:00.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:43:00.493+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:43:00.492+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:43:00.559+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:43:00.558+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:43:00.560+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:43:00.560+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:43:00.561+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:43:00.561+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:43:00.567+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:43:00.567+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:43:00.571+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:43:00.571+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:43:00.576+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:43:00.576+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:43:00.577+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:43:00.577+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:43:00.589+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:43:00.578+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:43:00.590+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:43:00.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.210 seconds
[2026-01-23T10:43:32.085+0000] {processor.py:161} INFO - Started process (PID=4199) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:43:32.088+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:43:32.095+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:43:32.093+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:43:32.177+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:43:32.176+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:43:32.179+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:43:32.179+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:43:32.181+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:43:32.181+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:43:32.189+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:43:32.188+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:43:32.195+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:43:32.194+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:43:32.201+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:43:32.200+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:43:32.202+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:43:32.202+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:43:32.214+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:43:32.203+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:43:32.217+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:43:32.299+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.230 seconds
[2026-01-23T10:44:03.673+0000] {processor.py:161} INFO - Started process (PID=4209) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:44:03.675+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:44:03.679+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:44:03.678+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:44:03.768+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:44:03.768+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:44:03.769+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:44:03.769+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:44:03.771+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:44:03.771+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:44:03.778+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:44:03.778+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:44:03.782+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:44:03.782+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:44:03.787+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:44:03.787+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:44:03.789+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:44:03.788+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:44:03.805+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:44:03.790+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:44:03.806+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:44:03.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.230 seconds
[2026-01-23T10:44:34.119+0000] {processor.py:161} INFO - Started process (PID=4219) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:44:34.121+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:44:34.124+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:44:34.123+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:44:34.225+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:44:34.224+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:44:34.227+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:44:34.227+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:44:34.229+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:44:34.229+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:44:34.238+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:44:34.237+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:44:34.244+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:44:34.243+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:44:34.249+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:44:34.248+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:44:34.250+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:44:34.250+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:44:34.263+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:44:34.252+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:44:34.265+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:44:34.364+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.254 seconds
[2026-01-23T10:45:05.181+0000] {processor.py:161} INFO - Started process (PID=4229) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:45:05.183+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:45:05.186+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:45:05.185+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:45:05.259+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:45:05.258+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:45:05.261+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:45:05.260+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:45:05.262+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:45:05.262+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:45:05.269+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:45:05.269+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:45:05.274+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:45:05.274+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:45:05.279+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:45:05.279+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:45:05.280+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:45:05.280+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:45:05.297+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:45:05.281+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:45:05.298+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:45:05.384+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.211 seconds
[2026-01-23T10:45:36.482+0000] {processor.py:161} INFO - Started process (PID=4239) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:45:36.484+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:45:36.487+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:45:36.487+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:45:36.559+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:45:36.559+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:45:36.561+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:45:36.561+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:45:36.563+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:45:36.562+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:45:36.570+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:45:36.570+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:45:36.575+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:45:36.574+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:45:36.580+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:45:36.579+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:45:36.581+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:45:36.581+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:45:36.595+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:45:36.582+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:45:36.596+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:45:36.683+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.209 seconds
[2026-01-23T10:46:07.508+0000] {processor.py:161} INFO - Started process (PID=4249) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:46:07.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:46:07.514+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:46:07.513+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:46:07.596+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:46:07.596+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:46:07.597+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:46:07.597+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:46:07.599+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:46:07.599+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:46:07.605+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:46:07.604+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:46:07.610+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:46:07.609+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:46:07.615+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:46:07.615+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:46:07.617+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:46:07.617+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:46:07.633+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:46:07.618+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:46:07.635+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:46:07.747+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.246 seconds
[2026-01-23T10:46:38.350+0000] {processor.py:161} INFO - Started process (PID=4260) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:46:38.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:46:38.357+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:46:38.356+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:46:38.451+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:46:38.450+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:46:38.452+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:46:38.452+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:46:38.454+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:46:38.454+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:46:38.462+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:46:38.461+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:46:38.467+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:46:38.466+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:46:38.473+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:46:38.473+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:46:38.475+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:46:38.475+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:46:38.491+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:46:38.476+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:46:38.493+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:46:38.581+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.240 seconds
[2026-01-23T10:47:09.924+0000] {processor.py:161} INFO - Started process (PID=4270) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:47:09.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:47:09.937+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:47:09.936+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:47:10.042+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:47:10.042+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:47:10.044+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:47:10.043+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:47:10.045+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:47:10.045+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:47:10.052+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:47:10.051+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:47:10.057+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:47:10.057+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:47:10.063+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:47:10.063+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:47:10.065+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:47:10.064+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:47:10.079+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:47:10.066+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:47:10.080+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:47:10.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.274 seconds
[2026-01-23T10:47:40.792+0000] {processor.py:161} INFO - Started process (PID=4280) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:47:40.794+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:47:40.797+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:47:40.797+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:47:40.881+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:47:40.880+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:47:40.882+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:47:40.882+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:47:40.883+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:47:40.883+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:47:40.889+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:47:40.889+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:47:40.894+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:47:40.894+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:47:40.898+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:47:40.898+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:47:40.899+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:47:40.899+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:47:40.912+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:47:40.901+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:47:40.913+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:47:41.002+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.219 seconds
[2026-01-23T10:48:11.861+0000] {processor.py:161} INFO - Started process (PID=4290) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:48:11.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:48:11.866+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:48:11.866+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:48:11.943+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:48:11.943+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:48:11.945+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:48:11.945+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:48:11.946+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:48:11.946+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:48:11.954+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:48:11.953+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:48:11.959+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:48:11.958+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:48:11.964+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:48:11.964+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:48:11.965+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:48:11.965+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:48:11.981+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:48:11.967+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:48:11.983+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:48:12.072+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.219 seconds
[2026-01-23T10:48:42.519+0000] {processor.py:161} INFO - Started process (PID=4300) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:48:42.522+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:48:42.525+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:48:42.525+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:48:42.631+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:48:42.631+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:48:42.633+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:48:42.632+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:48:42.635+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:48:42.634+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:48:42.642+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:48:42.642+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:48:42.647+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:48:42.646+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:48:42.651+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:48:42.650+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:48:42.652+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:48:42.652+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:48:42.668+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:48:42.653+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:48:42.670+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:48:42.752+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.241 seconds
[2026-01-23T10:49:13.850+0000] {processor.py:161} INFO - Started process (PID=4310) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:49:13.852+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:49:13.855+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:49:13.854+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:49:13.923+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:49:13.923+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:49:13.924+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:49:13.924+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:49:13.926+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:49:13.925+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:49:13.932+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:49:13.932+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:49:13.938+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:49:13.938+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:49:13.944+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:49:13.944+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:49:13.945+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:49:13.945+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:49:13.958+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:49:13.946+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:49:13.959+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:49:14.042+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.201 seconds
[2026-01-23T10:49:45.416+0000] {processor.py:161} INFO - Started process (PID=4320) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:49:45.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:49:45.427+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:49:45.426+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:49:45.536+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:49:45.535+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:49:45.538+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:49:45.537+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:49:45.540+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:49:45.539+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:49:45.547+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:49:45.546+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:49:45.553+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:49:45.553+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:49:45.558+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:49:45.558+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:49:45.559+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:49:45.559+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:49:45.575+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:49:45.561+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:49:45.577+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:49:45.741+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.342 seconds
[2026-01-23T10:50:16.048+0000] {processor.py:161} INFO - Started process (PID=4330) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:50:16.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T10:50:16.054+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:50:16.054+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:50:16.130+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:50:16.129+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T10:50:16.131+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:50:16.131+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T10:50:16.133+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:50:16.132+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T10:50:16.140+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:50:16.140+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:50:16.148+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:50:16.147+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:50:16.154+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:50:16.153+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T10:50:16.155+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:50:16.154+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T10:50:16.166+0000] {logging_mixin.py:188} INFO - [2026-01-23T10:50:16.155+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T10:50:16.167+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T10:50:16.262+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.225 seconds
[2026-01-23T11:58:37.069+0000] {processor.py:161} INFO - Started process (PID=4338) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T11:58:37.072+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T11:58:37.076+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:58:37.076+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T11:58:37.176+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:58:37.175+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T11:58:37.178+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:58:37.178+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T11:58:37.180+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:58:37.180+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T11:58:37.198+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:58:37.197+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T11:58:37.207+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:58:37.206+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T11:58:37.213+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:58:37.213+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T11:58:37.216+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:58:37.215+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T11:58:37.231+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:58:37.217+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T11:58:37.233+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T11:58:37.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.283 seconds
[2026-01-23T11:59:08.268+0000] {processor.py:161} INFO - Started process (PID=4348) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T11:59:08.270+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T11:59:08.274+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:59:08.273+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T11:59:08.339+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:59:08.338+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T11:59:08.340+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:59:08.340+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T11:59:08.341+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:59:08.341+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T11:59:08.348+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:59:08.347+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T11:59:08.354+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:59:08.353+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T11:59:08.360+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:59:08.359+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T11:59:08.361+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:59:08.361+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T11:59:08.374+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:59:08.363+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T11:59:08.376+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T11:59:08.459+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.200 seconds
[2026-01-23T11:59:39.381+0000] {processor.py:161} INFO - Started process (PID=4358) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T11:59:39.383+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T11:59:39.387+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:59:39.386+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T11:59:39.458+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:59:39.458+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T11:59:39.460+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:59:39.460+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T11:59:39.461+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:59:39.461+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T11:59:39.468+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:59:39.467+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T11:59:39.474+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:59:39.473+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T11:59:39.480+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:59:39.479+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T11:59:39.481+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:59:39.481+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T11:59:39.493+0000] {logging_mixin.py:188} INFO - [2026-01-23T11:59:39.481+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T11:59:39.495+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T11:59:39.572+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.200 seconds
[2026-01-23T12:00:09.857+0000] {processor.py:161} INFO - Started process (PID=4368) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:00:09.860+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:00:09.865+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:00:09.864+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:00:09.942+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:00:09.941+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:00:09.944+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:00:09.943+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:00:09.947+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:00:09.946+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:00:09.955+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:00:09.954+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:00:09.961+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:00:09.960+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:00:09.967+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:00:09.966+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:00:09.968+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:00:09.968+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:00:09.984+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:00:09.969+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:00:09.986+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:00:10.093+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.250 seconds
[2026-01-23T12:00:42.450+0000] {processor.py:161} INFO - Started process (PID=4378) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:00:42.452+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:00:42.458+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:00:42.458+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:00:42.530+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:00:42.529+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:00:42.532+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:00:42.531+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:00:42.533+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:00:42.533+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:00:42.541+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:00:42.541+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:00:42.546+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:00:42.546+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:00:42.551+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:00:42.550+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:00:42.553+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:00:42.552+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:00:42.568+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:00:42.554+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:00:42.569+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:00:42.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.215 seconds
[2026-01-23T12:01:14.196+0000] {processor.py:161} INFO - Started process (PID=4388) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:01:14.201+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:01:14.210+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:01:14.209+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:01:14.288+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:01:14.287+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:01:14.290+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:01:14.289+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:01:14.292+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:01:14.292+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:01:14.298+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:01:14.298+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:01:14.303+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:01:14.303+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:01:14.308+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:01:14.307+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:01:14.309+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:01:14.309+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:01:14.322+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:01:14.311+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:01:14.324+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:01:14.412+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.235 seconds
[2026-01-23T12:01:46.031+0000] {processor.py:161} INFO - Started process (PID=4398) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:01:46.033+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:01:46.038+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:01:46.036+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:01:46.185+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:01:46.185+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:01:46.188+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:01:46.187+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:01:46.192+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:01:46.192+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:01:46.199+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:01:46.198+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:01:46.210+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:01:46.209+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:01:46.215+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:01:46.214+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:01:46.216+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:01:46.216+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:01:46.235+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:01:46.217+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:01:46.238+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:01:46.454+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.434 seconds
[2026-01-23T12:02:19.416+0000] {processor.py:161} INFO - Started process (PID=4426) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:02:19.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:02:19.425+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:02:19.424+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:02:19.556+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:02:19.555+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:02:19.558+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:02:19.557+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:02:19.561+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:02:19.560+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:02:19.568+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:02:19.567+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:02:19.574+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:02:19.574+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:02:19.586+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:02:19.585+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:02:19.587+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:02:19.586+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:02:19.602+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:02:19.588+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:02:19.604+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:02:19.758+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.351 seconds
[2026-01-23T12:02:50.063+0000] {processor.py:161} INFO - Started process (PID=4436) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:02:50.066+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:02:50.072+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:02:50.071+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:02:50.166+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:02:50.165+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:02:50.167+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:02:50.167+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:02:50.169+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:02:50.169+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:02:50.177+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:02:50.176+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:02:50.182+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:02:50.182+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:02:50.187+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:02:50.186+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:02:50.188+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:02:50.188+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:02:50.200+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:02:50.189+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:02:50.202+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:02:50.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.245 seconds
[2026-01-23T12:03:21.774+0000] {processor.py:161} INFO - Started process (PID=4446) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:03:21.776+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:03:21.780+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:03:21.779+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:03:21.863+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:03:21.862+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:03:21.864+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:03:21.864+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:03:21.865+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:03:21.865+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:03:21.872+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:03:21.872+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:03:21.879+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:03:21.879+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:03:21.884+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:03:21.884+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:03:21.886+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:03:21.885+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:03:21.900+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:03:21.887+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:03:21.902+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:03:21.982+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.219 seconds
[2026-01-23T12:03:52.600+0000] {processor.py:161} INFO - Started process (PID=4456) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:03:52.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:03:52.606+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:03:52.605+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:03:52.677+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:03:52.677+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:03:52.679+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:03:52.679+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:03:52.681+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:03:52.680+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:03:52.688+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:03:52.688+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:03:52.694+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:03:52.694+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:03:52.699+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:03:52.699+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:03:52.700+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:03:52.700+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:03:52.718+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:03:52.701+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:03:52.719+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:03:52.815+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.223 seconds
[2026-01-23T12:04:24.448+0000] {processor.py:161} INFO - Started process (PID=4466) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:04:24.451+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:04:24.455+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:04:24.455+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:04:24.534+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:04:24.534+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:04:24.536+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:04:24.535+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:04:24.537+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:04:24.537+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:04:24.543+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:04:24.543+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:04:24.548+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:04:24.548+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:04:24.553+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:04:24.553+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:04:24.555+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:04:24.555+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:04:24.570+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:04:24.556+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:04:24.573+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:04:24.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.220 seconds
[2026-01-23T12:04:55.106+0000] {processor.py:161} INFO - Started process (PID=4476) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:04:55.108+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:04:55.111+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:04:55.111+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:04:55.174+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:04:55.173+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:04:55.175+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:04:55.175+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:04:55.176+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:04:55.176+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:04:55.183+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:04:55.182+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:04:55.188+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:04:55.188+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:04:55.192+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:04:55.191+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:04:55.193+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:04:55.193+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:04:55.203+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:04:55.194+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:04:55.204+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:04:55.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.179 seconds
[2026-01-23T12:05:25.795+0000] {processor.py:161} INFO - Started process (PID=4486) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:05:25.798+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:05:25.803+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:05:25.802+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:05:25.882+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:05:25.882+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:05:25.884+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:05:25.883+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:05:25.885+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:05:25.885+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:05:25.892+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:05:25.891+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:05:25.897+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:05:25.897+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:05:25.903+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:05:25.902+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:05:25.904+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:05:25.904+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:05:25.915+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:05:25.905+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:05:25.916+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:05:25.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.216 seconds
[2026-01-23T12:05:56.479+0000] {processor.py:161} INFO - Started process (PID=4496) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:05:56.481+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:05:56.484+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:05:56.484+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:05:56.566+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:05:56.566+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:05:56.568+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:05:56.568+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:05:56.570+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:05:56.569+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:05:56.575+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:05:56.574+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:05:56.579+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:05:56.579+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:05:56.584+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:05:56.584+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:05:56.585+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:05:56.585+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:05:56.600+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:05:56.586+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:05:56.602+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:05:56.686+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.215 seconds
[2026-01-23T12:06:27.336+0000] {processor.py:161} INFO - Started process (PID=4506) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:06:27.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:06:27.343+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:06:27.343+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:06:27.409+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:06:27.409+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:06:27.411+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:06:27.410+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:06:27.412+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:06:27.412+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:06:27.419+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:06:27.419+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:06:27.425+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:06:27.425+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:06:27.431+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:06:27.431+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:06:27.433+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:06:27.433+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:06:27.445+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:06:27.434+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:06:27.446+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:06:27.525+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.199 seconds
[2026-01-23T12:06:57.914+0000] {processor.py:161} INFO - Started process (PID=4516) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:06:57.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:06:57.922+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:06:57.920+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:06:57.977+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:06:57.977+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:06:57.978+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:06:57.978+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:06:57.979+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:06:57.979+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:06:57.985+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:06:57.985+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:06:57.989+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:06:57.989+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:06:57.993+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:06:57.993+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:06:57.994+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:06:57.994+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:06:58.004+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:06:57.995+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:06:58.005+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:06:58.070+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.163 seconds
[2026-01-23T12:07:30.228+0000] {processor.py:161} INFO - Started process (PID=4526) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:07:30.238+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:07:30.246+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:07:30.245+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:07:30.360+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:07:30.358+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:07:30.362+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:07:30.361+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:07:30.364+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:07:30.363+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:07:30.372+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:07:30.371+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:07:30.380+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:07:30.379+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:07:30.386+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:07:30.385+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:07:30.387+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:07:30.387+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:07:30.408+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:07:30.389+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:07:30.415+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:07:30.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.347 seconds
[2026-01-23T12:08:00.995+0000] {processor.py:161} INFO - Started process (PID=4536) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:08:00.997+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:08:01.002+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:08:01.001+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:08:01.069+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:08:01.068+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:08:01.070+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:08:01.069+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:08:01.071+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:08:01.071+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:08:01.078+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:08:01.078+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:08:01.082+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:08:01.082+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:08:01.086+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:08:01.086+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:08:01.087+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:08:01.087+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:08:01.096+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:08:01.088+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:08:01.097+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:08:01.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.172 seconds
[2026-01-23T12:08:31.776+0000] {processor.py:161} INFO - Started process (PID=4546) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:08:31.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:08:31.786+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:08:31.784+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:08:31.856+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:08:31.856+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:08:31.857+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:08:31.857+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:08:31.858+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:08:31.858+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:08:31.863+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:08:31.863+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:08:31.867+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:08:31.867+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:08:31.872+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:08:31.871+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:08:31.873+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:08:31.873+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:08:31.884+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:08:31.873+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:08:31.886+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:08:31.964+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.198 seconds
[2026-01-23T12:09:03.681+0000] {processor.py:161} INFO - Started process (PID=4556) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:09:03.684+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:09:03.689+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:09:03.688+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:09:03.762+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:09:03.762+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:09:03.764+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:09:03.764+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:09:03.765+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:09:03.765+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:09:03.772+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:09:03.772+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:09:03.777+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:09:03.777+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:09:03.782+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:09:03.782+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:09:03.783+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:09:03.783+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:09:03.793+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:09:03.784+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:09:03.794+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:09:03.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.187 seconds
[2026-01-23T12:09:35.123+0000] {processor.py:161} INFO - Started process (PID=4566) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:09:35.126+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:09:35.132+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:09:35.131+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:09:35.197+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:09:35.197+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:09:35.198+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:09:35.198+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:09:35.200+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:09:35.200+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:09:35.209+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:09:35.209+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:09:35.213+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:09:35.213+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:09:35.219+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:09:35.218+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:09:35.220+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:09:35.220+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:09:35.230+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:09:35.221+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:09:35.231+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:09:35.307+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.200 seconds
[2026-01-23T12:10:05.596+0000] {processor.py:161} INFO - Started process (PID=4576) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:10:05.598+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:10:05.602+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:10:05.601+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:10:05.675+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:10:05.674+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:10:05.676+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:10:05.676+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:10:05.677+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:10:05.677+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:10:05.684+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:10:05.684+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:10:05.689+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:10:05.689+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:10:05.693+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:10:05.693+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:10:05.694+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:10:05.694+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:10:05.707+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:10:05.695+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:10:05.708+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:10:05.784+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.195 seconds
[2026-01-23T12:10:36.136+0000] {processor.py:161} INFO - Started process (PID=4586) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:10:36.138+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:10:36.143+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:10:36.142+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:10:36.201+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:10:36.201+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:10:36.203+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:10:36.203+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:10:36.204+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:10:36.204+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:10:36.211+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:10:36.211+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:10:36.217+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:10:36.217+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:10:36.224+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:10:36.223+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:10:36.225+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:10:36.225+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:10:36.236+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:10:36.226+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:10:36.238+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:10:36.308+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.180 seconds
[2026-01-23T12:11:20.052+0000] {processor.py:161} INFO - Started process (PID=4613) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:11:20.054+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:11:20.058+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:11:20.057+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:11:20.147+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:11:20.146+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:11:20.148+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:11:20.148+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:11:20.149+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:11:20.149+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:11:20.156+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:11:20.156+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:11:20.162+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:11:20.161+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:11:20.168+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:11:20.168+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:11:20.169+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:11:20.169+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:11:20.180+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:11:20.170+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:11:20.182+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:11:20.253+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.209 seconds
[2026-01-23T12:11:50.882+0000] {processor.py:161} INFO - Started process (PID=4624) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:11:50.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:11:50.888+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:11:50.887+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:11:50.959+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:11:50.958+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:11:50.961+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:11:50.961+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:11:50.963+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:11:50.963+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:11:50.969+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:11:50.969+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:11:50.973+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:11:50.973+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:11:50.979+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:11:50.979+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:11:50.981+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:11:50.980+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:11:50.992+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:11:50.981+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:11:50.993+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:11:51.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.241 seconds
[2026-01-23T12:12:21.612+0000] {processor.py:161} INFO - Started process (PID=4634) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:12:21.616+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:12:21.621+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:12:21.621+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:12:21.703+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:12:21.703+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:12:21.705+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:12:21.705+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:12:21.707+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:12:21.707+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:12:21.715+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:12:21.715+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:12:21.721+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:12:21.721+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:12:21.727+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:12:21.726+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:12:21.729+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:12:21.728+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:12:21.739+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:12:21.730+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:12:21.741+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:12:21.807+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.204 seconds
[2026-01-23T12:12:52.269+0000] {processor.py:161} INFO - Started process (PID=4644) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:12:52.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:12:52.276+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:12:52.275+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:12:52.343+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:12:52.343+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:12:52.344+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:12:52.344+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:12:52.347+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:12:52.346+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:12:52.353+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:12:52.352+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:12:52.358+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:12:52.357+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:12:52.362+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:12:52.362+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:12:52.364+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:12:52.363+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:12:52.375+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:12:52.364+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:12:52.376+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:12:52.450+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.189 seconds
[2026-01-23T12:13:23.295+0000] {processor.py:161} INFO - Started process (PID=4654) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:13:23.298+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:13:23.303+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:13:23.302+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:13:23.382+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:13:23.382+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:13:23.383+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:13:23.383+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:13:23.384+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:13:23.384+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:13:23.392+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:13:23.391+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:13:23.396+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:13:23.396+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:13:23.401+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:13:23.400+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:13:23.402+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:13:23.402+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:13:23.411+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:13:23.402+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:13:23.413+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:13:23.486+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.204 seconds
[2026-01-23T12:13:54.090+0000] {processor.py:161} INFO - Started process (PID=4664) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:13:54.093+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:13:54.097+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:13:54.096+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:13:54.171+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:13:54.170+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:13:54.172+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:13:54.171+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:13:54.173+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:13:54.173+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:13:54.179+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:13:54.179+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:13:54.182+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:13:54.182+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:13:54.186+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:13:54.186+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:13:54.187+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:13:54.187+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:13:54.196+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:13:54.187+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:13:54.198+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:13:54.259+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.185 seconds
[2026-01-23T12:14:29.776+0000] {processor.py:161} INFO - Started process (PID=4691) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:14:29.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:14:29.782+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:14:29.782+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:14:29.870+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:14:29.869+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:14:29.871+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:14:29.871+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:14:29.873+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:14:29.872+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:14:29.879+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:14:29.878+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:14:29.883+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:14:29.883+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:14:29.888+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:14:29.888+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:14:29.890+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:14:29.889+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:14:29.903+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:14:29.891+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:14:29.905+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:14:29.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.223 seconds
[2026-01-23T12:15:00.218+0000] {processor.py:161} INFO - Started process (PID=4701) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:15:00.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:15:00.224+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:15:00.224+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:15:00.286+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:15:00.286+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:15:00.288+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:15:00.287+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:15:00.289+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:15:00.288+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:15:00.296+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:15:00.296+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:15:00.302+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:15:00.302+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:15:00.309+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:15:00.308+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:15:00.310+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:15:00.310+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:15:00.323+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:15:00.311+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:15:00.325+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:15:00.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.199 seconds
[2026-01-23T12:15:31.054+0000] {processor.py:161} INFO - Started process (PID=4711) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:15:31.056+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:15:31.060+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:15:31.060+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:15:31.126+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:15:31.126+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:15:31.127+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:15:31.127+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:15:31.129+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:15:31.128+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:15:31.135+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:15:31.134+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:15:31.139+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:15:31.139+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:15:31.143+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:15:31.143+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:15:31.144+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:15:31.144+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:15:31.154+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:15:31.145+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:15:31.155+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:15:31.226+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.182 seconds
[2026-01-23T12:16:01.917+0000] {processor.py:161} INFO - Started process (PID=4721) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:16:01.919+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:16:01.923+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:16:01.922+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:16:01.985+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:16:01.985+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:16:01.986+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:16:01.986+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:16:01.987+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:16:01.987+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:16:01.994+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:16:01.993+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:16:01.999+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:16:01.998+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:16:02.003+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:16:02.002+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:16:02.004+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:16:02.003+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:16:02.015+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:16:02.004+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:16:02.016+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:16:02.086+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.177 seconds
[2026-01-23T12:16:33.576+0000] {processor.py:161} INFO - Started process (PID=4731) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:16:33.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:16:33.584+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:16:33.581+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:16:33.659+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:16:33.658+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:16:33.661+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:16:33.660+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:16:33.662+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:16:33.662+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:16:33.668+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:16:33.667+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:16:33.677+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:16:33.676+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:16:33.681+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:16:33.681+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:16:33.683+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:16:33.682+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:16:33.694+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:16:33.684+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:16:33.695+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:16:33.763+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.198 seconds
[2026-01-23T12:17:04.164+0000] {processor.py:161} INFO - Started process (PID=4741) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:17:04.167+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:17:04.170+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:17:04.170+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:17:04.236+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:17:04.235+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:17:04.237+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:17:04.237+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:17:04.238+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:17:04.238+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:17:04.245+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:17:04.245+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:17:04.249+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:17:04.248+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:17:04.253+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:17:04.253+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:17:04.254+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:17:04.254+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:17:04.265+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:17:04.255+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:17:04.266+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:17:04.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.176 seconds
[2026-01-23T12:17:34.583+0000] {processor.py:161} INFO - Started process (PID=4751) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:17:34.586+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:17:34.592+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:17:34.591+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:17:34.681+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:17:34.680+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:17:34.682+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:17:34.682+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:17:34.684+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:17:34.684+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:17:34.689+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:17:34.689+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:17:34.693+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:17:34.693+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:17:34.697+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:17:34.697+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:17:34.699+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:17:34.698+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:17:34.712+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:17:34.700+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:17:34.713+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:17:34.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.225 seconds
[2026-01-23T12:18:05.077+0000] {processor.py:161} INFO - Started process (PID=4761) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:18:05.080+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T12:18:05.083+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:18:05.082+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:18:05.160+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:18:05.160+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T12:18:05.162+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:18:05.161+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T12:18:05.163+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:18:05.163+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T12:18:05.169+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:18:05.169+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:18:05.174+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:18:05.173+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:18:05.178+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:18:05.177+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T12:18:05.179+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:18:05.179+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T12:18:05.191+0000] {logging_mixin.py:188} INFO - [2026-01-23T12:18:05.180+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T12:18:05.193+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T12:18:05.269+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.199 seconds
[2026-01-23T14:13:51.278+0000] {processor.py:161} INFO - Started process (PID=4771) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:13:51.286+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:13:51.303+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:13:51.301+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:13:51.574+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:13:51.573+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:13:51.581+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:13:51.580+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:13:51.587+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:13:51.587+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:13:51.604+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:13:51.603+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:13:51.616+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:13:51.616+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:13:51.627+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:13:51.627+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:13:51.630+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:13:51.629+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:13:51.656+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:13:51.631+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:13:51.662+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:13:51.847+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.610 seconds
[2026-01-23T14:14:22.478+0000] {processor.py:161} INFO - Started process (PID=4781) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:14:22.482+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:14:22.487+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:14:22.486+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:14:22.590+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:14:22.590+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:14:22.593+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:14:22.592+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:14:22.595+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:14:22.595+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:14:22.604+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:14:22.603+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:14:22.610+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:14:22.610+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:14:22.618+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:14:22.617+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:14:22.620+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:14:22.619+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:14:22.637+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:14:22.621+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:14:22.639+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:14:22.744+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.283 seconds
[2026-01-23T14:14:53.050+0000] {processor.py:161} INFO - Started process (PID=4791) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:14:53.054+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:14:53.062+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:14:53.061+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:14:53.185+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:14:53.184+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:14:53.187+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:14:53.187+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:14:53.189+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:14:53.189+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:14:53.200+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:14:53.199+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:14:53.206+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:14:53.206+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:14:53.212+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:14:53.211+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:14:53.214+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:14:53.213+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:14:53.231+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:14:53.215+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:14:53.233+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:14:53.355+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.325 seconds
[2026-01-23T14:15:24.637+0000] {processor.py:161} INFO - Started process (PID=4801) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:15:24.641+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:15:24.648+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:15:24.647+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:15:24.769+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:15:24.768+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:15:24.772+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:15:24.771+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:15:24.774+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:15:24.774+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:15:24.785+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:15:24.784+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:15:24.792+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:15:24.791+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:15:24.799+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:15:24.798+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:15:24.800+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:15:24.800+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:15:24.822+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:15:24.802+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:15:24.824+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:15:24.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.331 seconds
[2026-01-23T14:15:55.257+0000] {processor.py:161} INFO - Started process (PID=4811) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:15:55.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:15:55.266+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:15:55.265+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:15:55.378+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:15:55.377+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:15:55.380+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:15:55.380+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:15:55.383+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:15:55.382+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:15:55.392+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:15:55.392+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:15:55.399+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:15:55.398+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:15:55.406+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:15:55.405+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:15:55.408+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:15:55.407+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:15:55.429+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:15:55.409+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:15:55.431+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:15:55.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.299 seconds
[2026-01-23T14:16:26.712+0000] {processor.py:161} INFO - Started process (PID=4821) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:16:26.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:16:26.722+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:16:26.721+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:16:26.855+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:16:26.854+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:16:26.858+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:16:26.857+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:16:26.860+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:16:26.860+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:16:26.870+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:16:26.869+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:16:26.877+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:16:26.876+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:16:26.884+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:16:26.883+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:16:26.886+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:16:26.885+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:16:26.906+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:16:26.887+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:16:26.908+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:16:27.021+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.326 seconds
[2026-01-23T14:16:57.397+0000] {processor.py:161} INFO - Started process (PID=4831) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:16:57.401+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:16:57.409+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:16:57.408+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:16:57.548+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:16:57.547+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:16:57.550+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:16:57.550+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:16:57.553+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:16:57.552+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:16:57.563+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:16:57.563+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:16:57.572+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:16:57.572+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:16:57.579+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:16:57.578+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:16:57.581+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:16:57.580+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:16:57.605+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:16:57.582+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:16:57.607+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:16:57.745+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.365 seconds
[2026-01-23T14:42:55.456+0000] {processor.py:161} INFO - Started process (PID=4837) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:42:55.466+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:42:55.477+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:42:55.475+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:42:55.672+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:42:55.671+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:42:55.680+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:42:55.677+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:42:55.683+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:42:55.682+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:42:55.694+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:42:55.693+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:42:55.704+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:42:55.703+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:42:55.717+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:42:55.716+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:42:55.722+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:42:55.722+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:42:55.749+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:42:55.725+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:42:55.755+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:42:55.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.545 seconds
[2026-01-23T14:43:26.417+0000] {processor.py:161} INFO - Started process (PID=4847) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:43:26.422+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:43:26.431+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:43:26.429+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:43:26.562+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:43:26.561+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:43:26.566+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:43:26.565+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:43:26.569+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:43:26.568+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:43:26.580+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:43:26.579+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:43:26.588+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:43:26.587+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:43:26.597+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:43:26.596+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:43:26.599+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:43:26.598+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:43:26.618+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:43:26.600+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:43:26.620+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:43:26.743+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.351 seconds
[2026-01-23T14:43:57.485+0000] {processor.py:161} INFO - Started process (PID=4857) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:43:57.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:43:57.497+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:43:57.496+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:43:57.603+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:43:57.603+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:43:57.605+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:43:57.605+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:43:57.608+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:43:57.607+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:43:57.617+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:43:57.617+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:43:57.625+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:43:57.624+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:43:57.632+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:43:57.631+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:43:57.634+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:43:57.633+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:43:57.651+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:43:57.636+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:43:57.653+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:43:57.761+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.303 seconds
[2026-01-23T14:44:29.120+0000] {processor.py:161} INFO - Started process (PID=4867) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:44:29.124+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:44:29.130+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:44:29.129+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:44:29.245+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:44:29.244+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:44:29.247+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:44:29.247+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:44:29.250+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:44:29.250+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:44:29.260+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:44:29.259+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:44:29.266+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:44:29.266+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:44:29.273+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:44:29.272+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:44:29.275+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:44:29.274+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:44:29.298+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:44:29.276+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:44:29.301+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:44:29.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.328 seconds
[2026-01-23T14:45:00.495+0000] {processor.py:161} INFO - Started process (PID=4877) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:45:00.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:45:00.507+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:45:00.506+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:45:00.624+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:45:00.623+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:45:00.627+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:45:00.627+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:45:00.630+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:45:00.629+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:45:00.640+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:45:00.639+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:45:00.649+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:45:00.649+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:45:00.656+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:45:00.655+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:45:00.659+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:45:00.659+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:45:00.680+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:45:00.661+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:45:00.682+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:45:00.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.351 seconds
[2026-01-23T14:45:31.697+0000] {processor.py:161} INFO - Started process (PID=4887) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:45:31.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:45:31.707+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:45:31.706+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:45:31.841+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:45:31.839+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:45:31.844+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:45:31.843+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:45:31.847+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:45:31.846+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:45:31.861+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:45:31.860+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:45:31.868+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:45:31.867+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:45:31.878+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:45:31.877+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:45:31.880+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:45:31.879+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:45:31.902+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:45:31.881+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:45:31.904+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:45:32.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.359 seconds
[2026-01-23T14:46:03.369+0000] {processor.py:161} INFO - Started process (PID=4897) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:46:03.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:46:03.381+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:46:03.379+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:46:03.488+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:46:03.487+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:46:03.490+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:46:03.489+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:46:03.493+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:46:03.492+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:46:03.504+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:46:03.503+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:46:03.512+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:46:03.511+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:46:03.518+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:46:03.518+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:46:03.520+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:46:03.520+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:46:03.541+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:46:03.522+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:46:03.543+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:46:03.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.363 seconds
[2026-01-23T14:46:34.623+0000] {processor.py:161} INFO - Started process (PID=4907) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:46:34.626+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:46:34.632+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:46:34.631+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:46:34.732+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:46:34.731+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:46:34.735+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:46:34.734+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:46:34.738+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:46:34.737+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:46:34.746+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:46:34.746+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:46:34.754+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:46:34.752+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:46:34.762+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:46:34.761+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:46:34.763+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:46:34.763+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:46:34.780+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:46:34.765+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:46:34.782+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:46:34.884+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.282 seconds
[2026-01-23T14:47:06.056+0000] {processor.py:161} INFO - Started process (PID=4917) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:47:06.060+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:47:06.070+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:47:06.069+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:47:06.183+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:47:06.181+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:47:06.185+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:47:06.184+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:47:06.188+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:47:06.187+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:47:06.199+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:47:06.198+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:47:06.209+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:47:06.208+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:47:06.217+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:47:06.216+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:47:06.220+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:47:06.219+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:47:06.243+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:47:06.223+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:47:06.245+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:47:06.381+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.346 seconds
[2026-01-23T14:47:37.367+0000] {processor.py:161} INFO - Started process (PID=4927) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:47:37.372+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:47:37.378+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:47:37.377+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:47:37.496+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:47:37.495+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:47:37.498+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:47:37.498+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:47:37.500+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:47:37.500+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:47:37.509+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:47:37.509+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:47:37.516+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:47:37.515+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:47:37.522+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:47:37.521+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:47:37.523+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:47:37.523+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:47:37.538+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:47:37.524+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:47:37.540+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:47:37.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.294 seconds
[2026-01-23T14:48:09.225+0000] {processor.py:161} INFO - Started process (PID=4937) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:48:09.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:48:09.237+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:48:09.234+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:48:09.364+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:48:09.363+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:48:09.367+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:48:09.366+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:48:09.370+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:48:09.369+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:48:09.381+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:48:09.379+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:48:09.388+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:48:09.388+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:48:09.396+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:48:09.395+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:48:09.398+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:48:09.397+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:48:09.417+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:48:09.399+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:48:09.419+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:48:09.531+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.326 seconds
[2026-01-23T14:48:40.319+0000] {processor.py:161} INFO - Started process (PID=4947) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:48:40.323+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:48:40.329+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:48:40.328+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:48:40.435+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:48:40.435+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:48:40.438+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:48:40.437+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:48:40.441+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:48:40.440+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:48:40.450+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:48:40.450+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:48:40.459+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:48:40.458+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:48:40.474+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:48:40.474+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:48:40.476+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:48:40.476+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:48:40.493+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:48:40.477+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:48:40.495+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:48:40.605+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.303 seconds
[2026-01-23T14:49:11.568+0000] {processor.py:161} INFO - Started process (PID=4957) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:49:11.572+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:49:11.579+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:49:11.578+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:49:11.714+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:49:11.713+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:49:11.717+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:49:11.716+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:49:11.719+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:49:11.719+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:49:11.731+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:49:11.730+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:49:11.737+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:49:11.736+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:49:11.746+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:49:11.745+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:49:11.748+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:49:11.748+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:49:11.768+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:49:11.749+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:49:11.769+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:49:11.881+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.328 seconds
[2026-01-23T14:49:42.694+0000] {processor.py:161} INFO - Started process (PID=4967) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:49:42.697+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:49:42.703+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:49:42.702+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:49:42.817+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:49:42.817+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:49:42.820+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:49:42.820+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:49:42.823+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:49:42.822+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:49:42.833+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:49:42.832+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:49:42.840+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:49:42.839+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:49:42.847+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:49:42.846+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:49:42.849+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:49:42.848+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:49:42.869+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:49:42.850+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:49:42.872+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:49:42.985+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.309 seconds
[2026-01-23T14:50:14.427+0000] {processor.py:161} INFO - Started process (PID=4977) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:50:14.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:50:14.438+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:50:14.437+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:50:14.579+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:50:14.578+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:50:14.581+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:50:14.580+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:50:14.584+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:50:14.583+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:50:14.596+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:50:14.595+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:50:14.603+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:50:14.603+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:50:14.611+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:50:14.610+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:50:14.613+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:50:14.612+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:50:14.632+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:50:14.614+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:50:14.635+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:50:14.747+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.336 seconds
[2026-01-23T14:50:45.758+0000] {processor.py:161} INFO - Started process (PID=4987) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:50:45.762+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:50:45.768+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:50:45.766+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:50:45.868+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:50:45.866+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:50:45.870+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:50:45.870+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:50:45.872+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:50:45.872+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:50:45.881+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:50:45.881+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:50:45.889+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:50:45.888+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:50:45.895+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:50:45.894+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:50:45.897+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:50:45.896+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:50:45.913+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:50:45.898+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:50:45.915+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:50:46.032+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.294 seconds
[2026-01-23T14:51:16.506+0000] {processor.py:161} INFO - Started process (PID=4997) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:51:16.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:51:16.519+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:51:16.518+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:51:16.624+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:51:16.623+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:51:16.626+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:51:16.626+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:51:16.629+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:51:16.628+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:51:16.639+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:51:16.638+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:51:16.644+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:51:16.644+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:51:16.650+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:51:16.650+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:51:16.652+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:51:16.652+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:51:16.673+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:51:16.653+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:51:16.675+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:51:16.806+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.323 seconds
[2026-01-23T14:51:47.519+0000] {processor.py:161} INFO - Started process (PID=5007) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:51:47.524+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:51:47.530+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:51:47.529+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:51:47.676+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:51:47.675+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:51:47.678+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:51:47.678+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:51:47.681+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:51:47.681+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:51:47.691+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:51:47.690+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:51:47.699+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:51:47.698+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:51:47.706+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:51:47.706+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:51:47.709+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:51:47.708+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:51:47.726+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:51:47.710+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:51:47.728+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:51:47.838+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.336 seconds
[2026-01-23T14:52:18.898+0000] {processor.py:161} INFO - Started process (PID=5017) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:52:18.901+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:52:18.908+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:52:18.906+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:52:19.012+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:52:19.012+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:52:19.015+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:52:19.014+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:52:19.017+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:52:19.016+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:52:19.027+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:52:19.026+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:52:19.033+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:52:19.032+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:52:19.040+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:52:19.039+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:52:19.042+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:52:19.042+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:52:19.061+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:52:19.044+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:52:19.063+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:52:19.171+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.291 seconds
[2026-01-23T14:52:49.533+0000] {processor.py:161} INFO - Started process (PID=5027) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:52:49.538+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:52:49.545+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:52:49.544+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:52:49.649+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:52:49.648+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:52:49.651+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:52:49.650+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:52:49.652+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:52:49.652+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:52:49.661+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:52:49.661+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:52:49.668+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:52:49.667+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:52:49.675+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:52:49.674+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:52:49.677+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:52:49.676+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:52:49.696+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:52:49.678+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:52:49.698+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:52:49.817+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.309 seconds
[2026-01-23T14:53:21.083+0000] {processor.py:161} INFO - Started process (PID=5037) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:53:21.086+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:53:21.092+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:53:21.091+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:53:21.190+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:53:21.190+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:53:21.192+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:53:21.192+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:53:21.194+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:53:21.194+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:53:21.203+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:53:21.202+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:53:21.209+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:53:21.209+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:53:21.216+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:53:21.215+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:53:21.219+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:53:21.218+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:53:21.237+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:53:21.220+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:53:21.239+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:53:21.344+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.278 seconds
[2026-01-23T14:53:52.265+0000] {processor.py:161} INFO - Started process (PID=5047) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:53:52.269+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:53:52.275+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:53:52.274+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:53:52.446+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:53:52.445+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:53:52.448+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:53:52.447+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:53:52.450+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:53:52.450+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:53:52.460+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:53:52.460+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:53:52.467+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:53:52.466+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:53:52.474+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:53:52.473+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:53:52.476+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:53:52.475+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:53:52.496+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:53:52.477+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:53:52.498+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:53:52.617+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.372 seconds
[2026-01-23T14:54:23.488+0000] {processor.py:161} INFO - Started process (PID=5057) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:54:23.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:54:23.498+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:54:23.497+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:54:23.607+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:54:23.607+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:54:23.610+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:54:23.609+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:54:23.612+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:54:23.611+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:54:23.622+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:54:23.621+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:54:23.629+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:54:23.629+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:54:23.636+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:54:23.635+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:54:23.638+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:54:23.638+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:54:23.655+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:54:23.639+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:54:23.657+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:54:23.767+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.299 seconds
[2026-01-23T14:54:54.320+0000] {processor.py:161} INFO - Started process (PID=5067) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:54:54.323+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:54:54.331+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:54:54.329+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:54:54.430+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:54:54.429+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:54:54.432+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:54:54.432+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:54:54.435+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:54:54.434+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:54:54.444+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:54:54.444+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:54:54.451+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:54:54.450+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:54:54.458+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:54:54.457+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:54:54.460+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:54:54.459+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:54:54.476+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:54:54.461+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:54:54.478+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:54:54.585+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.281 seconds
[2026-01-23T14:55:25.855+0000] {processor.py:161} INFO - Started process (PID=5077) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:55:25.859+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:55:25.865+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:55:25.864+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:55:25.972+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:55:25.971+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:55:25.974+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:55:25.973+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:55:25.976+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:55:25.975+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:55:25.986+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:55:25.985+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:55:25.992+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:55:25.992+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:55:25.999+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:55:25.998+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:55:26.001+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:55:26.000+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:55:26.021+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:55:26.002+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:55:26.023+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:55:26.129+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.291 seconds
[2026-01-23T14:55:58.650+0000] {processor.py:161} INFO - Started process (PID=5087) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:55:58.655+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T14:55:58.661+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:55:58.660+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:55:58.772+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:55:58.770+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T14:55:58.774+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:55:58.773+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T14:55:58.777+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:55:58.776+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T14:55:58.787+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:55:58.787+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:55:58.795+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:55:58.794+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:55:58.802+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:55:58.802+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T14:55:58.804+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:55:58.804+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T14:55:58.820+0000] {logging_mixin.py:188} INFO - [2026-01-23T14:55:58.805+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T14:55:58.822+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T14:55:58.931+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.298 seconds
[2026-01-23T15:00:50.608+0000] {processor.py:161} INFO - Started process (PID=5097) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:00:50.621+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:00:50.638+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:00:50.636+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:00:50.966+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:00:50.965+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:00:50.974+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:00:50.973+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:00:50.985+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:00:50.984+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:00:51.038+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:00:51.037+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:00:51.054+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:00:51.053+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:00:51.079+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:00:51.078+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:00:51.090+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:00:51.090+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:00:51.195+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:00:51.098+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:00:51.199+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:00:51.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.925 seconds
[2026-01-23T15:01:21.795+0000] {processor.py:161} INFO - Started process (PID=5107) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:01:21.798+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:01:21.802+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:01:21.801+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:01:21.875+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:01:21.874+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:01:21.877+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:01:21.876+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:01:21.879+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:01:21.879+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:01:21.885+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:01:21.884+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:01:21.891+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:01:21.890+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:01:21.896+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:01:21.896+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:01:21.898+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:01:21.897+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:01:21.908+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:01:21.899+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:01:21.909+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:01:21.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.202 seconds
[2026-01-23T15:01:52.805+0000] {processor.py:161} INFO - Started process (PID=5117) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:01:52.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:01:52.816+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:01:52.815+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:01:52.944+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:01:52.943+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:01:52.947+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:01:52.946+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:01:52.949+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:01:52.949+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:01:52.963+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:01:52.961+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:01:52.971+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:01:52.970+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:01:52.979+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:01:52.978+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:01:52.981+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:01:52.980+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:01:53.000+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:01:52.982+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:01:53.002+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:01:53.104+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.316 seconds
[2026-01-23T15:02:23.695+0000] {processor.py:161} INFO - Started process (PID=5127) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:02:23.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:02:23.706+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:02:23.705+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:02:23.831+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:02:23.830+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:02:23.834+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:02:23.833+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:02:23.836+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:02:23.836+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:02:23.846+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:02:23.845+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:02:23.852+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:02:23.852+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:02:23.859+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:02:23.858+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:02:23.861+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:02:23.860+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:02:23.883+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:02:23.862+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:02:23.886+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:02:24.007+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.327 seconds
[2026-01-23T15:02:55.324+0000] {processor.py:161} INFO - Started process (PID=5137) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:02:55.328+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:02:55.335+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:02:55.334+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:02:55.444+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:02:55.442+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:02:55.446+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:02:55.446+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:02:55.450+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:02:55.449+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:02:55.459+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:02:55.458+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:02:55.466+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:02:55.465+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:02:55.471+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:02:55.471+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:02:55.473+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:02:55.473+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:02:55.489+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:02:55.474+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:02:55.491+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:02:55.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.291 seconds
[2026-01-23T15:03:27.013+0000] {processor.py:161} INFO - Started process (PID=5147) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:03:27.018+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:03:27.026+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:03:27.025+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:03:27.118+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:03:27.118+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:03:27.120+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:03:27.120+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:03:27.122+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:03:27.122+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:03:27.130+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:03:27.130+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:03:27.136+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:03:27.135+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:03:27.141+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:03:27.141+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:03:27.143+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:03:27.142+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:03:27.159+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:03:27.144+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:03:27.161+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:03:27.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.284 seconds
[2026-01-23T15:03:57.775+0000] {processor.py:161} INFO - Started process (PID=5157) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:03:57.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:03:57.787+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:03:57.786+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:03:57.901+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:03:57.900+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:03:57.903+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:03:57.902+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:03:57.905+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:03:57.905+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:03:57.915+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:03:57.914+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:03:57.928+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:03:57.927+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:03:57.935+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:03:57.934+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:03:57.937+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:03:57.936+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:03:57.953+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:03:57.938+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:03:57.956+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:03:58.056+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.304 seconds
[2026-01-23T15:04:29.028+0000] {processor.py:161} INFO - Started process (PID=5167) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:04:29.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:04:29.038+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:04:29.036+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:04:29.154+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:04:29.153+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:04:29.157+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:04:29.156+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:04:29.160+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:04:29.159+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:04:29.168+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:04:29.168+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:04:29.175+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:04:29.174+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:04:29.181+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:04:29.180+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:04:29.182+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:04:29.182+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:04:29.202+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:04:29.183+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:04:29.203+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:04:29.770+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.760 seconds
[2026-01-23T15:05:00.201+0000] {processor.py:161} INFO - Started process (PID=5177) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:05:00.204+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:05:00.210+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:05:00.209+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:05:00.346+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:05:00.345+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:05:00.349+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:05:00.348+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:05:00.352+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:05:00.351+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:05:00.363+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:05:00.362+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:05:00.371+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:05:00.371+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:05:00.378+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:05:00.378+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:05:00.380+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:05:00.380+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:05:00.400+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:05:00.382+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:05:00.403+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:05:00.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.325 seconds
[2026-01-23T15:05:31.705+0000] {processor.py:161} INFO - Started process (PID=5187) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:05:31.709+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:05:31.717+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:05:31.716+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:05:31.847+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:05:31.846+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:05:31.850+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:05:31.849+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:05:31.853+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:05:31.852+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:05:31.863+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:05:31.862+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:05:31.869+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:05:31.868+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:05:31.875+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:05:31.874+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:05:31.877+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:05:31.876+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:05:31.896+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:05:31.878+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:05:31.898+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:05:32.004+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.318 seconds
[2026-01-23T15:06:03.172+0000] {processor.py:161} INFO - Started process (PID=5197) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:06:03.175+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:06:03.182+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:06:03.181+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:06:03.301+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:06:03.301+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:06:03.304+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:06:03.303+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:06:03.306+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:06:03.306+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:06:03.316+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:06:03.315+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:06:03.322+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:06:03.321+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:06:03.328+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:06:03.328+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:06:03.330+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:06:03.329+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:06:03.351+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:06:03.331+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:06:03.353+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:06:03.459+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.303 seconds
[2026-01-23T15:06:33.899+0000] {processor.py:161} INFO - Started process (PID=5207) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:06:33.903+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:06:33.910+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:06:33.909+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:06:34.025+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:06:34.024+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:06:34.028+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:06:34.027+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:06:34.031+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:06:34.030+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:06:34.041+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:06:34.040+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:06:34.049+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:06:34.048+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:06:34.055+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:06:34.054+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:06:34.057+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:06:34.056+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:06:34.075+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:06:34.058+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:06:34.077+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:06:34.185+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.308 seconds
[2026-01-23T15:07:04.382+0000] {processor.py:161} INFO - Started process (PID=5217) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:07:04.386+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:07:04.395+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:07:04.394+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:07:04.509+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:07:04.508+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:07:04.511+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:07:04.511+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:07:04.514+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:07:04.514+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:07:04.525+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:07:04.524+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:07:04.532+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:07:04.531+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:07:04.539+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:07:04.538+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:07:04.541+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:07:04.540+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:07:04.562+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:07:04.542+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:07:04.564+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:07:04.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.318 seconds
[2026-01-23T15:07:35.217+0000] {processor.py:161} INFO - Started process (PID=5227) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:07:35.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:07:35.227+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:07:35.225+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:07:35.337+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:07:35.336+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:07:35.339+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:07:35.339+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:07:35.342+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:07:35.341+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:07:35.351+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:07:35.350+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:07:35.358+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:07:35.357+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:07:35.365+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:07:35.364+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:07:35.367+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:07:35.366+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:07:35.388+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:07:35.368+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:07:35.390+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:07:35.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.309 seconds
[2026-01-23T15:08:06.910+0000] {processor.py:161} INFO - Started process (PID=5237) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:08:06.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:08:06.918+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:08:06.917+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:08:07.034+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:08:07.033+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:08:07.036+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:08:07.036+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:08:07.038+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:08:07.038+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:08:07.047+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:08:07.046+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:08:07.053+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:08:07.052+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:08:07.058+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:08:07.058+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:08:07.060+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:08:07.059+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:08:07.079+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:08:07.061+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:08:07.080+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:08:07.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.294 seconds
[2026-01-23T15:08:37.709+0000] {processor.py:161} INFO - Started process (PID=5247) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:08:37.712+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:08:37.718+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:08:37.717+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:08:37.847+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:08:37.846+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:08:37.849+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:08:37.848+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:08:37.851+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:08:37.851+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:08:37.860+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:08:37.859+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:08:37.866+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:08:37.865+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:08:37.872+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:08:37.871+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:08:37.874+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:08:37.873+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:08:37.895+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:08:37.876+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:08:37.898+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:08:38.014+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.322 seconds
[2026-01-23T15:09:08.953+0000] {processor.py:161} INFO - Started process (PID=5257) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:09:08.956+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:09:08.961+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:09:08.960+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:09:09.090+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:09:09.089+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:09:09.092+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:09:09.092+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:09:09.096+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:09:09.095+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:09:09.105+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:09:09.104+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:09:09.113+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:09:09.112+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:09:09.120+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:09:09.119+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:09:09.122+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:09:09.122+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:09:09.142+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:09:09.123+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:09:09.144+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:09:09.254+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.316 seconds
[2026-01-23T15:09:40.539+0000] {processor.py:161} INFO - Started process (PID=5267) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:09:40.543+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:09:40.549+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:09:40.548+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:09:40.657+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:09:40.656+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:09:40.660+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:09:40.659+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:09:40.662+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:09:40.662+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:09:40.671+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:09:40.670+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:09:40.678+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:09:40.677+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:09:40.685+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:09:40.684+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:09:40.687+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:09:40.686+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:09:40.707+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:09:40.688+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:09:40.709+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:09:40.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.335 seconds
[2026-01-23T15:10:12.212+0000] {processor.py:161} INFO - Started process (PID=5277) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:10:12.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:10:12.222+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:10:12.221+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:10:12.359+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:10:12.358+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:10:12.362+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:10:12.361+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:10:12.364+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:10:12.364+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:10:12.373+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:10:12.372+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:10:12.379+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:10:12.379+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:10:12.385+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:10:12.384+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:10:12.387+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:10:12.387+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:10:12.405+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:10:12.389+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:10:12.407+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:10:12.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.333 seconds
[2026-01-23T15:10:43.127+0000] {processor.py:161} INFO - Started process (PID=5287) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:10:43.131+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:10:43.136+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:10:43.135+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:10:43.242+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:10:43.241+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:10:43.244+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:10:43.244+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:10:43.247+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:10:43.246+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:10:43.256+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:10:43.255+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:10:43.263+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:10:43.262+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:10:43.269+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:10:43.269+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:10:43.271+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:10:43.271+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:10:43.288+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:10:43.272+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:10:43.290+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:10:43.390+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.282 seconds
[2026-01-23T15:11:13.981+0000] {processor.py:161} INFO - Started process (PID=5297) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:11:13.984+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:11:13.990+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:11:13.989+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:11:14.094+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:11:14.093+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:11:14.096+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:11:14.096+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:11:14.099+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:11:14.098+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:11:14.107+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:11:14.107+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:11:14.113+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:11:14.113+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:11:14.119+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:11:14.118+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:11:14.121+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:11:14.120+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:11:14.139+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:11:14.122+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:11:14.141+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:11:14.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.290 seconds
[2026-01-23T15:11:45.003+0000] {processor.py:161} INFO - Started process (PID=5307) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:11:45.013+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T15:11:45.038+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:11:45.036+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:11:45.257+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:11:45.256+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T15:11:45.260+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:11:45.260+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T15:11:45.263+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:11:45.262+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T15:11:45.273+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:11:45.273+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:11:45.280+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:11:45.279+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:11:45.286+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:11:45.286+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T15:11:45.288+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:11:45.288+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T15:11:45.305+0000] {logging_mixin.py:188} INFO - [2026-01-23T15:11:45.289+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T15:11:45.308+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T15:11:45.410+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.474 seconds
[2026-01-23T16:15:41.068+0000] {processor.py:161} INFO - Started process (PID=5320) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:15:41.080+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:15:41.098+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:15:41.096+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:15:41.258+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:15:41.257+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:15:41.261+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:15:41.260+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:15:41.264+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:15:41.263+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:15:41.276+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:15:41.275+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:15:41.286+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:15:41.285+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:15:41.295+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:15:41.294+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:15:41.297+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:15:41.297+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:15:41.317+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:15:41.299+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:15:41.319+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:15:41.465+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.435 seconds
[2026-01-23T16:16:12.724+0000] {processor.py:161} INFO - Started process (PID=5330) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:16:12.728+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:16:12.737+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:16:12.736+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:16:12.846+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:16:12.844+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:16:12.848+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:16:12.848+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:16:12.851+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:16:12.851+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:16:12.860+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:16:12.860+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:16:12.868+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:16:12.867+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:16:12.875+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:16:12.874+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:16:12.877+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:16:12.876+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:16:12.901+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:16:12.878+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:16:12.903+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:16:13.023+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.317 seconds
[2026-01-23T16:16:44.638+0000] {processor.py:161} INFO - Started process (PID=5340) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:16:44.641+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:16:44.648+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:16:44.647+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:16:44.764+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:16:44.763+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:16:44.767+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:16:44.766+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:16:44.770+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:16:44.769+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:16:44.780+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:16:44.779+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:16:44.789+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:16:44.788+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:16:44.796+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:16:44.795+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:16:44.799+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:16:44.798+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:16:44.818+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:16:44.800+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:16:44.820+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:16:44.931+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.311 seconds
[2026-01-23T16:17:15.824+0000] {processor.py:161} INFO - Started process (PID=5350) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:17:15.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:17:15.839+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:17:15.838+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:17:15.951+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:17:15.950+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:17:15.953+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:17:15.952+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:17:15.956+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:17:15.955+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:17:15.966+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:17:15.965+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:17:15.972+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:17:15.972+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:17:15.979+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:17:15.978+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:17:15.980+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:17:15.980+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:17:15.998+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:17:15.982+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:17:16.004+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:17:16.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.295 seconds
[2026-01-23T16:17:46.379+0000] {processor.py:161} INFO - Started process (PID=5360) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:17:46.383+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:17:46.389+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:17:46.389+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:17:46.523+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:17:46.522+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:17:46.525+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:17:46.524+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:17:46.527+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:17:46.527+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:17:46.537+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:17:46.536+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:17:46.544+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:17:46.543+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:17:46.552+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:17:46.551+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:17:46.553+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:17:46.553+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:17:46.571+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:17:46.554+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:17:46.573+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:17:46.685+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.322 seconds
[2026-01-23T16:18:18.358+0000] {processor.py:161} INFO - Started process (PID=5370) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:18:18.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:18:18.369+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:18:18.368+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:18:18.491+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:18:18.491+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:18:18.493+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:18:18.493+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:18:18.496+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:18:18.495+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:18:18.504+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:18:18.504+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:18:18.510+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:18:18.510+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:18:18.518+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:18:18.517+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:18:18.520+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:18:18.519+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:18:18.541+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:18:18.521+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:18:18.543+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:18:18.674+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.334 seconds
[2026-01-23T16:18:50.078+0000] {processor.py:161} INFO - Started process (PID=5380) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:18:50.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:18:50.088+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:18:50.087+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:18:50.208+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:18:50.207+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:18:50.211+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:18:50.210+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:18:50.214+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:18:50.214+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:18:50.223+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:18:50.222+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:18:50.230+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:18:50.229+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:18:50.237+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:18:50.236+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:18:50.239+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:18:50.238+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:18:50.258+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:18:50.240+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:18:50.260+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:18:50.364+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.302 seconds
[2026-01-23T16:19:20.762+0000] {processor.py:161} INFO - Started process (PID=5390) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:19:20.766+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:19:20.773+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:19:20.772+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:19:20.900+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:19:20.899+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:19:20.902+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:19:20.902+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:19:20.905+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:19:20.904+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:19:20.914+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:19:20.914+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:19:20.921+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:19:20.921+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:19:20.928+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:19:20.928+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:19:20.930+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:19:20.930+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:19:20.954+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:19:20.932+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:19:20.956+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:19:21.087+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.342 seconds
[2026-01-23T16:19:52.710+0000] {processor.py:161} INFO - Started process (PID=5400) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:19:52.714+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:19:52.721+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:19:52.720+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:19:52.863+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:19:52.862+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:19:52.866+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:19:52.865+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:19:52.869+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:19:52.868+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:19:52.879+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:19:52.878+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:19:52.887+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:19:52.886+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:19:52.893+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:19:52.893+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:19:52.895+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:19:52.895+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:19:52.921+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:19:52.897+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:19:52.923+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:19:53.045+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.352 seconds
[2026-01-23T16:37:05.262+0000] {processor.py:161} INFO - Started process (PID=5407) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:37:05.276+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:37:05.294+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:37:05.292+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:37:05.496+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:37:05.494+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:37:05.505+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:37:05.504+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:37:05.507+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:37:05.507+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:37:05.526+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:37:05.525+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:37:05.550+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:37:05.549+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:37:05.620+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:37:05.619+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:37:05.623+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:37:05.622+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:37:05.644+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:37:05.625+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:37:05.648+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:37:06.881+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 1.684 seconds
[2026-01-23T16:37:38.467+0000] {processor.py:161} INFO - Started process (PID=5417) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:37:38.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:37:38.477+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:37:38.476+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:37:38.606+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:37:38.605+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:37:38.608+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:37:38.607+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:37:38.611+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:37:38.610+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:37:38.620+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:37:38.620+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:37:38.628+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:37:38.627+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:37:38.635+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:37:38.634+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:37:38.637+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:37:38.636+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:37:38.656+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:37:38.638+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:37:38.658+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:37:38.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.326 seconds
[2026-01-23T16:38:09.236+0000] {processor.py:161} INFO - Started process (PID=5427) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:38:09.240+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:38:09.246+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:38:09.245+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:38:09.370+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:38:09.369+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:38:09.372+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:38:09.372+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:38:09.375+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:38:09.374+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:38:09.385+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:38:09.384+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:38:09.392+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:38:09.392+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:38:09.400+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:38:09.399+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:38:09.403+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:38:09.402+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:38:09.425+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:38:09.405+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:38:09.427+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:38:09.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.329 seconds
[2026-01-23T16:38:40.428+0000] {processor.py:161} INFO - Started process (PID=5437) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:38:40.432+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:38:40.440+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:38:40.439+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:38:40.579+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:38:40.577+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:38:40.583+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:38:40.582+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:38:40.587+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:38:40.586+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:38:40.597+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:38:40.596+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:38:40.605+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:38:40.604+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:38:40.612+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:38:40.611+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:38:40.613+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:38:40.613+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:38:40.630+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:38:40.615+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:38:40.631+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:38:40.737+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.327 seconds
[2026-01-23T16:39:11.162+0000] {processor.py:161} INFO - Started process (PID=5447) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:39:11.166+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:39:11.172+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:39:11.171+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:39:11.307+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:39:11.306+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:39:11.310+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:39:11.309+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:39:11.313+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:39:11.312+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:39:11.324+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:39:11.323+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:39:11.332+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:39:11.331+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:39:11.339+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:39:11.338+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:39:11.341+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:39:11.340+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:39:11.359+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:39:11.343+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:39:11.361+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:39:11.482+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.335 seconds
[2026-01-23T16:39:41.778+0000] {processor.py:161} INFO - Started process (PID=5457) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:39:41.782+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:39:41.788+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:39:41.786+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:39:41.920+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:39:41.918+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:39:41.922+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:39:41.922+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:39:41.925+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:39:41.924+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:39:41.934+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:39:41.934+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:39:41.941+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:39:41.940+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:39:41.949+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:39:41.948+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:39:41.951+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:39:41.951+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:39:41.977+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:39:41.953+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:39:41.979+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:39:42.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.362 seconds
[2026-01-23T16:40:12.454+0000] {processor.py:161} INFO - Started process (PID=5467) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:40:12.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:40:12.463+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:40:12.462+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:40:12.569+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:40:12.568+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:40:12.571+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:40:12.570+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:40:12.573+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:40:12.573+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:40:12.582+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:40:12.582+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:40:12.589+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:40:12.588+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:40:12.596+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:40:12.596+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:40:12.599+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:40:12.598+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:40:12.620+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:40:12.600+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:40:12.622+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:40:12.755+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.316 seconds
[2026-01-23T16:53:50.637+0000] {processor.py:161} INFO - Started process (PID=5477) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:53:50.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:53:50.668+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:53:50.666+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:53:50.845+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:53:50.843+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:53:50.854+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:53:50.847+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:53:50.858+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:53:50.857+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:53:50.879+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:53:50.878+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:53:50.887+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:53:50.887+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:53:50.897+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:53:50.896+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:53:50.901+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:53:50.900+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:53:50.930+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:53:50.903+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:53:50.933+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:53:51.088+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.506 seconds
[2026-01-23T16:54:21.806+0000] {processor.py:161} INFO - Started process (PID=5487) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:54:21.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:54:21.816+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:54:21.815+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:54:21.940+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:54:21.939+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:54:21.942+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:54:21.942+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:54:21.945+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:54:21.945+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:54:21.955+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:54:21.954+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:54:21.962+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:54:21.961+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:54:21.968+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:54:21.968+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:54:21.970+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:54:21.970+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:54:21.989+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:54:21.972+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:54:21.991+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:54:22.111+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.323 seconds
[2026-01-23T16:54:53.303+0000] {processor.py:161} INFO - Started process (PID=5497) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:54:53.306+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:54:53.313+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:54:53.312+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:54:53.474+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:54:53.474+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:54:53.477+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:54:53.476+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:54:53.480+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:54:53.479+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:54:53.490+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:54:53.490+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:54:53.497+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:54:53.496+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:54:53.503+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:54:53.503+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:54:53.505+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:54:53.505+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:54:53.523+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:54:53.506+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:54:53.526+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:54:53.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.362 seconds
[2026-01-23T16:55:24.798+0000] {processor.py:161} INFO - Started process (PID=5507) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:55:24.802+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:55:24.810+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:55:24.809+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:55:24.936+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:55:24.935+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:55:24.938+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:55:24.938+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:55:24.941+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:55:24.940+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:55:24.951+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:55:24.950+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:55:24.957+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:55:24.956+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:55:24.963+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:55:24.963+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:55:24.965+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:55:24.965+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:55:24.982+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:55:24.966+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:55:24.985+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:55:25.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.333 seconds
[2026-01-23T16:55:56.233+0000] {processor.py:161} INFO - Started process (PID=5517) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:55:56.237+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:55:56.243+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:55:56.242+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:55:56.347+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:55:56.346+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:55:56.350+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:55:56.349+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:55:56.352+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:55:56.352+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:55:56.361+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:55:56.360+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:55:56.368+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:55:56.367+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:55:56.374+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:55:56.373+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:55:56.376+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:55:56.375+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:55:56.394+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:55:56.378+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:55:56.397+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:55:56.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.295 seconds
[2026-01-23T16:56:27.680+0000] {processor.py:161} INFO - Started process (PID=5527) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:56:27.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:56:27.693+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:56:27.691+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:56:27.838+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:56:27.837+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:56:27.841+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:56:27.840+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:56:27.844+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:56:27.843+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:56:27.855+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:56:27.854+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:56:27.863+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:56:27.862+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:56:27.870+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:56:27.870+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:56:27.872+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:56:27.872+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:56:27.899+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:56:27.874+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:56:27.901+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:56:28.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.385 seconds
[2026-01-23T16:56:59.068+0000] {processor.py:161} INFO - Started process (PID=5537) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:56:59.071+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:56:59.077+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:56:59.076+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:56:59.206+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:56:59.205+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:56:59.208+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:56:59.208+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:56:59.211+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:56:59.210+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:56:59.221+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:56:59.220+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:56:59.228+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:56:59.227+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:56:59.235+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:56:59.234+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:56:59.237+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:56:59.236+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:56:59.254+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:56:59.238+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:56:59.255+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:56:59.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.314 seconds
[2026-01-23T16:57:30.676+0000] {processor.py:161} INFO - Started process (PID=5547) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:57:30.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:57:30.698+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:57:30.696+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:57:30.941+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:57:30.940+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:57:30.946+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:57:30.945+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:57:30.950+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:57:30.949+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:57:30.970+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:57:30.969+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:57:30.983+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:57:30.983+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:57:31.000+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:57:30.999+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:57:31.007+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:57:31.006+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:57:31.058+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:57:31.009+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:57:31.065+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:57:31.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.634 seconds
[2026-01-23T16:58:01.450+0000] {processor.py:161} INFO - Started process (PID=5557) to work on /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:58:01.453+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/GCSToBigQueryOperatorDAG.py for tasks to queue
[2026-01-23T16:58:01.459+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:58:01.458+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:58:01.601+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:58:01.600+0000] {connection.py:274} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2026-01-23T16:58:01.604+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:58:01.603+0000] {base.py:84} INFO - Using connection ID 'google_cloud_default' for task execution.
[2026-01-23T16:58:01.607+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:58:01.606+0000] {credentials_provider.py:353} INFO - Getting connection using `google.auth.default()` since no explicit credentials are provided.
[2026-01-23T16:58:01.618+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:58:01.617+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:58:01.625+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:58:01.624+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:58:01.632+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:58:01.631+0000] {_metadata.py:139} WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 111] Connection refused
[2026-01-23T16:58:01.634+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:58:01.634+0000] {_default.py:338} WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.
[2026-01-23T16:58:01.661+0000] {logging_mixin.py:188} INFO - [2026-01-23T16:58:01.636+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 24, in <module>
    employee_schema = read_schema_from_gcs(
  File "/opt/airflow/dags/GCSToBigQueryOperatorDAG.py", line 18, in read_schema_from_gcs
    schema_content = hook.download(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 337, in download
    client = self.get_conn()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/hooks/gcs.py", line 169, in get_conn
    credentials=self.get_credentials(), client_info=CLIENT_INFO, project=self.project_id
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 308, in get_credentials
    credentials, _ = self.get_credentials_and_project_id()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/common/hooks/base_google.py", line 285, in get_credentials_and_project_id
    credentials, project_id = get_credentials_and_project_id(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 362, in get_credentials_and_project_id
    return _CredentialProvider(*args, **kwargs).get_credentials_and_project()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 243, in get_credentials_and_project
    credentials, project_id = self._get_credentials_using_adc()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/providers/google/cloud/utils/credentials_provider.py", line 348, in _get_credentials_using_adc
    credentials, project_id = google.auth.default(scopes=self.scopes)
  File "/home/airflow/.local/lib/python3.10/site-packages/google/auth/_default.py", line 691, in default
    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)
google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.
[2026-01-23T16:58:01.666+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/GCSToBigQueryOperatorDAG.py
[2026-01-23T16:58:01.815+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/GCSToBigQueryOperatorDAG.py took 0.381 seconds
